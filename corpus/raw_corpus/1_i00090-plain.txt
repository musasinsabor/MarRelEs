
Primera parte 

Hacia un nuevo sistema tecnológico 

Figura 1

Esquema del sistema tecnológico actual

Sistema y redes inmateriales de búsqueda y difusión de la información:
Hipermedia, bancos de datos, servidores telemáticos, Internet, Telnet, Usenet, Gopher, WAIS, World Wide Web, Mosaic y NetScape.

Documentos de comunicación y aplicaciones multimedia interactivos: 
Formación continua, servicios de información, servicios de asesoramiento o de valor añadido, presentaciones promocionales, terminales interactivos, juegos.

Sistemas de redes materiales de difusión de la información:
Redes telefónicas, RDSI, hercianas de TV, redes de TV por cable, redes de TV por satélite, redes celulares, autopistas de la información.

Sistema de tratamiento y gestión de la información: 
Microcomputadoras y estaciones de trabajo, sistemas ópticos de grabación, compresión de datos, redes de trabajo en colaboración, sistemas de autor multimedia, servidores multimedia, sistemas de conmutación.

Presión económica: 
Búsqueda de la competitividad a escala mundial, acortamiento del ciclo de vida de los productos, necesidades de formación continua, necesidades de gestión de la información, mejora del servicio al consumidor, mercados financieros, política de desarrollo económico internacional.

Estos últimos años, el desempleo no ha cesado de aumentar en la mayoría de los países.
Las nuevas tecnologías de tratamiento de la información y la comunicación figuran entre las causas más citadas: 

"Abundan, de hecho, los textos que achacan a la evolución tecnológica del pasado decenio la menor demanda de trabajadores no calificados» (informe de la OIT, El empleo en el mundo 1995 , pág. 59).

Aunque la aplicación de las nuevas tecnologías origine nuevos empleos, el balance no parece claramente positivo.
En las crisis de ajuste tecnológico anteriores a los siglos XVII y XIX, los efectos de compensación no fueron inmediatos.

No hay un reequilibrio automático que suponga una sustitución inmediata de los puestos de trabajo perdidos.
Los economistas no se ponen de acuerdo en si debe dejarse al mercado de trabajo encontrar su nuevo equilibrio o si los estados deben intervenir activamente para acelerar el proceso.

EL proyecto de autopistas de la información del vicepresidente de los Estados Unidos de América, Edward Gore, así como el Libro Blanco del ex presidente de la Comisión Europea Jacques Delors, son el resultado de la voluntad de dirigir y estimular los cambios en curso.
Completan estos proyectos algunos programas de experimentación o de estímulo para ayudar al establecimiento de las infraestructuras que se consideran necesarias para el desarrollo de las nuevas actividades económicas que ya se cree percibir y que desembocarán en nuevos puestos de trabajo.
La reunión del G7 que tuvo lugar en febrero de 1995 sobre este tema atestigua el interés que despiertan estas cuestiones en los países desarrollados.

Las tecnologías son el resultado de la aplicación de los conocimientos científicos que prevalecen en cada época dentro del ámbito de la producción, la gestión y la comunicación.
Se concretan en forma de técnicas que combinan equipamiento y conocimientos técnicos y que corresponden a nuevas actividades económicas, nuevos empleos y un nuevo ciclo de prosperidad.
De este modo, a lo largo de la historia de la humanidad la introducción de nuevas tecnologías ha provocado duras reacciones sobre las estructuras económicas y sociales y ha dado lugar a revueltas obreras y movimientos de destrucción de maquinaria.

El sistema tecnológico que poco a poco se ha implantado ha engendrado un modelo jerárquico piramidal que constituye la base de las empresas y las instituciones.
Las interacciones humanas actúan en la empresa siguiendo el modelo de las redes biológicas, que se oponen por su horizontalidad al poder que se ejerce de arriba abajo.
Pero el sistema que nos ha llevado a la aparición de las tecnologías de la información y la comunicación introduce nuevas dimensiones que son las de la flexibilidad, la mundialización, la economía de lo inmaterial y la gestión de la complejidad.
Dimensiones que suponen un cambio de actitud tan radical, a menudo tan duramente vivido, que resultan difíciles de prever.

La sociedad fractal 

Según Andràs November, con la introducción de los microprocesadores en el proceso productivo no se puede establecer más una línea de demarcación precisa entre la tecnología industrial (aplicada exclusivamente en la fabricación) y la tecnología de la información (utilizada para las actividades administrativas).
Todo converge hacia las «industrias del saber» que implican la aplicación de los conocimientos y la adquisición de una formación entendida a nivel del taller de fabricación y utilización de máquinas electrónicas perfeccionadas.
Con la aplicación de la nueva tecnología, la información se convierte en uno de los recursos principales de las actividades productivas.
El dominio de la información (es decir, capacidad de memorización, tratamiento y transmisión de los datos) es la condición previa a la utilización de otros factores de producción.
(Andràs November, Nouvelles tecnologies et mutations ocio- économiques , IIES-OIT, Ginebra, 1990, pág. 20).

En los talleres y las oficinas, el microprocesador, un elemento discreto situado en el corazón de los sistemas, reina como dueño absoluto.
Todas las tareas son informatizables: la gestión administrativa y contable, la Gestión Electrónica de Documentos (GED), el Intercambio Electrónico de Documentos (EDI), la Enseñanza Asistida por Computadora (EAC), el Diseño Asistido por Computadora (DAC), la Fabricación Asistida por Computadora (FAC), o la Gestión de la Producción Asistida por Computadora (GPAC).
«El microprocesador es la máquina de vapor de nuestros tiempos» Jacques Lesourne, Les mille sentiers de l'avenir , París, 1981, pág. 281).
A la microcomputadora le falta todavía conquistar los hogares y restablecer el vínculo social que los una.

La informática, que se encuentra en el corazón del nuevo sistema tecnológico, es una potente herramienta de gestión y simulación de la complejidad.
Los espíritus confortablemente instalados en los hábitos y la tranquilidad de las tradiciones no se adaptan a ella fácilmente.
Hoy, por encima de los modelos mecanicistas y las redes biológicas, el reto consiste en considerar la complejidad de la naturaleza, simular el caos, gestionar todos los factores simultáneamente, enfrentarse a las catástrofes, favorecer la creatividad de la persona en el trae bajo de equipo y buscar la máxima optimización de los procesos de diseño, producción y difusión de la información, los valores y los bienes.

Por medio de una serie de cálculos reiterados con ecuaciones «interactivas», la computadora visualiza en la pantalla la representación de formas naturales llamadas «fractales».
Estos modelos fractales se encuentran en el centro mismo de la naturaleza, más en su desarrollo armonioso que en sus accidentes o catástrofes; por ejemplo, en la formación de nubes, la propagación del rayo, la erosión de las montañas, el perfil de las costas, la estructura de las hojas v los árboles, el crecimiento de las plantas, los fenómenos sociales o económicos.
Las imágenes de fractales tienen la propiedad fascinante de ser idénticas en su conjunto a lo que son en detalle.
La realidad puede de esta forma simularse en sus mínimos pormenores, la obra resultante puede a su vez convertirse en virtual como la misma realidad.

Por un efecto de simetría inquietante, si una ecuación de fractal describe la imagen de una forma natural, a la inversa cualquier imagen de una forma natural (y a mayor abundamiento cualquier imagen) puede reducirse a una serie de ecuaciones de fractales.

Entonces, este efecto equivale a una forma última de «compresión» de las imágenes, reducidas de alguna manera a su «quintaesencia matemática».

Es como si se hubiera dado la vuelta a la pirámide.
La persona se hace más eficaz y, equipada de una microcomputadora dotada de microprocesadores cada día más potentes y memorias de mayor capacidad y más rápidas a mejor precio, aumenta su capacidad de trae bajo.
Por medio de la red interna y las conexiones cada vez más económicas y fáciles con las redes locales o de telecomunicación internacional, comunica rápidamente y tiene acceso de manera autónoma a las más importantes fuentes de información.
La empresa está interesada en hacer cuanto esté en su mano para favorecer y canalizar la creatividad de sus colaboradores y optimizar la comunicación entre ellos.

La persona equipada para trabajar y comunicar en red tiene tendencia a convertirse más en un socio (interno o externo) que en un asalariado de las empresas que buscan flexibilidad y competitividad.
Su autonomía, su capacidad de trabajo y su rapidez de reacción son muy superiores a las que permiten los circuitos de toma de decisiones y los protocolos de la empresa clásica.
En algunos casos, la persona puede incluso convertirse en competidora de aquellas empresas que no evolucionen bastante rápidamente frente a la competencia y la mundialización de los mercados.

La empresa se ha hecho virtual, hecha añicos desde hace algún tiempo entre las manos de sus miembros.
Sólo existe debido a su red de comunicación y al flujo de información que fluye constantemente por todas sus secciones.
La empresa está en todas partes y en ninguna, siempre a la búsqueda de círculos virtuosos y de un mercado potencial más amplio y más provechoso.
El principio es: cero stocks, cero defectos.

Los que no entren en este torbellino no participan en la fiesta y son marginados o excluidos.
En la actualidad, parece que éste es el precio del desarrollo económico y la producción de riqueza.

Figura 2

Imágenes de fractales

Figura 3

La empresa virtual 

El sindicalismo y las nuevas tecnologías de la comunicación 

Frente a estas conmociones, los sindicatos intentan reconsiderar la situación para garantizar mejor su misión de defensa de los trabajadores.

Entre los objetivos de esta misión, los sindicatos deben desempeñar una función fundamental en el mantenimiento o la reconstitución del vínculo social.
Algunos tienen todavía la tentación de condenar el trabajo realizado por medio de computadoras en la empresa, o el teletrabajo a domicilio, en la medida en que contribuyen a aumentar aún más los beneficios de los inversores a expensas de los trabajadores.
Les cuesta aceptar esta herramienta, que tienen tendencia a considerar un instrumento de alineación.
Otras organizaciones más radicales (no sindicales) se lanzan a acciones de resistencia, organizando destrucciones simbólicas de computadoras siguiendo el modelo del movimiento ludita que apareció en la Inglaterra del siglo XVIII.
La computadora es un blanco emblemático, la parte aparente de un sistema tentacular que se ha introducido por todas partes y que ha hecho estallar los valores y las referencias en que se basaba tanto la vida de los trabajadores como la organización de las empresas y los sindicatos después de la revolución industrial.

De hecho, la computadora puede considerarse un fabuloso instrumento para el desarrollo humano y económico.
Igual que los demás interlocutores sociales, los sindicatos tienen necesidad de nuevas tecnologías de la comunicación.

La mayoría de ellos utilizan ya computadoras para el correo, la gestión administrativa y la edición de sus medios de comunicación.

Asimismo, las federaciones y los sindicatos más importantes utilizan computadoras conectadas a las redes de telecomunicación para consultar bancos de datos o intercambiar correo electrónico.
Se trata de tener acceso a textos de leyes, normas y acuerdos internacionales, alimentar la documentación, la investigación y la reflexión necesarias para la elaboración de los documentos de trabajo y obtener las informaciones decisivas para llevar a buen fin las negociaciones con sus interlocutores, que a su vez están muy bien informados.

Los sindicatos tienen necesidad de dominar las nuevas tecnologías de la comunicación para formar a sus dirigentes y sus instructores, es decir, a aquellos que formarán a los sindicalistas del mañana entre los trabajadores jóvenes, una parte creciente de los cuales dispone ya personalmente (en los países ricos) de una microcomputadora conectada a las redes - como dispone también de televisión y teléfono.

Todos los obstáculos que limitaban el uso de las nuevas tecnologías de la comunicación están a punto de desaparecer.

Por lo que atañe a las dificultades de uso y al costo de los equipos, los nuevos sistemas operativos modernos dotados de interfaces gráficos de fácil comprensión y de sistemas de ayuda en línea han hecho que la utilización de las computadoras sea muy sencilla y no requiera ya aprender informática o lenguajes abstractos.
El incremento de la potencia de los microprocesadores y su amplia difusión lleva consigo, por otra parte, un descenso de los precios de los equipos, que así resultan accesibles para los particular res en los países ricos y están al alcance de las instituciones en los países en desarrollo.

Otro obstáculo es el establecimiento de las conexiones telefónicas y sus elevadas tarifas.

También lo es la complejidad de las modalidades y el costo de los accesos a los servidores y a los bancos de datos.
Pero la popularización de Internet gracias a World Wide Web favorece los acuerdos entre los operadores de telecomunicaciones y los servidores comerciales, que ofrecen tarifas interesantes para la empresa e incluso para el aficionado perspicaz.

El correo electrónico y la búsqueda de documentos pueden efectuarse de manera transparente por todo el mundo al precio de una conversación telefónica y el abono de un canon (generalmente poco elevado) al servidor de la instalación a la cual el usuario está conectado.
Las estructuras importantes, como empresas u organismos de interés público, pueden intentar convertirse ellas mismas en servidores de información con soluciones técnicas sencillas, prácticas y económicas.
Se está produciendo la interconexión global del planeta, que prefigura ya esas autopistas de la información que nos prometen para el día de mañana.

Estas herramientas no están únicamente reservadas para el beneficio de las empresas y la pasión de los profesionales o los aficionados perspicaces.
Los trabajadores v los organismos que los representan o participan en su formación pueden v deben apoderarse decididamente de ellas en todos los países.
Existen soluciones incluso en los países menos adelantados.
En el caso de que no existan, deben negociarse con las administraciones nacionales o privadas que rigen las telecomunicaciones, o con los organismos internacionales competentes que pueden ayudar al desarrollo de estos nuevos medios de comunicación.

La actitud de las principales organizaciones sindicales internacionales y la encuesta realizada por el Labour Telematics Centre (Manchester, Reino Unido) en 1990 sobre la utilización de la telemática por los sindicatos ponen de manifiesto que se llevan a cabo prácticas de este tipo.
En su Informe del proyecto preparatorio sobre la organización, la educación y la formación sindical y las posibilidades ofrecidas por la informática y las telecomunicaciones, titulado Telemática: oportunidad y apuesta , publicado en mayo de 1994, el Labour Telematics Center presenta una lista de recomendaciones y propuestas basadas en un enfoque consecuente que parece ir por el buen camino, si bien requiere cierta actualización.
En este ámbito, los proyectos y los productos del sector comercial tienen un ciclo de vida cada vez más corto.

La OIT, y muy especialmente la Oficina de Actividades para los Trabajadores , establece al respecto disposiciones que deberían favorecer la evolución hacia la integración de las nuevas tecnologías de la comunicación con todos sus interlocutores: organismos internacionales, sindicatos y organismos dedicados a la educación obrera y el desarrollo.

El presente número de Educación Obrera quisiera contribuir (en su modesta medida) a la realización de este objetivo.

La mutación de los medios de comunicación 

En las industrias de los medios de comunicación, al igual que en otros sectores, las estructuras tradicionales se adaptan a estas nuevas tecnologías:
las competencias evolucionan y algunos puestos de trabajo desaparecen.
Las empresas que no se adapten están condenadas probablemente a desaparecer.
Aparecen nuevos oficios, pero no se puede decir todavía hoy si el balance de puestos de trabajo es positivo en este sector ni tampoco en los demás.

Cuando las nuevas tecnologías de tratamiento de la información se apliquen a los medios de comunicación cuya finalidad es elaborar la información, estaremos tentados de decir que "se ha rizado el rizo".
Pero ¿se trata del cierre de un círculo virtuoso generador de milagros económicos?
Según algunos observadores: "la economía de lo inmaterial crea valor añadido, potencialmente infinito, puesto que no está limitado por los condicionantes de la escasez material.
EL mercado de datos, ideas e imágenes constituye un gran yacimiento de puestos de trabajo" (Charles Goldfinger, " Le travail dans l'économie de l'immatériel ", Le Monde , 23 de mayo de 1995).

Se habla mucho de la informatización de las industrias de los medios de comunicación tradicionales, pero la aparición del multimedia ya es irreversible.
Todos los soportes tradicionales se ven afectados: la prensa, la edición, la radio, la televisión, las telecomunicaciones.
La microcomputadora permite editar todo tipo de documentos sobre su soporte tradicional, pero sobre todo tiende a integrarlos en un único nuevo soporte llamado «multimedia».

El multimedia es un nuevo medio de comunicación propio de la microcomputadora, que permite combinar en un mismo producto (llamado a menudo «aplicación») imágenes fijas o animadas, textos, sonidos y vídeo.
A petición del usuario se puede tener acceso a cada uno de estos elementos, de acuerdo con unas modalidades preestablecidas por los autores.
Este nuevo medio de comunicación se puede editar sobre cualquier soporte informático con el único condicionante de las características técnicas de cada uno de estos soportes: disco duro, disco flexible, CD-ROM.

El multimedia también se puede editar en línea en las redes locales o, a través de las redes de telecomunicación, en servidores nacionales o internacionales, o también, por ejemplo, en el Internet y su extensión, el World Wide Web .
Se trata de una nueva manera revolucionaria de editar y difundir información v conocimientos.

Así pues, ante nuestros ojos surge una nueva escritura de la que no podemos medir todavía todas las implicaciones y potencialidades.

Las redes de telecomunicación y de televisión tienden a convertirse a largo plazo en la red de la computadora.
Parece que todos los sistemas centralizados de difusión y de información están llamados a sufrir un cambio profundo.
Esta circunstancia afecta tanto a los sise temas de telecomunicación y a las cadenas de televisión como a los grandes sistemas informáticos centralizados.

Los medios de comunicación y la formación 

Esta evolución afecta, por diversas razones, a la enseñanza formal, la formación profesional (inicial o continua) y la formación informal.

Por una parte, es necesario formar a los jóvenes de hoy en el dominio de las herramientas informáticas que tendrán el día de mañana entre sus manos y de las cuales deben poder sacar el máximo provecho.

Por otra parte, es necesario formar a los trabajadores con respecto a los nuevos mecanismos con los que tienen que operar en la actualidad.

Por último, es necesario adaptar los métodos de formación y de gestión de los recursos pedagógicos utilizados para la educación y la formación, formal o informal.
Todas las modalidades de la formación deben de tener en cuenta las nuevas tecnologías de la comunicación para ser más eficaces y adaptarse mejor a la evolución del entorno.

La administración y las actividades relacionadas con la investigación están ya bastante informatizadas en las universidades.
Gracias al descenso de los precios, los estudiantes tienden a equiparse personalmente.
Algunos docentes operan en la actualidad a través de mecanismos informatizados, a veces a distancia.
También las computadoras han hecho su aparición en las escuelas, y su uso tiende poco a poco a generalizarse.
Las bibliotecas y los centros de documentación se informatizan.
Los organismos de formación profesional y las empresas se movilizan poco a poco.
Se habla de empresa aprendiz .
El movimiento se ha iniciado en los países desarrollados y en los países en rápido desarrollo.

En los países en desarrollo y en los más por lores, el movimiento ha empezado de manera bastante desigual.
El ajuste estructural lleva consigo a menudo dificultades económicas y los proyectos de desarrollo comportan cambios de sistema tecnológico.
El dilema de la introducción de las nuevas tecnologías se plantea por temor a las consecuencias tanto en caso de integración como en caso de no integración.
Por lo que afane a la formación, la inversión en nuevas tecnologías debe hacerse por lo menos a nivel de formación de los instructores, mandos e ingenieros.
Pero también son posibles acciones dirigidas a los trabajadores rurales o los pequeños comerciantes.
Los estudios de costos llevados a cabo en Africa o en América Latina, expuestos en Innovations in educational and training technologies , OIT, Ginebra 1991, pág. 128, son a este respecto muy significativos.

Sea lo que fuere, el «dilema» de la acepción de las nuevas tecnologías por el tercer mundo no se plantea en términos dicotómicos - adoptar o rehusar - sino más bien como una asociación entre nuevas tecnologías con miras a ampliar la capacidad tecnológica de un país.
Lo cual no quiere decir que el «dilema tecnológico» esté resuelto.
Sin embargo, la incertidumbre frente a las nuevas tecnologías no se limita a los países en desarrollo, sino que atañen a todo el mundo, porque se desprende de la imprevisibilidad de todos los efectos desencadenados por la introducción acelerada de las nuevas tecnologías (Andràs November, Nouvelles technologies et mutations socio-économiques , IIES OIT, 1990, pág. 168).

SEGUNDA PARTE 

Comunicación y formación 

En su Programa y Presupuesto para el período bienal 1994/1995 , la Organización Internacional del Trabajo señala en el párrafo 70.1, en el marco de su programa principal Formación, lo siguiente:
«Los objetivos generales de este programa principal son los siguientes: adquisición por los trabajadores de las calificaciones que les permitan asumir un empleo libremente elegido y productivo y adaptarse a los cambios en las necesidades del mercado del trabajo; aumentar la eficacia y eficiencia de los sistemas públicos y privados de formación; asegurar la participación de las organizaciones de trabajadores y de empleadores, junto con los gobiernos, en la formulación y aplicación de las políticas y programas de formación; y aumentar las oportunidades para los grupos vulnerables de mejorar sus calificaciones, productividad e ingresos".

Por otra parte, la Recomendación núm. 150 de la OIT, de 4 de junio de 1975, establece: 

En el párrafo 15: 
"Los Miembros deberían gradualmente ampliar, adaptar y armonizar sus sistemas de formación profesional en forma que cubran las necesidades de formación profesional permanente de los jóvenes y los adultos en todos los sectores de la economía y a todos los niveles de calificación y de responsabilidad".

y en el párrafo 17: 
"En los programas de formación debería recurrirse, según convenga, a los medios de comunicación de masas, a unidades móviles, a cursos por correspondencia y a otros medios de autoenseñanza".

Sin duda, en veinte años han tenido lugar importantes progresos en la aplicación de las recomendaciones del párrafo 15, pero desde hace algunos años, con la presión de la crisis, la mundialización de la economía y el ajuste estructural, se han observado avances y luego retrocesos, desviaciones o retrasos en la realización de estos objetivos.
Han aparecido nuevas orientaciones, como la de enfocar la formación centrándola en la empresa, la puesta en marcha de la formación alternativa, la introducción de nuevas tecnologías en la formación, el desarrollo de métodos de autoaprendizaje o la disminución de los presupuestos consagrados a la formación, por no citar más que algunas tendencias.

Por lo que respecta al párrafo 17, se han tomado medidas para aplicar las recomendar clones en la mayoría de los países desarrollados y en los nuevos países industrializados (NPI), bajo la tutela de los estados y/o en colaboración con los organismos de formación públicos o privados.
Asimismo, en los países en desarrollo, los estados han iniciado programas (a menudo en colaboración con las organizaciones internacionales o en el marco de ayudas bilaterales) para construir la infraestructura necesaria.
Pero queda mucho por hacer, especialmente en los países menos avanzados.

Los interlocutores interesados han diseñado, financiado y realizado de consuno los proyectos.
Los resultados han sido satisfactorios, más o menos.
No siempre han estado a la altura de las ambiciones iniciales.
Entre todos los factores que afectan al buen desarrollo de los programas existe uno que no siempre se identifica y al cual casi nunca se hace claramente alusión: el insuficiente dominio de los problemas de la comunicación .

Los que toman las decisiones, los planificadores, los especialistas en formación, los instructores (profesionales u ocasionales) y los expertos en los distintos ámbitos de la enseñanza no son siempre especialistas en comunicación capaces de hacer propuestas globales, coherentes y pertinentes, precisas en términos técnicos frente a los problemas de comunicación planteados por la elaboración y ejecución de los proyectos.

Sin embargo, la educación y la formación implican la creación de protocolos, medios de comunicación, soportes y sistemas cuya definición depende de un buen conocimiento de las modalidades y tecnologías de la comunicación.
Pese a ser un ámbito científico complejo y difuso, se trata de un conjunto de ciencias que ha dado lugar a tecnologías, procedimientos técnicos y enfoques metodológicos cuyo dominio no siempre han considerado necesario los autores de esos proyectos.

Así pues, en un pasado más o menos reciente se proyectaron actividades de formación u operaciones de comunicación no siempre suficientemente adaptadas a las necesidades existentes ni a las poblaciones afectadas.
Se establecieron métodos de formación, aprovechando a veces las tecnologías audiovisuales, sin que las condiciones estructurales locales, económicas, culturales y tradicionales fuesen tenidas en cuenta suficientemente.
En ocasiones, con la mejor voluntad, se transfirieron políticas o modalidades de formación, de los países ricos a los países menos avanzados, sin una adaptación adecuada.
Se crearon organismos de formación a distancia o medios móviles de formación sin un estudio suficientemente profundo de las infraestructuras de comunicación o sin prever el mantenimiento de los equipos a largo plazo.
La lista de carencias podría ser larguísima.

Más recientemente, se ha aplicado el autoaprendizaje en acciones de formación en las que intervienen "paquetes multimedia" (reagrupando soportes escritos, casetes de audio y/o de vídeo y, a veces, disquetes a menudo bien preparados.
Se han desarrollado muchos programas informáticos de enseñanza asistida por computadora que han dado muy buenos resultados globalmente, pero que no han sido aceptados por todos.

Así pues, con la intención de dar respuesta a esta necesidad de «incrementar el rendimiento y la eficacia de los sistemas de formación» y de «seguir la evolución de las necesidades del mercado de trabajo» para contribuir a una mejor utilización de las nuevas tecnologías de la comunicación en el ámbito de la formación, vamos a intentar conocer más a fondo los procesos actuales de comunicación que actúan en la formación, dejando a un lado los aspectos teóricos.
Queremos permanecer lo más cerca posible de las preocupaciones prácticas de nuestros lectores.

Destacaremos los diferentes contextos y soportes que entran en juego en la formación, tanto en sus formas tradicionales como en sus aspectos más modernos.
De esta forma, pondremos de manifiesto los nuevos usos que tienden a imponerse.
Daremos algunas referencias metodológicas sencillas referentes a la producción de documentos y a la definición de los entornos de edición.

Después examinaremos de manera simplificada su aplicación práctica y sus ventajas en la enseñanza y la formación.

Las nuevas tecnologías de la comunicación no deben eliminar sistemática y ciegamente las herramientas y los métodos utilizados tradicionalmente en educación y formación.
Dichas tecnologías vienen a completarlos, siempre que ello sea deseable, posible y necesario.
La mayoría de métodos que requieren las relaciones humanas son insustituibles.
Cualquier cambio debe reflexionarse mucho y someterse a estudio y planificación.

Las diferentes modalidades de educación y formación 

La formación se efectúa a través de medios de comunicación y utiliza unos recursos que llamamos herramientas.
Hoy la formación se beneficia de los nuevos medios de comunicación y las nuevas herramientas.
Las políticas y las tradiciones que presiden la elaboración de los programas y los métodos y la estructuración de los sistemas de formación nos llevan a utilizar métodos y procedimientos de tipos diferentes que podemos representar de la manera siguiente: 

Figura 4

Clasificación de los mecanismos de formación 

En función de los contenidos, las materias o los contextos, la educación y la formación ponen en marcha diferentes actividades, desde las más materiales hasta las más sofisticadas, las cuales tienen por finalidad transmitir conocimientos teóricos o prácticos.
- imitación de un modelo, un maestro o un tutor; 
- escritura y dibujo; 
- expresión oral; 
- visionado de soportes audiovisuales; 
- gestión responsable del aprovechamiento de los diferentes recursos;
- estructuración de los conocimientos; 
- participación y trabajo en colaboración con los colegas; 
- búsqueda de documentos. 


Todas estas actividades no se encuentran necesariamente reunidas en el marco de una formación o una enseñanza, sino que pueden intervenir de forma puntual o continua en función de sus virtudes características que permitan tratar algún aspecto determinado de la operación.

Estas actividades no son escogidas casi nunca por su eficacia o potencialidades específicas.
Se imponen por los condicionamientos económicos, el contexto o la costumbre.

El aprendizaje mediante la imitación y la simulación 

La forma más antigua de aprendizaje es la imitación , que consiste en observar y reproducir tan fielmente como sea posible las operaciones efectuadas por el «maestro».
El nivel de capacitación requerido se alcanza por medio de una serie de correcciones realizadas por el maestro sobre las prestaciones del aprendiz.
Esta forma de aprendizaje, que se efectúa generalmente en el taller de un artesano, también es hoy bastante corriente en la empresa y se completa de manera alternativa con una formación teórica.
En algunos países, este tipo de formación permite alcanzar niveles de capacitación muy altos y darles validez.

Este método práctico es relativamente fácil de aplicar en un entorno artesanal tradicional y muy fácil de adaptar en la empresa.
Presenta muchas ventajas porque enfoca la formación mediante un contacto directo con el entorno de la empresa, el personal y los equipos que el alumno debe dominar sin otra mediación que la del tutor.
Puede dirigirse con altas perspectivas de éxito a poblaciones de bajo nivel.
La persona formada de esta manera queda insertada en la empresa y es operativa de inmediato.
Así pues, el alumno tiene grandes posibilidades de ser contratado al acabar su formación, lo cual representa una ventaja nada despreciable en una época en la que no es fácil para millones de jóvenes encontrar empleo.

La simulación 

Paradójicamente, esta forma de aprendizaje arcaico se presta hoy a uno de los progresos más espectaculares en la aplicación de la innovación tecnológica a la formación.
En efecto, la computadora, que, como ya hemos dicho, es una fabulosa herramienta de simulación de la realidad, cada día resulta más útil para el aprendizaje de los conocimientos técnicos necesarios para la gestión o la dirección de sistemas complejos .

El sistema complejo de que se trate se modeliza en un ordenador con todos los parámetros variables.
La modificación de uno o varios de estos parámetros lleva consigo la modificación de la representación en pantalla del estado de todo el sistema en tiempo real y de manera interactiva.
Así pues, el alumno puede aprender a dirigir el sistema a su manera sin necesidad de movilizar el sistema real - lo que generaría unos costos (enormes en algunos casos) vinculados con el funcionamiento y la interrupción de la producción del sistema real -.
Para la representación de las operaciones que deben efectuarse y los diferentes elementos del sistema puede bastar una cierta abstracción o simbolismo, pero el incremento de la potencia y capacidad de los microprocesadores y las memorias, acompañado de la baja de precios, permite actualmente efectuar representaciones muy realistas que ofrecen al aprendiz más facilidades de uso y un mejor rendimiento cognoscitivo .

Por ejemplo, es posible aprender así a dirigir una central nuclear, pilotar un avión, conducir un tren o un petrolero gigante, dirigir una fábrica de producción de acero o la construcción de un edificio, o administrar una empresa, una ciudad, un hormiguero, la salud de un ser humano, un jardín, o incluso efectuar operaciones bursátiles o quirúrgicas.
En resumen, no acabaríamos nunca de enumerar todo lo que es posible aprender a hacer, de forma bastante fácil y rápidamente, con este tipo de simulación, y que resulta muy difícil por medios tradicionales.

La realidad virtual 

Todavía se ha avanzado un paso más en el perfeccionamiento de este tipo de aprendizaje por medio de la simulación gracias al desarrollo de lo que ahora se llama «realidad virtual» .
Esta tecnología permite simular un espacio en tres dimensiones, mediante la estereoscopia producida por lentes especiales, pero también sobre una pantalla.
EL usuario se encuentra inmerso en este espacio, en el que puede desplazarse manipulando un dispositivo adecuado.
La computadora calcula en tiempo real los pares de imágenes simultáneas que despliega en los lentes que lleva puestos el usuario delante de cada ojo, con lo que éste tiene la ilusión de desplazarse por un espacio llamado virtual que sólo existe en los cálculos de la computadora.

Con esta técnica puede simularse cualquier entorno para las necesidades de formación.
La inmersión del alumno es todavía más completa que ante una simulación en la pantalla y el rendimiento de la formación es más importante.
Los medios necesarios para realizar estas aplicaciones son por el momento relativamente importantes, pero es posible que la situación evolucione muy rápidamente en este sector.

Es bastante curioso que las simulaciones por ordenador den paso a productos derivados en forma de juegos para niños, en "consolas de juego" especializadas o en microcomputadoras.
Editadas en discos flexibles o en CD-ROM, e incluso en línea en las redes de telecomunicación, han hecho posible la aparición de un nicho de mercado muy provechoso, el de las aplicaciones ludoeducativas , mercado en el que han entrado grandes grupos internacionales de comunicación y del que sacan importantes beneficios.
Esta circunstancia ha hecho que muchos observadores prevean un gran desarrollo de este mercado en los próximos años al igual que un gran porvenir.

Asimismo, otros esfuerzos se dirigen a objetivos francamente didácticos.
Hoy es posible adquirir en el mercado, a precios populares productos educativos de formación inicial para el autoaprendizaje de idiomas, matemáticas, ciencias que simulan un entorno a menudo lúdico.
La computadora es un profesor particular incansable que permite al alumno efectuar el recorrido a su propio ritmo, volviendo una y otra vez a los puntos deseados cuando sea necesario.

Si los creadores de la aplicación lo han previsto, es posible el seguimiento del alumno .
Puede registrarse su progresión y el nivel de los resultados.
Si su utilización tiene lugar en el marco de una formación tutelada , el instructor puede hacerse cargo de la situación e intervenir para insistir en los puntos débiles, pero la utilización de estas herramientas de formación puede realizarla de manera libre y espontánea toda persona que tenga una microcomputadora y la motivación necesaria.

Las primeras tentativas efectuadas hace algunos años en este sector con la denominación de "enseñanza asistida por computadora" no tuvieron en su momento éxito comercial.

Además, durante mucho tiempo este tipo de recursos sufrió las consecuencias de este semifracaso.
EL grado de abstracción impuesto por las microcomputadoras y los sistemas operativos de la época, y su falta de ergonomía, no permitían ofrecer representaciones muy realistas y entornos cognoscitivos muy eficaces para los no informáticos.
Durante mucho tiempo, el público ha creído que la utilización de las computadoras estaba reservada para siempre a los informáticos.
Felizmente, va no es el caso.

Nuestros niños están ahí para recordárnoslo, si es que no estamos convencidos de ello.

La llegada de los interfaces gráficos intuitivos y ergonómicos de los sistemas operativos modernos ha propiciado que todos puedan disponer de las funciones fundamentales de la microcomputadora.
La informática ha podido extenderse a aplicaciones de formación más fáciles de utilizar.
Los pedagogos saben muy bien hasta qué punto la visualización de los fenómenos, la representación gráfica de los conocimientos en la pantalla y su estructuración en una forma elaborada con criterios de ergonomía cognoscitiva son puntos fundamentales en el proceso de adquisición y estructuración de los conocimientos .

EL nivel de precios del material informático v de los programas existente actualmente en el mercado permite su utilización con fines educativos, por lo menos a nivel institucional, en todos los países, incluso los más pobres.
Por supuesto, en el caso de estos últimos no se ha alcanzado todavía el objetivo de una microcomputadora por alumno, ya que se está aún lejos de dicho objetivo hasta en los países ricos.
En cambio, es completamente realista (sobre todo en los países más pobres) introducir, cuando sea posible, esos usos para la formación de instructores, ingenieros, administradores, directores de empresa o representantes de los trabajadores.

Los soportes impresos y la publicación asistida por computadora 

El grafismo y la escritura son dos de los medios más antiguos que han llegado hasta nosotros para codificar y representar la realidad.
A lo largo de milenios, pero sobre todo en los últimos siglos, las tecnologías vinculadas a estos medios de comunicación han evolucionado mucho.
El dibujo, el grabado, la pintura, la caligrafía, la literatura y la imprenta se han convertido en artes vivas que despiertan la curiosidad de las masas siempre y en todas partes, y movilizan la pasión de los artistas y de los compradores con recursos.
El descubrimiento de un grabado prehistórico, una pintura rupestre, una lápida de arcilla con caracteres cuneiformes o un vetusto manuscrito antiguo constituye un hecho destacado para la ciencia.

La escritura es el primer procedimiento intentado por el hombre, en el curso de un largo proceso de gestación, para estructurar las informaciones y registrarlas en un soporte fiable que pueda transportarse y que resista al tiempo.
A este respecto, el escrito constituye el soporte predilecto para la educación y la formación desde hace siglos en la mayoría de las regiones del mundo.
Hoy, el dominio del lenguaje escrito y hablado está en la base de cualquier sistema educativo, pese a que poco a poco las virtudes pedagógicas de la imagen y de los soportes audiovisuales tienden a ocupar cada vez mas espacio.

Las herramientas técnicas y los procedimientos de las artes gráficas han evolucionado al ritmo de las innovaciones tecnológicas características que se han impuesto en diversas regiones del mundo a lo largo de la historia.
Los últimos hitos de esta aparición son lo que llamamos el tratamiento de textos y el correo electrónico.
Hace poco la microcomputadora ha destronado a la máquina de escribir, que se había impuesto en las oficinas desde finales del siglo pasado.

El tratamiento de textos 

Existen muchos soportes lógicos en el mercado con las funcionalidades más evolucionadas para realizar las tareas corrientes que facilitan la producción de documentos escritos de manera autónoma.
Enumeremos las funciones que ofrecen estos soportes que permiten producir documentos impresos en un aparato informático.
Distinguiremos las tareas de entrada de datos, elaboración, archivo y salida de documentos.

- incorporación de textos por medio del teclado; 
- incorporación de textos impresos y reconocimiento automático de los caracteres de estos textos digitalizados; 
- incorporación de grafismos y fotografías. 


- configuración del texto; 
- compaginación; 
- acceso en línea a diccionarios de sinónimos; 
- ayuda a la corrección ortográfica; 
- creación de cuadros; 
- creación de hojas de cálculo automático; 
- ilustración gráfica; 
- retoque fotográfico. 


Archivo: 

Cualquier documento acabado se presenta en forma de un icono y/o por su nombre, y puede guardarse en carpetas o directorios en el disco duro de la microcomputadora.
El documento puede también copiarse sobre un soporte periférico de tipo disco flexible (disquete) o cinta magnética.
El acceso al documento puede obtenerse por búsqueda automática, visualización de la jerarquía o manipulación directa de las carpetas por medio del ratón, de acuerdo con las funcionalidades del sistema operativo.

- impresión sobre impresora a chorro de tinta o láser (blanco y negro o color); 
- telecopia directa a partir de la computadora conectada a un modem, tanto para la emisión como para la recepción;
- correo electrónico en redes locales, telemáticas o de telecomunicación. 


Cada programa se caracteriza por la adecuación y la multiplicidad de sus funciones, la rapidez de aprendizaje (lo más próximo posible a un tiempo igual a cero) y la facilidad y comodidad de utilización.
Las características, según el soporte lógico de que se trate, son muy variables.
Se habla de "ergonomía" del soporte, la cual está en función del propio soporte y sobre todo del sistema operativo de la plataforma (es decir, del tipo de microcomputadora) para la cual se ha creado dicho soporte.

La publicación asistida por computadora 

Esta familia de soportes lógicos que sirven para crear documentos escritos o gráficos que pueden imprimirse se denomina «ofimática» o «publicación asistida por computadora» (PAC) .
Su utilización en el ámbito de la educación y la formación contribuye a acelerar y optimizar la producción de documentos escritos , racionalizar su archivo y su búsqueda y facilitar de nuevo su aprovechamiento, lo que permite una capitalización real de los documentos y las actividades.
Estos documentos pueden imprimirse, luego fotocopiarse en la forma adecuada, de manera autónoma, y por último reunirse y difundirse a los usuarios.
Por ejemplo, el presente documento se ha concebido y escrito totalmente en una microcomputadora personal portátil dotada de tratamiento de textos Word 5.1 para MacOS, apto para los diferentes formatos en vigor en la OIT, necesarios para su producción.

Muchas organizaciones que se dedican a la formación, la educación de los trabajadores o la defensa de sus derechos cuentan ya con estos medios para el correo y la gestión contable o administrativa de su estructura.
Cada día los utilizan más para la edición de sus soportes de comunicación internos o externos: actas, informes, discursos, formularios, octavillas, cartee les, folletos de presentación, artículos de prense, boletines periódicos de información, libros o cualquier otro soporte necesario para el cumplimiento de su misión.

Los soportes lógicos de la PAC pueden utilizarse también para necesidades más propias de la formación.
En efecto, el diseño y organización de una labor de formación pueden verse facilitados por la utilización de estos medios.
Partiendo del documento acabado para una formación anterior, podemos volver a aprovecharlo para una nueva formación conservando la misma estructura y la misma presentación, modificando únicamente aquellos elementos que deban modificarse.

La planificación puede definirse como un modelo único y coherente que permite coordinar todos los parámetros necesarios entre diversas actividades simultáneas de formación.
Así pues, las modificaciones debidas a los cambios accidentales o imprevistos pueden tenerse en cuenta de manera casi automática y reflejarse en la planificación general.

Un archivo coherente situado en el disco duro o en cualquier otro soporte de salvaguardia permite el acceso a cualquiera de los documentos en forma casi instantánea.
Algunas partes del contenido o de los módulos elaborados para una formación pueden volverse a utilizar muy fácilmente o adaptarse a una nueva formación, haciendo posible una capitalización real de los documentos y las actividades.

Algunos tipos de ejercicios definidos en las «hojas de cálculo» pueden corregirse automáticamente y sus resultados reflejarse en un cuadro gráfico.
Gracias a ello puede obtenerse de manera muy eficaz la estadística referente a cada alumno.

También existen soportes lógicos específicos de gestión de los alumnos, pero son más soportes lógicos de gestión que soportes lógicos de PAC.

Un soporte escrito de formación bien diseñado, claro, ilustrado y bien presentado y encuadernado con una espiral es mucho más eficaz y fácil de utilizar que una multicopia mal ilustrada, mecanografiada sobre un cliché, impresa y grapada como todavía se ve frecuentemente.
El alumno lo puede utilizar durante el curso, en su casa para los ejercicios o archivarlo como referencia.

Lamentablemente, en algunos países deben contentarse demasiado a menudo con una multicopista;
¡y aun contentos de tenerla!

Por consiguiente, la producción del conjunto de documentos editados para atender las necesidades de información puede optimizarse y armonizarse con la utilización de las nuevas tecnologías.
El resultado es un mejor dominio de la coherencia general de las operaciones y de la imagen interna y externa del organismo.
La incidencia de esta coherencia de la imagen global - que refleja la «tarjeta de presentación» de un organismo o de una tarea de formación es muy importante sobre su rendimiento y no resulta despreciable para el balance global.
Desde el punto de vista económico, pese a que las inversiones iniciales puedan parecer importantes (lo son cada vez menos), las ventajas obtenidas y el ahorro - a menudo a corto plazo - son indiscutibles.

Las prestaciones orales y la presentación asistida por computadora 

Clasificaremos con esta denominación todas las intervenciones que un formador debe efectuar ante un grupo más o menos importante de personas presentes en una sala o quizá alejadas de ella (comunicándose por medio de la televisión o las telecomunicaciones) en el marco de una actividad de formación.
Se trata de cursos, conferencias, presentaciones, reuniones.
Es un ejercicio para el cual el formador (profesional u ocasional) está más o menos preparado y cuya técnica proviene en buena parte de las artes del espectáculo o de la «retórica» (el arte de hablar y argumentar bien en la antigüedad griega).
Algunas personas tienen, naturalmente, más facilidad que otras para este tipo de ejercicio, pero es un arte que puede aprenderse - incluso con la ayuda de las nuevas tecnologías.

Parece que el éxito de una actividad de formación se basa desde siempre y en gran parte en la naturaleza y la cualidad de la relación que el formador consigue establecer con el alumno.
Este hecho depende de la afinidad que exista espontáneamente entre los dos personajes, pero sobre todo depende de la simpatía, el sentimiento de emulación y la autoridad que el formador sea capaz de inspirar a su auditorio.
Si la simpatía y la autoridad no se dan en el encuentro, habrá que intentar paliar esta situación con la seguridad y la confianza.

Un arte difícil 

Este aspecto de la formación es complejo y nada fácil de dominar.
Consiste en tener un buen dominio de sí mismo y de los contenidos que deben transmitirse, pero sobre todo un buen dominio de la relación con los alumnos.
Deben detectarse las necesidades y saber hacerles frente, incluso si no se manifiestan todavía de una manera explícita.
Es fundamental satisfacerlas rápidamente para el buen desarrollo y el éxito de la operación.

AL mismo tiempo, el formador debe organizar el manejo de documentos o recursos didácticos sobre los que apoyará e ilustrará su argumentación.
Si no está bien preparado, no encontrará el buen elemento en el momento oportuno y ello repercutirá negativamente en su exposición.
Este es un punto clave en el arte de dominar este tipo de situación: ser capaz de efectuar una exposición bien estructurada, clara y sin tiempos muertos.
Por todo ello, será de gran ayuda una proyección de documentos impecable (a poder ser, bella y espectacular) que enlace perfectamente con el discurso y con la que el auditorio pueda seguir paso a paso la progresión.
Hoy existen diversas tecnologías muy eficaces para realizar este tipo de prestación.

Las tecnologías audiovisuales permiten proyectar grafismos y titulares con un retroproyector, fotografías con un proyector de día positivas y vídeos con un magnetoscopio v un televisor o con un proyector de vídeo. 
Éstas operaciones se llevan habitualmente a la práctica en algunos organismos dotados de medios importantes que no están al alcance de todos.
EL dominio por parte de una sola persona (aunque esté bastante dotada, como ocurre a menudo con los formadores) de tan nutrido arsenal mientras habla delante de un auditorio no es tarea fácil.
EL retroproyector es ya de por sí una herramienta bastante difícil de manejar para un formador en el curso de este tipo de exposiciones, pero la cosa se complica si a ello se añaden las diapositivas y el vídeo.
Por razones de eficacia, a veces se requiere la presencia de un operador y que el acto se realice en un local con posibilidades técnicas.

La presentación asistida por computadora 

Actualmente, la solución más práctica de estos problemas se encuentra en los soportes lógicos y los sistemas de Presentación Asistida por Computadora o PreAC .
Para ello, el presentador (formador, conferenciante, etc.) prepara en su microcomputadora el contenido de la exposición con la ayuda de su programa favorito de tratamiento de textos, a fin de tenerla a su disposición en la pantalla si lo considera necesario llegado el momento.

A continuación, con la ayuda de un soporte lógico de presentación asistida por computadora dará a los títulos de los capítulos de su discurso y a los puntos fuertes de su argumentación la configuración visual necesaria para adaptarse a la proyección.
Estos títulos 0 frases cortas se combinarán con las ilustraciones gráficas (fijas o animadas), fotográficas e incluso videográficas o sonoras que piense utilizar y que previamente habrá digitalizado y almacenado en el disco duro en forma de fichero informático.
Siguiendo el programa de PreAC de que dispone, podrá incorporarlas en su aplicación, colocarlas en el orden apetecido, reagruparlas, compaginarlas, darles color y montarlas con la multitud de funciones más o menos sofisticadas que le ofrece el programa.

EL presentador podrá proyectar todos los elementos que previamente haya preparado y salvaguardado en forma de fichero único en su disco duro con la ayuda del programa de PreAC.
La proyección podrá desarrollarse en el orden previsto al ritmo continuo deseado, o pasando de una pantalla a otra por medio de una simple pulsación del ratón o de una tecla.
Ello se consigue conectando una computadora (de poder ser portátil) a un tablero de proyección de cristal líquido por medio de un retroproyector .

EL resultado será todavía mejor si en el equipo con el que se desarrolla la intervención figura un proyector de vídeo especialmente adaptado a la proyección informática, denominado habitualmente proyector multimedia .
En este caso, la calidad de las imágenes y la comodidad de la proyección serán excelentes, y la exposición será tanto más coherente y eficaz.

La presentación podrá modificarse con mucha facilidad en función de las necesidades, enriquecerse paulatinamente e incluso, en caso necesario, registrarse directamente de la computadora a un casete de vídeo siguiendo el tipo de sistema y el soporte lógico de PreAC de que se dispone.

Si la grabación se hace en vídeo, no puede esperarse la misma calidad de lectura del casete de vídeo que de la pantalla de la microcomputadora, especialmente por lo que se refiere al resultado de letras y grafismos con características que no pasan muy bien en el televisor, por lo menos con los equipos de vídeo disponibles en la actualidad.

Los soportes audiovisuales y el sector audiovisual asistido por computadora 

Desde sus orígenes, la película cinematográfica se ha utilizado para grabar la realidad y analizarla desde un punto de vista científico.
Incluso se puede afirmar que se ha inventado para esto.
Los primitivos inventos de Marey y Muybridge servían para estudiar el vuelo de los pájaros y el ritmo de la carrera del caballo y del hombre.

La vocación educativa del cine y luego de la televisión se ha aprovechado mucho en el contexto de la formación, pero los aspectos lúdicos de estos dos medios de comunicación, y sus llamativas carreras como medios de diversión de masas, contradicen un poco sin duda su primera vocación.
Frente a los mastodontes económicos que son las películas de gran espectáculo, frente a los concursos televisivos, los talk shows y las informaciones o los culebrones, el documental sigue resistiendo y existiendo, aunque no sea un género muy popular, pese a que tiene un público importante.

Sin que su uso se haya extendido demasiado en la comunidad de profesores y formadores, las películas captadas en directo de un canal de televisión, grabadas en casete, o incluso sacadas de la mediateca del establecimiento, han acabado por encontrar un pequeño «nicho» en el universo de la formación, pese a todo.
Por otra parte, resulta extraño que en la formación de los instructores el lenguaje audiovisual no se aborde de manera más sistemática para destacar las virtudes y determinar con precisión los usos más pertinentes en el contexto de la educación y la formación.

El videocasete 

Hoy en día, en el ámbito de la formación el videocasete es el soporte privilegiado de las películas.
La flexibilidad de utilización y la facilidad con que puede copiarse, archivarse y difundirse hacen del videocasete el soporte predilecto.
En cualquier caso, se deben precisar algunos puntos que tienen su importancia.
Cada lectura de un videocasete conlleva un desgaste y una pérdida de calidad, aunque sea pequeña.
La copia de un videocasete VHS sobre otro de la misma clase lleva consigo una pérdida importante de la definición y del color de la imagen y la aparición de "ruidos", es decir, de interferencias.
Además, la imagen y el sonido se graban en forma magnética sobre una cinta y esta cinta se desmagnetiza con el tiempo.
Así pues, los documentos grabados en un videocasete no tienen una gran duración.

La utilización de los videocasetes en el ámbito de la formación se efectúa por medio del visionado integral del documento grabado o el visionado de uno o varios fragmentos sobre los que el formador deberá probablemente volver una y otra vez.
Para ello, en cada una de estas ocasiones deberá rebobinarse el videocasete, operación que requiere cierto tiempo.
A esta circunstancia debe añadirse que los sistemas de referencias de principio y fin de secuencia no son todavía muy precisos.
Todo ello impide el buen desarrollo de la prestación del formador.
Se dice que el videocasete no disfruta de una buena interactividad .
EL aparato de vídeo no proporciona una respuesta instantánea.

Podemos considerar a vuela pluma diversos tipos de utilización del vídeo.
Es un medio ideal para presentar la realidad del funcionamiento o del aspecto de un aparato, de un sistema o de un ámbito particular.
No queremos insistir sobre las películas con finalidad educativa cuya vocación es evidente.
Estas películas, de duración variable, pueden limitarse a la presentación de segmentos específicos de conocimientos.
El contenido puede mediatizarse con un presentador - presente en la imagen o ausente de ella - e ilustrarse con tantos grafismos fijos o animados, secuencias de vídeo, comentarios, efectos sonoros y musicales, títulos o subtítulos como se considere necesario.

Como ya hemos visto en el capítulo anterior, una aplicación elaborada en un soporte lógico de PreAC puede grabarse también en un videocasete.
El sonido correspondiente a la exposición del presentador puede registrarse en un magnetófono y añadirse a las imágenes.

Desde un punto de vista más general, el vídeo permite visualizar en directo en una pantalla o grabar el desarrollo de actividades o prestaciones que se efectúen en el marco de una formación.
Por ejemplo, permite que el formador comente y corrija la manera en que los alumnos efectúan sus ejercicios prácticos.

La exposición del formador ante un grupo de alumnos puede también captarse, proyectarse en un monitor (o en una gran pantalla) o grabarse cuando se considere necesario.
El resultado de una toma de este tipo rara vez puede utilizarse tal cual si no se dispone de importantes medios técnicos (diversas cámaras, control de montaje...) que permitan un montaje en directo (en línea on line )).
De lo contrario, el montaje diferido (no lineal ( off line )) de los diferentes elementos e ilustraciones que correspondan se efectúa después de la grabación en una sala de montaje.
Posteriormente se hacen copias y se distribuyen.

La televisión educativa 

Con medios todavía mucho más importantes, un programa de este tipo podría difundirse a distancia a través de una cadena de televisión .
Pero los medios necesarios para ello son costosos y difíciles de movilizar: muchos técnicos especializados, material de vídeo, material de sonido, iluminación específica, montaje, locales especialmente equipados, red de teledifusión herciana, etc.
Una vez sumado todo, la cuenta resulta bastante abultada.
Además, este tipo de emisión - sobre todo si se trata de la filmación de un curso - no gusta a todo el mundo.

Los programadores de las cadenas generalistas de televisión tienen tendencia a programar este tipo de material durante las últimas horas de la tarde, por la noche o en las primeras horas de la mañana.

Sin embargo, algunas cadenas de televisión se dedican a difundir programas educativos, aunque tampoco en este caso las filmaciones de cursos propiamente dichos son populares.
Con un buen dominio del lenguaje audiovisual y un poco de creatividad es posible presentar contenidos didácticos de manera mucho más atractiva que en forma de curso televisado.
Se trata de proyectar documentales cortos, videoclips o entrevistas ilustradas con secuencias determinadas.
A horas de máxima audiencia, las cadenas de televisión educativa programan este tipo de documentos.
Los cursos propiamente dichos se programan entrada la noche y las personas interesadas pueden grabarlos en videocasetes y luego utilizarlos a su gusto según sean alumnos o formadores.

La transmisión de estos programas educativos por televisión puede realizarse en la red de televisión hertziana clásica, pero desde hace algún tiempo esta red se halla muy saturada en los países desarrollados.
Hoy podemos encontrar programas de televisión educativa en redes de televisión por cable o satélite.

Las redes por cable (cable de televisión coaxial) existen generalmente en las grandes ciudades y se puede acceder a ellas por suscripción.
Ofrecen simultáneamente varias decenas de programas, algunos de los cuales son de tipo educativo.
Las redes por satélite permiten emitir programas generalistas en diversas regiones del planeta, pero algunas difunden emisiones educativas.
Para recibirlas basta captarlas con una antena parabólica adecuada.

La aportación de la informática al video: el montaje virtual 

Naturalmente, también en este ámbito las tecnologías informáticas han invadido la producción de vídeo.
Lo que sólo era posible realizando una inversión en vídeo muy importante, ahora lo es a partir de una configuración microinformática multimedia específica, con un costo considerablemente menor.
Nos referimos especialmente a lo que se denomina el montaje virtual de las películas de vídeo dedicadas a la formación que posean un nivel de calidad suficiente.

Así pues, los documentos necesarios de vídeo, gráficos, fotográficos y de audio se obtienen de manera tradicional sobre sus soportes de origen, tanto si se han producido especialmente para las necesidades del caso como si se han localizado por medio de una búsqueda documental y se han comprado.
Los elementos (o partes) útiles de estos documentos se examinan y se referencian claramente para establecer el diseño final de la película.

A continuación, la configuración microinformática dedicada al montaje virtual permite digitalizar el conjunto de estos elementos para grabarlos en el disco duro de gran capacidad que alberga los ficheros informáticos específicos.
En ese momento puede empezar el montaje virtual, es decir, con la ayuda de un programa de montaje es posible agrupar poco a poco el conjunto de elementos en el orden deseado, ajustando su duración, los efectos de transición necesarios, los títulos y los subtítulos, y los gráficos y las ilustraciones, fijos o animados.

Los comentarios, las entrevistas y los efectos sonoros o musicales adicionales también pueden mezclarse, y ajustarse su duración, acelerar o desacelerar su velocidad, aumentar o disminuir su volumen, etc.
Todas las ideas pueden ponerse a prueba, conservarse o eliminarse tan fácilmente como lo permitan las funciones y la ergonomía de la plataforma y el programa de montaje.

Una vez montada "virtualmente" la película, se archiva en un fichero único, ejecutable en una microcomputadora por medio de un pequeño programa utilitario de lectura.
A continuación, sólo queda grabarla en un videocasete por medio del correspondiente aparato.
Se podrán hacer tantas copias como sea necesario, en cualquier formato de videocasete, sin que el fichero original sufra ninguna degradación.
Además, la ventaja de este método consiste en que se puede volver a intervenir en cualquier momento para modificar uno o varios elementos - para editar una nueva versión, por ejemplo - sin tener que volver a empezar el montaje del principio al final, como ocurre con el vídeo tradicional.
Una vez hechas las copias sobre un casete VHS, se podrá difundir la película por la red elegida.

Esta película podrá también grabarse, sola o acompañada de otros elementos de cualquier clase, en cualquier tipo de soporte informático que dé respuesta a un mercado o a un tipo de utilización determinado, como los soportes CD-ROM, CD-I o CD-Vídeo.
Los soportes de esta clase tienen muchas ventajas en relación con el videocasete.
No hay contacto entre el cabezal de lectura y el soporte, así pues no hay deterioro.

También son mucho más compactos, duran más y gozan de una excelente interactividad.
EL paso de una secuencia a otra es casi instantáneo.

También puede considerarse la posibilidad de que el fichero informático de la película se transfiera a un disco duro de una computadora «servidora» y que esté disponible en línea en una red local o internacional - en autoservicio en el sistema World Wide Web de Internet o en un servicio de pago dedicado a la formación profesional en una red de telecomunicación rápida como la Red Digital de Servicios Integrados.
O incluso en las futuras autopistas de la información, en un servidor de televisión educativa interactivo.

Los soportes multimedia separados o integrados e interactivos 

Tradicionalmente, la adquisición de conocimientos teóricos y prácticos supone el uso de documentos - o materiales - diversos.
Como quiera que la localización de estos documentos puede constituir un obstáculo, el formador indica generalmente al alumno las referencias correspondientes, pero el formador puede verse obligado a proporcionar al alumno estos documentos para facilitarle su acceso y aumentar así las oportunidades de éxito.

A menudo estos documentos ni siquiera existen y el formador se ve obligado a producirlos él mismo.

La prolongación natural de este paso lleva al formador a producir una serie de documentos que facilitará al alumno todo el proceso de adquisición de conocimientos como si se tratara de un método integrado.
Puesto que se necesitan soportes de muchos tipos, es habitual presentar estos documentos concebidos con una finalidad precisa en forma de «paquetes multimedia».

Los paquetes multimedia 

Así pues, el formador y el alumno disponen de una serie coherente de documentos adaptados a sus necesidades.
Por ejemplo, el Centro de Turín ha editado diversos paquetes de este tipo.
Los paquetes multimedia son muy populares, particularmente para la enseñanza de idiomas.
Reúnen en una cajita o paquete todos los documentos necesarios para una actividad de formación: hojas, opúsculos, manuales, diapositivas, transparencias, casetes de audio o vídeo, disquetes, CD-ROM.

Utilizado a menudo en la enseñanza a distancia, el paquete multimedia permite que el alumno progrese a su propio ritmo en la adquisición de conocimientos y, sobre todo, que posea una serie compacta de documentos fundamentales que le son necesarios para efectuar los ejercicios prácticos y atender los objetivos previstos.
Si el paquete está bien concebido, unos pasajes de los documentos pueden hacer referencia a otros y remitir al alumno a hacer pruebas prácticas, funcionando de manera análoga a un hipertexto manual.

Las aplicaciones multimedia y los CD-ROM 

Hoy existen, en las diferentes plataformas de microcomputadoras, muchos soportes lógicos, que podemos denominar soportes lógicos de diseño de aplicaciones multimedia (llamados a veces sistemas autores), que permiten integrar en una misma aplicación una serie de documentos de diversos orígenes previamente digitalizados o creados con la ayuda de otros soportes lógicos, como hemos visto en el caso de los soportes lógicos de PreAC.
Cada uno de estos soportes tiene funciones específicas y un enfoque determinado de este tipo de edición.
Además, permiten crear pantallas que pueden contener textos, grafismos fijos o animados, fotos, sonido y vídeo.

AL iniciar el proyecto es conveniente elaborar un guión que defina el contenido y los posibles recorridos, con el fin de introducir y pasar la aplicación de una pantalla a otra en función de una lógica previamente establecida.
Los botones sobre los cuales el usuario podrá pulsar el ratón de su computadora le permitirán acceder a informaciones que él habrá escogido.
Estas aplicaciones multimedia se caracterizan fundamentalmente por la simplicidad de su utilización, la calidad o la oportunidad de su contenido.
Hoy se pueden encontrar aplicaciones de este tipo editadas en disquetes, en CD-ROM o en línea con servidores telemáticos nacionales o internacionales.
Pueden clasificarse con arreglo a las cuatro funciones siguientes: distraer, informar, formar y promocionar.

Además, los editores de libros añaden un disquete o un CD-ROM a sus publicaciones.
Estos discos repiten en todo o en parte los contenidos de los libros en la forma más o menos elaborada de una aplicación multimedia.
Es una manera de ofrecer al lector otro tipo de recorrido y de acceso a los mismos contenidos.
Se trata de un sistema que permite un enfoque interactivo de los datos en la microcomputadora y la posibilidad de disponer si es preciso del texto y de las imágenes para un uso personal o en el marco de trabajos escolares o universitarios.

Los editores de revistas especializadas en microinformática (que han proliferado en los últimos años) ofrecen casi todos como suplemento disquetes y CD-ROM que repiten en todo o en parte los contenidos reproducidos en "papel" y dan a sus lectores diversas ventajas complementarias.
Por ejemplo, la posibilidad de probar las nuevas versiones de los nuevos programas comerciales - o las novedades - que se presentan en la revista o algunas demostraciones de estos programas.
O incluso la posibilidad de copiar programas y documentos de todas clases: textos, imágenes, sonidos, aplicaciones lúdicas o educativas, ofrecidos por sus autores a título de prueba, ya sea gratuitamente ( freewares ) o pagando una suma modesta si el lector los utiliza ( sharewares ).

Ya hemos dicho que el CD-ROM es un medio privilegiado de difusión de aplicaciones multimedia en un soporte material no lineal ( off line ).
Tiene una capacidad de aproximadamente 600 megabytes.
Es un derivado del CDAudio cuyas características técnicas se fijaron hace diez años.
Primero sirvió para editar datos numéricos o textuales (bancos de datos jurídicos, médicos, económicos, etc.).
Después aprovechó el desarrollo tecnológico de los últimos años para archivar y emitir todo tipo de datos.
Sin embargo, el vídeo que necesita flujos de datos importantes debe comprimirse y el tamaño de la ventana en la que aparece es reducido.

Varios otros tipos de discos compactos derivados del CD-ROM han aparecido en el mercado, como el CD-I y el CD-Vídeo.
El primero, destinado al público en general, permite que el usuario prescinda de la computadora, ya que su lectura la efectúa un programa especializado que se conecta con un televisor ordinario.
Está concebido como una plataforma de lectura de aplicaciones interactivas de tipo ludoeducativas destinadas al público en general.

El segundo procede del CD-I y permite editar aproximadamente una hora de vídeo comprimido a toda pantalla pero con una interactividad reducida.

Está concebido como un soporte de edición de películas en varios discos.

Hoy es posible grabar una aplicación multimedia en un CD-ROM a partir de la microcomputadora en la que se ha creado.
A continuación se puede «llevar» a los diferentes entornos del mercado, y sacar copias y difundirlas.
Esta tecnología evoluciona muy deprisa y están a punto de aparecer nuevos materiales y nuevas técnicas que permiten grabar cantidades de datos mucho más importantes a fin de editar en formato compacto aplicaciones multimedia todavía más ricas y completas.

Los editores de contenidos pedagógicos tradicionales ya se han movilizado para ocupar este nicho y están llevando muchos productos al mercado.
Se pueden encontrar títulos referentes a la enseñanza de idiomas 0 ciencias (física, matemáticas, biología, zoología, medicina, etc.), así como enciclopedias.
El sector de la edición de obras de arte y de la museografía es bastante dinámico.
Algunos títulos de este tipo llegan a venderse ya por decenas de millares de ejemplares.

El CD-ROM presenta varias ventajas atractivas para los editores.
Dejando aparte los honorarios por la elaboración de los contenidos, es muy económico de producir y difundir.
La cadena de copia y difusión del CD-Audio es muy potente y se aplica de igual manera al CD-ROM.
Se pueden acoger en un mismo soporte varias versiones lingüísticas de un mismo producto, incluso si al pasar de una cultura a otra un producto de este tipo debe tratarse diferenciadamente.
Por su parte, el número de lectores aumenta cada año en proporciones muy importantes y, además, este disco fino, ligero, práctico, brillante e irisado gusta, está de moda.

Agencias especializadas han desarrollado aplicaciones multimedia para las necesidades específicas de las empresas o las instituciones.

Estas aplicaciones de formación, presentación, promoción o comunicación externa se editan frecuentemente en pequeñas series de CD-ROM.
Algunas empresas o instituciones están equipadas para editar sus propias aplicaciones multimedia internas.
Generalmente, producen la matriz, que luego confían a una empresa especializada en la realización de copias para la fabricación en serie.

La organización de los documentos y datos 

Generalmente, los documentos se referencian, clasifican o archivan en las bibliotecas de forma que sea fácil volverlos a encontrar.
Desde hace algunos años ha aparecido la noción de mediateca y de centro de documentación.
La mediateca amplía esta función a todos los soportes, y el centro de documentación extiende todavía más la responsabilidad de satisfacer las necesidades del usuario.
Estas estructuras reagrupan en forma material documentos portadores de informaciones y de conocimientos, organizándolos para facilitar el acceso a los mismos.
Desde hace algún tiempo, la informática ha hecho su entrada en este ámbito como una herramienta de gestión de documentos y de búsqueda documental.
Marcaje, fichero, tesauro son palabras que se han incorporado al vocabulario de la informática.

Cuando los documentos ya se han digitalizado, estas palabras cambian un poco de sentido.
Un documento se convierte en un fichero (digital) y en tanto que documento puede marcarse siguiendo una lista de palabras y conceptos (tesauro), pero cada elemento significante también puede ser objeto de marcaje.
Por tanto, unas herramientas informáticas permiten registrar y organizar estos datos de manera que se pueda encontrar automática y rápidamente cada unidad útil.
Estas herramientas son programas que se llaman bases de datos y permiten practicar toda clase de operaciones de búsqueda.
Por ejemplo, en un texto o en un conjunto de textos se pueden encontrar todas las características o circunstancias de una palabra, de un grupo de palabras o de un grupo de palabras excluyendo una palabra determinada.
Asimismo, un documentalista puede describir a partir de los mismos tesauros las imágenes fijas o animadas, pese a que muy pronto éstas podrán describirse automáticamente.

Las bases de datos se crean y se guardan en redes de computadoras, o pueden editarse sobre memorias de regeneración como los CD-ROM y, con medios telemáticos apropiados, son accesibles en línea a partir de una microcomputadora situada a distancia.
La conexión directa a través de un modem es el procedimiento más elemental; la norma y el sistema del Minitel que se ha desarrollado en Francia en el decenio de 1980 es una derivación de este tipo de conexión.
Internet y todos sus sistemas y servicios derivados son todavía mucho más potentes y económicos.
Lo veremos más adelante.

La estructuración de los conocimientos 

En casi todos los ámbitos, el trabajo del alumno pasa también por este proceso, a veces inadvertido, que consiste en organizar en su memoria los conocimientos, los comportamientos y las aptitudes técnicas adquiridos con el fin de poder encontrarlos espontáneamente para aplicarlos.
Esta esquematización de la representación de las ideas se genera durante el aprendizaje, estableciendo relaciones que, partiendo de una unidad de información, remiten a una o varias referencias ya inventariadas.
Este trabajo, que puede efectuarse inconscientemente (o conscientemente), contribuye a fijar las experiencias de manera más o menos eficaz.

En algunos tipos de aprendizaje, la experiencia docente aconseja a veces que el alumno plasme este trabajo personal en forma de fichas de colores que recuperan y esquematizan los conocimientos adquiridos por medio de sistemas de notas y llamadas específicas.
A menudo, el resultado consiste en una serie de documentos complejos bastante hermosos según la creatividad del autor, que frecuentemente es el único capaz de orientarse en ese laberinto.

Siguiendo también este principio, los editores ofrecen fichas para ayudar a los estudiantes a revisar sus exámenes.

Esta actividad del espíritu que consiste en clasificar los hechos y las ideas a medida que se hacen presentes en la conciencia del individuo la practicamos naturalmente en la vida de cada día.

La lectura es quizá la operación en la que se puede observar mejor este fenómeno.
A medida que la atención del lector recorre las líneas, las ideas se encadenan y se estructuran en relación con los esquemas ya adquiridos.
El escrito, por medio de su construcción, debe ayudar al lector a realizar esta tarea.
A ello contribuyen también los gráficos, pues sintetizan en forma compacta y va estructurada los datos y los conocimientos.
La memorización de la forma gráfica es más inmediata y global en la mayoría de personas.

El libro, el hipertexto y el hipermedia 

El libro es el fruto de una tradición producto de una lenta maduración.
Está dotado de unos mecanismos, unos sistemas de estructuración de su contenido que, de tan habituales que se han hecho, no los percibimos.
Un conjunto de referencias que permiten navegar entre las informaciones, encontrar rápidamente lo que uno busca y ser conscientes en seguida de su contenido es la indumentaria que recubre el texto: las tapas, las portadillas, el sumario, el índice, las notas a pie de página o a final de capítulo, las ilustraciones, etc.

Habitualmente, la lectura de un libro no es lineal, muchas veces está hecha de idas y venidas.

Sobre todo en un proceso de aprendizaje.
Cada individuo hace de su lectura una aventura sin precedentes.
Uno empezará por buscar las palabras en el índice para leer los pasa­es en que figuran.
Otro mirará las referencias bibliográficas.

Alguien inspeccionará el sumario, algún otro degustará el texto al azar.

Cada frase, cada idea, cada palabra escrita por el autor se corresponde con la percepción que tiene el lector en relación con sus conocimientos previos.
Esta percepción y su grado de memorización y retención están en función del contexto y de las experiencias del lector y de las relaciones que puede establecer con determinados elementos de su experiencia anterior.
El lector busca y encuentra un sitio para registrar y localizar sus nuevas experiencias dentro de la estructura general de sus conocimientos.

Partiendo de esta reflexión sobre la manera en que las ideas se construyen y se estructuran, unos investigadores que trabajaban sobre soluciones informáticas que permitieran establecer de manera más o menos automática relaciones entre las circunstancias de una palabra en un texto, o todos los conocimientos que tienen relación con ellas, introdujeron el concepto de hipertexto .
De hecho, estos investigadores soñaban con relacionar entre sí todo el saber de la humanidad.

El concepto de hipermedia es un derivado del de hipertexto, pero su proyecto se hace extensivo a todos los medios de comunicación.
En cierta manera, es un hipertexto multimedia.

Hoy existen muchos soportes lógicos que permiten crear aplicaciones de tipo hipermedia en diferentes plataformas, con funciones más o menos sofisticadas.
Algunas aplicaciones multimedia funcionan con el modelo del hipermedia.
Ciertas palabras que figuran en el texto, algunos iconos, determinadas imágenes, pueden presentarse de tal manera que el usuario comprenda que puede accionar sobre ellas para tener acceso a un contenido o un documento conexo.
Es el caso de las páginas desarrolladas en los servidores de World Wide Web de Internet, del que hablaremos más adelante.

Otros programas que funcionan más bien con arreglo al modelo de sistema de gestión de base de datos documental permiten relacionar de forma automática todas las veces que una palabra determinada aparece en un texto, y resaltarla en negritas o subrayarla para indicarle al usuario que de esta manera puede tener acceso a otras informaciones.
Es el caso de algunas enciclopedias multimedia editadas en CD-ROM.

El interés de este tipo de programas es doble.
Por una parte, un autor puede editar un tipo de aplicación multimedia que ofrece funciones de acceso suplementarias y hace la búsqueda o la consulta más rica y fácil.
Por otra parte, desde un punto de vista pedagógico, estos soportes lógicos, cuando son de aprendizaje fácil (como Hypercard o Toolbook), permiten que el alumno configure por sí mismo en forma de hipermedia la estructura de conocimientos que adquiere, lo que constituye una manera de creación especialmente seductora que puede contrastarse con la crítica del formador o de los condiscípulos.

Algunas actividades de formación pueden dar lugar a trabajos de grupo y configurarse para facilitar aplicaciones concebidas y producidas en equipo, que pueden generar intercambios o distribuirse en forma de shareware , o ser publicadas por un editor.

El trabajo en colaboración y las redes locales 

EL trabajo en grupo tiene algunas ventajas, tanto en lo que se refiere a la formación como a la producción.
Las interacciones y los intercambios que tienen lugar entre las personas contribuyen a la mejora de la productividad, la calidad de la producción y la capacitación de los trabajadores.
El trabajo en colaboración hace que los participantes sean más activos y pongan en común sus ideas y el fruto de su labor, y, si el ambiente se presta a ello, la critiquen y enriquezcan.

Para ello es necesario que la comunicación circule fácilmente entre las personas que deben colaborar.
En las estructuras laborales clásicas, los puestos de trabajo son a menudo compartimientos estancos o distantes.
No es fácil hacer caer los tabiques o suprimir la distancia entre las personas si se tiene en cuenta lo indispensables que son estos obstáculos en el ámbito del trabajo clásico.
La persona tiene necesidad de autonomía y calma para concentrarse en su trabajo, pero también tiene la necesidad contradictoria de consultar a los otros miembros del equipo para adaptar, actualizar y sincronizar su trabajo.
Además, los mandos tienen necesidad de echar una ojeada sobre la marcha de los trabajos.
Toda la organización de la estructura laboral descansa sobre la búsqueda de un equilibrio entre estas diferentes presiones para llegar a un compromiso óptimo aceptable para todos.
Este punto de equilibrio caracteriza la cultura de empresa de una estructura.
Algunas estructuras adoptan el espacio abierto, otras los despachos separados.
Se practican todas las variaciones posibles.
La circulación de la información en las estructuras laborales obedece a protocolos muy estrictos y a circuitos exclusivos.

Las modalidades tradicionales de circulación de la información son directas, verbales, por presencia voluntaria (entrevista, reunión, seminario, prácticas, acontecimiento conmemorativo), o por encuentro fortuito en el lugar de trabajo (en los pasillos, los ascensores, la cantina) o fuera del lugar de trabajo.
En las conversaciones telefónicas entre dos o más personas, los interlocutores intercambian sin verse información inmediata.
La información también se intercambia por escrito : circulares, notas de información, boletines, cartas, actas, informes, expedientes, etc. Cada uno de estos usos tiene una connotación muy determinada, corresponde a una necesidad específica de comunicación y contribuye a perpetuar el orden establecido que garantiza la continuidad de la forma y cultura de la estructura.

Las redes una nueva manera de trabajar 

Como ya hemos visto, la introducción de las nuevas tecnologías permite aumentar la productividad a cambio de una revolución en los métodos de producción y la naturaleza del trabajo.
Tanto en las situaciones laborales como en las pedagógicas, la introducción de las nuevas tecnologías de la comunicación permite optimizar el tratamiento y la circulación de la información en función de todos los parámetros deseables.

La introducción en una red a escala local de puestos de trabajo informatizados permite establecer procedimientos de comunicación más eficaces.
Cada individuo puede tener acceso rápido a informaciones que la estructura pone a su disposición.
Con un programa de correo electrónico podrá comunicar informaciones a sus colegas.
EL acceso a estas informaciones podrá ser libre o limitado.
El interés de este tipo de corresponsalía radica en que es instantáneo y no intrusivo, el destinatario puede leer el mensaje y contestarlo, si se encuentra presente y lo desea.
Es una corresponsalía escrita que permite intercambios rápidos que pueden salvaguardarse y archivarse.

También puede haber intercambios mucho más ricos que los mensajes escritos.
Los programas de trabajo en colaboración permiten que los colegas vean el trabajo que uno está realizando: textos, dibujos, e imágenes.
Es la posibilidad de compartir un entorno de trabajo, en una pantalla, con un conjunto de colaboradores determinados, que pueden intervenir para efectuar propuestas o ajustes en tiempo real o diferido.

Alguno de estos soportes lógicos del trabajo en colaboración permiten integrar simultáneamente la visioconferencia con el fin de que los interlocutores puedan oír y ver en la pantalla, en una ventana, la imagen de vídeo del que está dirigiéndoles la palabra.
Estas modalidades de trabajo son independientes de la localización de los colaboradores en una red local de tipo LAN (Local Area Network) o ampliada de tipo WAN (Wide Area Network).

Más adelante veremos que este concepto de trabajo en colaboración se ha hecho extensivo a las conexiones en las redes de telecomunicación.

Las mismas funciones son posibles en un entorno de formación.
Además, los procedimientos de trabajo pueden alternarse o incluso fusionarse con las secuencias de formación en el mismo puesto de trabajo informatizado.
La integración de la formación en la empresa, en el puesto de trabajo o en una sala especializada es una tendencia que se desarrolla rápidamente.
Algunos la llaman la empresa alumno .

Las redes, una nueva manera de formarse 

En algunos organismos de educación y de formación existen mecanismos de este tipo.
EL formador puede ver la pantalla de cada uno de los alumnos e intervenir en su trabajo.
Los alumnos pueden verse inducidos a colaborar, a intercambiar mensajes o, por el contrario, a centrarse en su propia pantalla para efectuar un trabajo personal.

De este modo, el formador puede vigilar o dirigir desde su puesto las actividades de cada uno de los alumnos.
Puede enviar un mensaje a uno de ellos, dar una indicación a otro u observar los progresos de otro más y orientarlo.
Puede dar ejercicios o pruebas y obtener la corrección de los mismos de manera instantánea, integrar los resultados y tener estadísticas de cada alumno para visualizar su progresión.
Todo ello hace posible adaptar el ritmo de la formación al progreso de cada uno de los alumnos.

Contando con los elementos necesarios, este tipo de redes puede configurarse de arriba abajo.
Según las plataformas elegidas, el trabajo para construirlas será diferente.
En algunos casos se parecerá a un juego de construcción.
EL material y los programas serán configurados de manera casi automática, en la lógica que tiende a generalizarse del «plug and play» .
Diversos programas, como los de gestión de red, comunicación, base de datos o hipermedia, pueden servir para definir el entorno de trae bajo y desarrollar los contenidos.
Es una operación que está al alcance de todo pedagogo que se familiarice fácilmente con este tipo de plataforma.

Además, con la práctica, el formador puede adaptar poco a poco por sí mismo el sistema en función de sus necesidades o de las necesidades de los alumnos, y perfeccionarlo.
También se pueden utilizar contenidos didácticos elaborados con las mismas herramientas.
Asimismo, el formador podrá editar y difundir sus contenidos didácticos siempre que lo considere conveniente.

En otras plataformas de concepción menos integrada será necesario ser informático para programar toda la aplicación.
Este es un proceso largo, difícil y poco evolutivo que condiciona la actuación del pedagogo.
Sin embargo, para este tipo de plataformas existen aplicaciones integradas más o menos parametrables que tienen funcionalidades interesantes, sobre las que se pueden desarrollar contenidos, pero que son muy poco adaptables al contexto y a la diversidad de los contenidos disponibles.

Las redes de telecomunicación y las redes de redes 

Las redes de telecomunicación se crearon a finales del siglo pasado, y desde entonces no han cesado de tejer incansablemente su tela de araña alrededor del globo.
La Tierra no hace más que encogerse poco a poco ante este fuerte abrazo.
Las palabras y los escritos surcan el espacio a la velocidad del rayo en forma de números binarios.
Sólo los países menos adelantados, los países subequipados o las regiones deshabitadas escapan relativamente a esta ofensiva.

¿Relativamente?
Sí, porque los satélites geoestacionarios de telecomunicaciones cubren casi todos los rincones de la Tierra y un individuo equipado con el material necesario (que cabe en una maleta) puede telefonear, enviar un fax o conectarse con cualquier red, incluir dos Minitel o Internet, con su computadora portátil, desde el centro del Atlántico o el desierto de Gobi.

En un siglo, las telecomunicaciones han remodelado la superficie de la Tierra o, mejor dicho, la imagen que el hombre se hacía de ella.
AL mismo tiempo, la vida del hombre ha cambiado, toda vez que ahora vive condicionado por la imagen que se hace de la realidad.
Los intercambios de informaciones y de bienes se han acelerado mucho en el interior de los países y a escala mundial.
Las economías que practican esos intercambios son muy dinámicas.

Durante mucho tiempo, la mayoría de los países consideró los sistemas de telecomunicación como infraestructuras estratégicas que los estados debían controlar de cerca para garantizar este servicio público y protegerlo de sus enemigos potenciales.

Servicio público y telemática 

En el pasado, en el ámbito de las telecomunicaciones, los estados no fueron siempre gestores demasiado innovadores.
Bajo su exclusiva tutela, los sistemas de telecomunicación buscaron más la seguridad que la eficacia, pero la calidad y los precios del servicio quedaron en un segundo plano.

Algunos estados, como Alemania y Francia, tomaron conciencia del reto y acabaron por dar a sus administraciones un estatuto de empresa pública que debía mejorar el servicio, pero conservaron el monopolio de las telecomunicaciones.
Estas empresas públicas supieron desarrollar y modernizar las redes, invertir en investigación y hacer un esfuerzo considerable para satisfacer a la clientela.

También se han producido avances significativos en el ámbito de las redes digitales (Red Digital de Servicios Integrados: RDSI) o la telemática.
El Minitel es un ejemplo famoso en Francia.
Gracias a una incitación voluntarista, el Minitel ha permitido el desarrollo de un sector privado de producción de servicios telemáticos en línea.
Se ha hecho muy popular en Francia, pero no ha conseguido implantarse perdurablemente en ningún otro país.
Alemania, Canadá, Reino Unido y otros países han creado también sus propias normas, pero tampoco han conseguido exportarlas.
Es difícil saber si el mercado va a adoptar una norma.
Sobre todo, si se define de manera unilateral con la intención de imponerla lo más ampliamente posible.

Este tipo de servicios telemáticos, basados sobre todo en el texto, los grafismos rudimentarios y unas funciones reducidas, quizá no consigan doblar el cabo del año 2000, aunque se prevea una mejora de la norma para difundir fotografías.
Es una solución cerrada y cara que sólo funcionará en Francia.
Mientras tanto, en el resto del mundo, el Internet está conectando entre sí todas las microcomputadoras en una red de redes planetaria libre, de utilización gratuita y mucho más potente.

La conexión de los miles de servicios telemáticos del Minitel con el Internet podría ser una solución.
Pero el precio de estos servicios y la lentitud y la baja resolución inherente a esa norma restringirán su uso, aunque esta conexión abra a Minitel un mercado mucho más amplio.
En cualquier caso, pese a todos estos problemas algunos servicios pueden tener gran interés para una clientela internacional.

La desregulación, ¿una apuesta de futuro? 

En los países de economía liberal, como los Estados Unidos, las telecomunicaciones dependen del sector privado.
Durante mucho tiempo la sociedad Bell dominó el mercado de manera hegemónica, pero en el decenio de 1980 fue dividida en varias empresas a causa de la ley antimonopolio.
Estas empresas de telecomunicaciones se han convertido a su vez en gigantes de tamaño internacional.
La competencia entre estas empresas ha favorecido la mejora de la calidad y del precio de los servicios.
Desde hace algunos años, determinados estados de tradiciones opuestas se han librado a una privatización completa de sus administraciones o de los operadores de servicios públicos de telecomunicaciones para evolucionar mejor hacia la realidad del mercado en lo que se refiere a tecnología y servicios.
Este fue el caso especialmente del Japón y el Reino Unido.

Hoy, pese a algunas resistencias, la liberalización de las telecomunicaciones está a la orden del día.
Por ejemplo, en la Unión Europea la desregulación de las telecomunicaciones está programada para 1998.

Aunque sigan siendo gigantes con tendencias autoritarias, las empresas desreguladas se verán obligadas a hacer frente a la competencia y a adaptarse al mercado.

Sin embargo, es probable que a los competidores no les resulte fácil crear sus propias redes en un plazo inmediato.

Pequeña genealogía de las relaciones entre las telecomunicaciones y la informática 

Al principio, el telégrafo transmitía mensajes codificados, entre puntos alejados, por medio de secuencias manuales de señales ópticas.
Luego, la electricidad lo hizo por medio de secuencias de variaciones de corriente en líneas eléctricas que codifican los mensajes.
Hacia finales del siglo pasado, el teléfono transmitió el sonido en forma de señal analógica.
Las primeras experiencias de transmisión de imágenes son de la misma época, pero se deberá esperar hasta principios del siglo XX para ver llegar la primera máquina de transmisión de mensajes escritos: el belinógrafo, que es el antepasado de la telecopia (fax), cuyo uso sólo se desarrolló a partir del decenio de 1980.

Entretanto, se había impuesto el sistema del télex, como máquina de escribir telefónica que ha tenido gran importancia hasta que el fax, revisado y corregido por la microcomputadora, lo ha hecho obsoleto.

Conviene destacar que desde la invención del teléfono los observadores y los pedagogos veían en este invento un formidable medio de desarrollo de la educación.
Hoy sabemos que no es en este ámbito en el que se ha desarrollado más el teléfono, pese a que en la enseñanza a distancia se utiliza todavía a veces en determinadas circunstancias para mantener periódicamente el contacto entre el alumno y el instructor, el tutor o la administración.

Redes de cables de cobre se han ido tejiendo poco a poco, y los sistemas de conmutación, al principio manuales, se han automatizado.
En la mayoría de los países, el teléfono se ha impuesto como un medio de comunicación vital que contribuye en gran medida al desarrollo económico y humano.
En los países menos adelantados, los programas de desarrollo o modernización de las infraestructuras de telecomunicaciones figuran generalmente entre los objetivos prioritarios.

Las grandes computadoras se dirigían desde un puesto de trabajo alejado, al cual estaban conectadas.

Las personas que trabajaban en estas computadoras lo hacían desde puestos alejados entre sí, conectados ya a una red.
Desde el decenio de 1960, las redes de telecomunicaciones han empezado a servir para intercambiar datos entre computadoras alejadas entre sí, con la ayuda de modems (modulador-desmodulador) que en la operación de emisión transforman los datos digitales en variaciones de la señal eléctrica en la línea telefónica y hacen exactamente lo contrario en la operación de recepción.

Acababa de surgir la idea de unir las telecomunicaciones y la informática para desarrollar servicios en línea: había nacido la telemática.
Antes incluso del desarrollo de la microinformática, las empresas de telecomunicaciones definían plataformas especializadas y normas para crear estos servicios.
El Minitel, del que va hemos hablado, es una de ellas.
Su lanzamiento permitió el desarrollo de toda una serie de nuevos usos y costumbres de la sociedad.
Por ejemplo, hoy existen varias decenas de miles de servicios telemáticos en Francia desde la guía de teléfonos electrónica hasta las "citas eróticas" pasando por los juegos, los resultados de la bolsa, las reservas de viajes y muchos más.

Algunos han tenido mucho éxito v luego han desaparecido.
Otros han tardado bastantes años en imponerse, como los servicios telemáticos de empresa.

En efecto, las empresas utilizan mucho la telemática en nuestros días con fines comerciales o promocionales.
Algunas firmas presentan sus catálogos de venta por correspondencia mediante una red telemática.
Los compradores pueden escoger y pagar introduciendo su tarjeta de crédito en el terminal.
El uso telemático que seguramente se ha extendido de forma más espectacular en el mundo es la automatización de las operaciones bancarias.
En efecto, hoy, con su tarjeta bancaria, una persona puede efectuar toda clase de operaciones en su cuenta en cualquier cajero automático de su red en todo el mundo, veinticuatro horas al día y siete días a la semana.

Pero, también en este caso, debemos reconocer que las esperanzas que se habían puesto en la telemática como medio revolucionario de formación y educación se han visto hasta ahora defraudadas.
De todas las aplicaciones pedagógicas que se han desarrollado en Francia en soporte telemático, muy pocas han conseguido imponerse.
Sin duda, este fracaso se debe en parte a la naturaleza y calidad de las aplicaciones que se han creado, pero también al mismo soporte, que se basa en una resolución de visualización del texto y el grafismo demasiado rudimentaria y a la lentitud y la interactividad mediocre de esta norma.

Aunque mejore su calidad permitiendo la visualización de fotografías, parece que ya es demasiado tarde para las normas cerradas.

Evolución de la telemática 

Mientras tanto, las microcomputadoras estaban en auge, las plataformas que conocemos en la actualidad se imponían poco a poco en el mercado con sistemas operativos de fácil utilización y se publicaban uno tras otro programas de aplicación en todas las esferas del tratamiento de la información y la comunicación.

Simultáneamente, las capacidades de comunicación de las redes telefónicas se ampliaban con nuevos modems más potentes, mientras que Minitel evolucionaba poco.

Programas de emulación de la norma Minitel se pueden utilizar en todas las plataformas de microcomputadoras conectadas a la red telefónica mediante un modem.
Dichos programas permiten acceder a cualquier servicio telemático creado para la norma Minitel.
La microcomputadora hace las funciones de un terminal de Minitel mucho más evolucionado de más fácil funcionamiento y más práctico.
Además, los datos consultados en los servicios telemáticos pueden salvaguardarse y volverse a utilizar en otras aplicaciones.

También existen otras redes privadas para microcomputadoras que no se acogen a la norma Minitel: son los servidores telemáticos a los cuales el usuario debe suscribirse para obtener una dirección que le permita comunicar con todos los miembros de la red, participar en foros para intercambiar informaciones, transferir programas o tener acceso a Internet.

La microcomputadora se ha convertido en una herramienta de comunicación universal en línea (on line) en las redes o no lineal (fuera de línea, off line ).
En su opción no lineal, ya hemos visto rápidamente sus múltiples recursos para la edición de soportes.
En la opción en línea, en redes LAN, teléfono o cable de TV, dotada de un programa adecuado, puede conectarse directamente con cualquier otra computadora aislada y accesible (es decir, conectada a la red y en funcionamiento).
Entonces, las dos microcomputadoras pueden intercambiar cualquier fichero: un fax, un mensaje electrónico, ficheros gráficos, fotografías, sonidos o vídeo.

También pueden intercambiar ficheros de vídeo y sonido en tiempo real para posibilitar una conversación visiofónica.

En estas condiciones, también puede conectarse a distancia con cualquier red local (LAN o WAN) de computadoras.
Los programas de conexión, los soportes lógicos operativos y sus extensiones que gestionan el intercambio de datos a través de normas de comunicación (como la H320 o la H261) hacen posible la comunicación entre plataformas diferentes distantes entre sí.
Incluso permiten la visioconferencia entre plataformas diferentes en redes heterogéneas (que reúnen plataformas distintas) y a distancia en la red telefónica clásica o la RDSI.

El fenómeno de Internet 

El éxito mundial de Internet permite confirmar hoy la universalidad de la microcomputadora como herramienta de comunicación.
Toda microcomputadora dotada de los soportes lógicos adecuados, si se conecta por medio de la red telefónica a un servidor (red local conectada a su vez a Internet), puede acceder a una serie de recursos puestos a su disposición en Internet por todos los organismos o personas que lo desean y lo deciden libremente.
A la inversa, cualquier microcomputadora conectada a una red puede convertirse en servidor en Internet si cumple determinadas modalidades técnicas.

La visiofonía y la visioconferencia son posibles en Internet gracias a soportes lógicos como el de la Cornell University y el CU-SeeMe, que están disponibles y pueden cargarse gratuitamente.

El sonido de la conversación tiene una calidad suficiente y la resolución de la imagen está en proporción con el rendimiento (aproximadamente una imagen cada cuatro segundos).
Todas estas conexiones con Internet se hacen al precio de la tarifa de las comunicaciones telefónicas entre los usuarios y sus servidores (a ello se añade el canon pagado al servidor), independientemente de la distancia que separa a los servidores.

Internet es una red que se creó hace veinte años en los Estados Unidos para las necesidades de la investigación científica de carácter militar.
Su objetivo era conectar redes de plataformas heterogéneas que trabajaban con el sistema operativo Unix para que pudieran comunicarse entre sí.
Por eso se dice que es una red de redes .
Internet se define por el protocolo TCP/IP (Transmission Control Protocol / Internet Protocol).

En Internet, cada computadora tiene una dirección específica que permite que los otros miembros de las redes conectadas entren en contacto con ella.
De esta forma se pueden intercambiar mensajes electrónicos, participar en foros de información temática (newsgroups) , enviar documentos, importar ficheros por medio de Telnet y FTP (File Transfer Protocol) o explorar la red con la ayuda de sistemas de búsqueda documental como Archie, Gopher, WAIS, o el famoso World Wide Web.
Este último sistema fue creado en un principio por investigadores científicos para resolver sus propias necesidades, pero primero los estudiantes y luego los dirigentes de empresa se apoderaron de él.
No pertenece a nadie y su expansión es espectacular.

Por su concepto de la libertad, su gratuidad de uso y sus diferentes funcionalidades de búsqueda que permiten un acceso a la documentación cada día más fácil, Internet está prefigurando la red mundial de intercambio de información del futuro.
World Wide Web (creado por el CERN en Ginebra) permite una búsqueda de tipo hipermedio en todas las informaciones disponibles en Internet, pulsando simplemente el ratón sobre las palabras o los iconos, sobre todo gracias a algunos soportes lógicos de navegación como Mosaic o Netscape.

Las autopistas de la información 

Las redes físicas que pueden conectar con Internet son heterogéneas (diferentes redes telefónicas, LAN, WAN), algunas son rápidas y otras son lentas, pero el conjunto funciona bien.
La mejora del soporte físico ayudará al desarrollo de Internet pero no lo sustituirá.

Internet es una red inmaterial basada en una lógica con objeto de difundir información.
Los diferentes proyectos llamados «autopistas de la información» son proyectos de instalación de redes físicas que pretenden conectar la gran mayoría de la población de los países ricos a una red de comunicación de gran rendimiento.
Esta conexión debe hacer posible la presencia de hasta quinientos canales de televisión interactiva en el domicilio de los consumidores.
EL modelo de Internet es diferente del de estas autopistas, donde la información circula sólo en un sentido y el usuario es pasivo y se desliza por la red haciendo zapping de un servicio a otro.
La lógica de Internet supone que el usuario busca una información precisa o tiene alguna cosa que decir.

La cumbre del G7 celebrada el 26 de febrero de 1995 en Bruselas postuló ocho principios clave para el desarrollo de estas redes.
- promoción de una competencia dinámica; 
- estímulo de la inversión privada; 
- definición de un marco reglamentario adaptable; 
- interoperatividad e interconexión de las redes; 
- acceso abierto a las futuras autopistas para los proveedores de servicios; 
- igualdad de acceso para todos los ciudadanos; 
- fomento de la diversidad de contenidos (incluida la diversidad cultural y lingüística); 
- reconocimiento de la cooperación mundial, con atención especial a los países en desarrollo. 


- educación; 
- formación; 
- bibliotecas; 
- museos y galerías electrónicas; 
- gestión del medio ambiente y de las catástrofes naturales; 
- salud; 
- gestión de la información gubernamental y administrativa; 
- información comercial de las PYME. 


De momento, los diferentes proyectos de autopistas de la información a base de fibra óptica que se anuncian en los Estados Unidos, en Europa o en Japón proclaman bastante abiertamente sus intereses mercantiles.
La finalidad que confiesan perseguir es aumentar el rendimiento de las redes con el fin de transportar más rápidamente mayores cantidades de información y permitir en especial la transmisión de programas de vídeo interactivos en tiempo real a todos los hogares.

Las redes de telecomunicaciones que existen actualmente aún no se explotan al máximo de su capacidad.
Por ejemplo, existen en Europa redes digitales muy eficaces, una parte de las cuales son de fibra óptica, pero frecuentemente están infrautilizadas por una gran parte de sus usuarios potenciales que no las aprovechan debido a unas tarifas consideradas demasiado elevadas.
Además, las redes de hilo de cobre servirán todavía durante muchos años, tanto más cuanto que la tecnología ADSL (Asymmetrical Digital Subscriber Loop) que se está experimentando actualmente permite hacer transitar por la red telefónica actual en un solo sentido 8 megabytes por segundo.
Con este rendimiento se pueden recibir simultáneamente a domicilio dos emisiones de televisión, mantener una conversación telefónica y efectuar una conexión con Internet.
Sin duda, surgirán otras utilizaciones que ni siquiera podemos imaginar.

Internet y la formación 

Según un estudio de 1993 realizado por la Computer Technology Research Corporation (Estados Unidos de América), un 47 por ciento de las computadoras conectadas a Internet lo estaban con fines educativos.
En efecto, Internet es una herramienta ideal de búsqueda documental para los estudiantes y de comunicación entre los investigadores.
Pero en adelante parece que Internet esté llamada también a convertirse en un medio de comunicación privilegiado para la educación y la formación a distancia.
Efectivamente, varias universidades y organismos de formación públicos o privados ofrecen enseñanzas en World Wide Web de Internet, que es la red más "navegable".
La publicidad de algunas universidades privadas acreditadas califica su campus de mundial y propone a sus alumnos diplomas oficiales: certificados de estudio, diplomas de bachillerato licenciaturas, diplomas de postgrado, doctorados en muchas materias.

Algunas universidades especializadas desde hace tiempo en la enseñanza a distancia, por ejemplo la Teleuniversidad de Quebec en el Canadá, o la Open Universidad Abierta del Reino Unido, utilizan ahora el Internet y el World Wide Web simultáneamente con otros soportes.
La versatilidad de sus usos, la universalidad y la libertad de acceso, su carácter de hipermedia mundial, la ergonomía de sus programas de navegación y la discreción de sus tarifas (distintas según los contextos económicos o administrativos, las regiones o los países) hacen de World Wide Web un soporte privilegiado para la formación profesional continua y la educación convencional.

Paradójicamente, el mayor inconveniente de Internet es al mismo tiempo su mayor ventaja: su libertad.
Cualquier persona puede crear un servicio.
Por ejemplo, en Francia, cuando apareció el Minitel, que sin embargo está sometido a una gran vigilancia, la administración no pudo impedir el desarrollo de redes de carácter erótico.
En teoría, todo es posible en el Internet, incluso contenidos perjudiciales para los niños.
Es un problema importante al que hay que buscar solución para dar una oportunidad a la educación, pero básicamente no es diferente del problema que representa el acceso de los jóvenes a documentos especializados utilizados por los adultos, como las revistas pornográficas y algunas emisiones de radio o televisión.

Otro problema que se invoca a menudo es la profusión de información en el Internet.

Ahora bien, ¿cuándo hay demasiada información?
Se trata de un problema de búsqueda y gestión de la información.
Uno se puede cansar mucho antes de encontrar la respuesta correcta a una pregunta, pero sin duda hay más posibilidades de encontrarla en Internet.
Además, ya han aparecido en el mercado algunos servicios o programas de ayuda para la búsqueda más o menos automatizada en Internet (programas llamado "agentes inteligentes").
Sea como fuere, no hay duda de que la conexión con la red permite compartir conocimientos, repartirlos mejor e impregnar más profundamente las organizaciones.

Las herramientas técnicas 

La descripción del sistema tecnológico en el que hemos entrado puede esquematizarse de la manera siguiente.

Figura 5

Esquema del sistema mediático

Ahora vamos a examinar los sistemas y las redes materiales de tratamiento y gestión de la información .
Este nivel reúne todos los elementos físicos y también los lógicos que están asociados a aquéllos.
Se refiere a todo lo que sucede dentro de una computadora, tanto si es producto de la conexión de entrada como de la de salida con sus elementos periféricos.
Tal como ya hemos visto en el capítulo anterior y como vemos en el esquema de la figura 5, la computadora está en el corazón de los sistemas que tratan y gestionan la información.

Pequeña historia de la microcomputadora 

Es ya casi una leyenda que las microcomputadoras fueron inventadas en el garaje de sus padres por unos estudiantes geniales salidos apenas de la universidad, a finales del decenio de 1970.
Pero éste fue realmente el caso de Steve Job y Steve Wozniack, fundadores de la sociedad Apple (Estados Unidos de América), una de las primeras en producir y sacar al mercado una microcomputadora y cuya divisa revolucionaria para la época era "una computadora para cada uno".

En aquellos tiempos, las computadoras eran monstruos enormes que costaban fortunas y que sólo las grandes empresas u organizaciones podían permitirse.
Sólo informáticos muy bien pagados sabían utilizarlas, pero la sociedad IBM (Estados Unidos de América), que tenía casi un monopolio del mercado de estas grandes máquinas, creó a su vez, a principios del decenio de 1980, con varios colaboradores e inspirándose en el concepto de una computadora para cada uno, un modelo de microcomputadora denominada IBM PC (PC por Personal Computer).
Una máquina que iba a disfrutar de éxitos diversos.

Así pues, la microcomputadora fue concebida al principio como una máquina personal que podía tenerse en un rincón del despacho del usuario.
Una máquina próxima al hombre, en oposición a la gran computadora centralizada a la que los usuarios estaban conectados a través de una pantalla y un teclado.
Con una lógica que ha resultado irresistible, el usuario se ha hecho más autónomo y puede ahora disponer a su antojo de toda la potencia de tratamiento de su máquina, dentro de los límites de las funcionalidades o las características técnicas de su sistema y su propia capacidad.
No hay que confundir la conexión en red de las microcomputadoras con la red de terminales conectados a una gran computadora.
Si se quiere evaluar las prestaciones de una red, en el primer caso la potencia es un múltiplo del número de máquinas conectadas y en el segundo caso la potencia de la computadora central se divide por el número de terminales.
Hoy podemos decir, simplificando, que estos dos modelos se fusionan en el seno de las redes locales, sobre la base del principio clientes/servidores que examinaremos más adelante.

La irrupción de los clones 

Al principio, la competencia entre todas las normas que surgieron espontáneamente fue muy dura.

La llegada de las PC de IBM contribuyó, muy a pesar suyo, a aclarar un poco la situación.
Como este producto no estaba bien protegido desde el punto de vista legal, muchos fabricantes lo copiaron y se convirtió en una norma de hecho.
Estos empresarios se lanzaron a la fabricación de lo que se denomina clones, es decir, microcomputadoras compatibles con la norma IBM.
EL gigante de la informática intentó querellarse contra los plagiarios, pero no tardó en abandonar esta idea.
La sociedad Intel, que proporcionaba los microprocesadores 8086 (y los que han venido a continuación), y la muy joven sociedad Microsoft, que proporcionaba el sistema operativo (MS-DOS), podían vender libremente sus produce tos a IBM o a cualquier otra empresa, ya que no les ataba ningún contrato de exclusiva.

Apple, IBM y los demás actores del mercado de la época, como Atari o Commodore, intentaron ofrecer resistencia proponiendo innovaciones relativas a la potencia de las máquinas o las funcionalidades de diálogo y al sistema operativo.
Esta resistencia contribuyó a garantizarles una parte del mercado y les permitió desarrollarse paralelamente con diferente fortuna.

Así, Apple Computers consiguió resistir a la proliferación de las PC compatibles con IBM proponiendo su famosa Macintosh, cuyo interfaz gráfico era muy avanzado y ha servido de modelo para otras plataformas.
Entretanto, IBM intentó contrarrestar a los plagiarios lanzando una nueva norma: 
el Personal System (PS), con el sistema operativo OS/2, que era de funcionamiento mucho más fácil que el MS-DOS, pero nada pudo frenar el desarrollo de la plataforma MS-DOS/PC, compatible con IBM.
Tanto más cuanto que la sociedad Microsoft tuvo la buena idea de crear en el MS-DOS una capa de interfaz gráfico, llamada Windows, que podía proporcionar de una sola vez una forma más fácil de funcionar a todos los PC instalados que fueran lo suficientemente potentes para resistirlo.

Una nueva estrategia 

Ante el éxito de Microsoft y de Intel y los fabricantes de clones, a principios del decenio de 1980 las empresas IBM, Apple y Motorola decidieron unir sus esfuerzos para definir una nueva generación de microprocesadores, las PowerPC, basadas en la tecnología RISC, en consecuencia mucho más potentes que las generaciones anteriores.
Así pues, nuevas microcomputadoras muy potentes que aprovechan esta nueva tecnología han salido al mercado recientemente: las PowerMAc de Apple y algunos servidores de IBM.
Ahora, su potencia les permite adquirir una compatibilidad de soportes lógicos que puedan ejecutar de manera satisfactoria la mayor parte de los programas para MS-DOS y Windows, además de los programas para Macintosh u OS/2.

Otra opción para que las Macintosh obtengan una compatibilidad con la plataforma PC consiste en equiparlas con una tarjeta de extensión que integra un microprocesador Intel que las hace completamente compatibles con toda la gama de aplicaciones escritas para las PC compatibles con IBM, o cualquier otra compatible.
Por otra parte, Apple ha decidido ceder a las presiones que hacía tiempo sufría por parte de empresas que querían difundir su tecnología, y ha vendido su licencia a empresas que se lanzarán a la producción de clones de Macintosh.
Desde hace poco, varios fabricantes ofrecen compatibles MacOS más baratos.

Por otra parte, el terceto compuesto por las empresas IBM, Apple y Motorola se ha puesto de nuevo de acuerdo para definir una "plataforma de referencia física común" (CHRP, Common Hardware Reference Platform) basada en los nuevos microprocesadores PowerPC.
Muy pronto se ofrecerán en el mercado máquinas que respondan a esa nueva norma común.
Esta nueva plataforma física es compatible con todos los sistemas operativos y, por consiguiente, con todas las aplicaciones que existen.
Los usuarios de esta plataforma podrán trabajar con soportes lógicos que les ofrezcan la máxima comodidad personal y las mayores funcionalidades en el sistema operativo que deseen.

- Las PC (Personal Computer) compatibles con IBM, que son, con mucho, las más numerosas; 
- las PS (Personal System) de IBM; 
- las Macintosh y sus compatibles; 
- las máquinas construidas alrededor del microprocesador PowerPC. 


Próximamente debería aparecer una quinta plataforma de compatibles con la norma CHRP (Common Hardware Reference Platform).

También existen varias plataformas de estaciones de trabajo que funcionan con el sistema operativo Unix.
Son computadoras muy potentes que se parecen por su aspecto exterior a las microcomputadoras, pero que son mucho más caras.
Nosotros no trataremos este tema.

Los sistemas operativos, la ergonomía y el diálogo entre el hombre y la máquina 

Como ya se habrá comprendido, todos los elementos que componen la microcomputadora están regidos por lo que denominamos el sistema operativo.
Este sistema es un programa que define y gestiona la mayoría de las funciones de la computadora.
Define las modalidades del diálogo que el usuario puede tener con la máquina para pedirle que efectúe las tareas que espera de ella.
En los orígenes de la informática, dominar el diálogo con el ordenador era toda una ciencia.
Se tenía que aprender a escribir un idioma con una sintaxis enigmática para que la computadora lo entendiera y pudiera ser útil, cosa que no era fácil.
Afortunadamente, luego las cosas cambiaron.

Hoy, gracias a los sistemas operativos evolucionados que se han creado, una computadora se dirige por medio de un ratón que genera un puntero, es decir, una pequeña flecha en la pantalla.
Se puede hacer pasear este puntero por la pantalla moviendo el ratón por encima de la mesa.

Con este procedimiento, el puntero señala palabras o iconos que aparecen en la pantalla y que corresponden a operaciones que pueden hacerse ejecutar.
Basta con señalar el icono de la operación elegida y pulsar sobre el botón del ratón para seleccionarla, o bien efectuar una doble pulsación para desencadenar la ejecución.
Así pues, los informáticos nos han enseñado a dialogar con las computadoras gracias a un derivado virtual de la punta de flecha primitiva de nuestros antepasados cazadores.
Las computadoras se pueden incluso dirigir hablando, pero éste es otro problema.
Los sistemas operativos y los programas en general se llaman ergonómicos cuando han sido creados en función de las necesidades de los usuarios para hacer su trabajo más fácil y más agradable.

Antes de llegar a esta meta se ha recorrido un largo camino y ha sido necesario romper con el corporativismo de una casta que quería que el trabajo fuera aburrido.
Muchos informáticos creyeron durante demasiado tiempo que serían los usuarios únicos y perennes de das computadoras.

Para dialogar con una computadora, es decir, para pedirle que ejecute una tarea o recupere su resultado, era necesario saber escribir el mismo idioma que la computadora: tenía que saberse informática.

Pero, como ya hemos visto, unos jóvenes iluminados pensaron que todo el mundo debía estar en disposición de usar una computadora y, sobre todo, que era la computadora la que debía aprender a comunicar con su usuario.
Entre el lenguaje de la máquina y el del hombre se debía crear lo que se denomina un interfaz :el diálogo de fácil acceso, cuyo aprendizaje fuera más simple, es decir, tan inmediato e intuitivo como fuera posible.
Además, debía evitarse, incluso, que uno tuviera la impresión de que estaba aprendiendo alguna cosa, fuera lo que fuese.

MS-DOS 

En sus orígenes, la sociedad IBM concibe el Personal Computer y solicita a una pequeña empresa, por aquel entonces desconocida, llamada Microsoft, que le proporcione el sistema operativo MS-DOS (MicroSoft Disc Operating System).
Los fabricantes de clones hicieron estallar las ventas y crearon un verdadero mercado libre de programas para esta plataforma.
Muchos equipos de investigadores, considerándose libres de cualquier impedimento, se lanzaron a la aventura de crear programas de aplicación, a la búsqueda del mercado más amplio posible.
Cada equipo inventaba sus propias soluciones para aprovechar las potencialidades del MS-DOS.
Pero no había ninguna coordinación entre estos diferentes equipos, sino que cada uno de ellos intentaba imponer sus propias soluciones a los demás.
EL usuario era la víctima, toda vez que se veía obligado a volver a aprender órdenes diferentes al pasar de un programa de aplicación a otro.
Un operador medio vivía como algo difícil y desagradable la utilización cotidiana de una computadora.

Para trabajar con el MS-DOS se tienen que escribir órdenes específicas respetando rigurosamente la sintaxis para que la máquina ejecute las tareas que uno quiere.
Son muchas órdenes que deben encadenarse en una sucesión precisa.
EL sistema se parece mucho a la programación informática.

EL MS-DOS es el entorno predilecto de los informáticos.
Dentro de esta lógica, el usuario final debe, en primer lugar, aprender rudimentos de programación y el MS-DOS.
No se le considerará capaz de dominar y armonizar fácilmente por sí solo su entorno de trabajo si no es una persona muy competente.
Aunque el MS-DOS haya evolucionado mucho desde entonces, este sistema operativo ha seguido siendo muy rudimentario en términos de ergonomía hasta que Microsoft diseñó un entorno superpuesto para ofrecer con Windows funcionalidades más fáciles de manejar.

El sistema operativo de las Macintosh de Apple 

La Macintosh se creó en 1984 con el microprocesador 68000 de la empresa Motorola como un sistema compacto y portátil que se hizo célebre, pero lo realmente original, e incluso revolucionario, era su sistema operativo, que la dotaba del primer interfaz gráfico fácil de manejar a base de iconos y el primer ratón.
La Macintosh se hizo popular rápidamente, puesto que cualquier persona podía utilizarla sin conocer nada de informática y sin teclear una sola línea de ningún código.

Además, estaba dotada de programas gráficos muy potentes para la época.
Una tras otra, han ido apareciendo versiones cada vez más sofisticadas, hasta el sistema 7.5 y finalmente el MacOS.

Cuando se pone en funcionamiento la Macintosh en la pantalla aparece la punta de flecha de la que hemos hablado y la simulación de una oficina: el disco duro, el disco flexible y la papelera están representados en cada caso por un icono, es decir, un signo gráfico que se les parece y lleva el nombre (hasta 31 caracteres) que se le haya dado.
Basta con pulsar dos veces sobre un icono de carpeta o de disco para que se abra y aparezca su contenido en una ventana en forma de otros iconos de ficheros o carpetas.
Se puede escoger cualquier fichero o carpeta de la ventana en que se encuentra señalándolo con el puntero y manteniendo apretado el botón del ratón para desplazarlo como se haría manualmente y colocarlo en otra ventana o carpeta, o bien copiarlo en otro disco 0 incluso meterlo en la papelera para borrarlo.
El nombre de un fichero o de una carpeta puede cambiarse instantáneamente pulsando el ratón sobre el rectángulo en que se halla inscrito, y luego escribir encima el nuevo nombre.
También el icono puede cambiarse y reemplazarse por cualquier grafismo de 32 x 32 pixels.
La barra de menús situada en lo alto de la pantalla despliega todas las funcionalidades ofrecidas cuando se señalan las diferentes rúbricas.
Basta activar con el puntero la función deseada para ejecutarla.

Así pues, todo el funcionamiento de la Macintosh puede dominarse con gestos simples parecidos a los gestos cotidianos.
Desde su origen, esta plataforma se ha basado en el principio "plug and play" .
Este principio significa que la instalación de un nuevo soporte lógico, un periférico cualquiera o una tarjeta llamada de extensión se efectúa simplemente haciendo deslizar con el ratón el icono de un pequeño programa llamado «extensión» sobre el icono de la carpeta sistema, o pulsando dos veces sobre el icono de un programa de instalación.
EL usuario puede hacer lo mismo y no tiene necesidad de recurrir a un informático para ello.

La homogeneidad definida por Apple del sistema operativo y de la microcomputadora hace que esta plataforma sea fiable y sencilla facilite el trabajo de los creadores de programas de aplicación y permita una mayor ergonomía.
Efectivamente, las órdenes y las funciones de los diferentes programas de aplicación figuran con los mismos menús en cascada para las mismas funciones, en la misma forma y sin confundir al usuario, que puede concentrarse mejor sobre el aspecto creativo de su tarea.

En cualquier momento, el usuario, si tiene alguna duda, puede recurrir a una función de ayuda en línea pulsando el ratón sobre el signo de interrogación de la barra de menús y obtiene las respuestas disponibles en una ventana de diálogo o en forma de un bocadillo de historieta que aparece al paso del puntero del ratón sobre los diferentes objetos que figuran en la pantalla.

El nivel de autoaprendizaje en la utilización de MacOS es muy alto.
Desde los primeros pasos, el usuario puede servirse de un programa didáctico muy simpático cuyo icono aparece en la pantalla desde que se pone en funcionamiento y que le enseñará con un método práctico los primeros rudimentos de la utilización de su microcomputadora.
EL usuario puede aprender solo a utilizar su máquina, desde el manejo del ratón hasta la creación y manipulación de las carpetas, los ficheros y los periféricos de almacenamiento, pasando por la puesta en marcha, la desconexión y el redimensionamiento de las ventanas.

Cada nueva versión aporta algunas innovaciones y sus funcionalidades mejoran continuamente.

Es un sistema operativo de fácil manejo cuyas cualidades, funcionalidades y ergonomía han sido reconocidas por todos los especialistas que investigan en el ámbito de la comunicación entre el hombre y la máquina.
Este ámbito se ha convertido en un campo de investigación muy dinámico que reúne equipos pluridisciplinarios: psicólogos, semiólogos, informáticos, ergonomistas, diseñadores, etc .

Sin embargo, al principio, su precio relativamente elevado no permitió una difusión muy amplia, salvo entre algunos no informáticos ricos y algunos creadores.
Poco a poco, al ritmo de su evolución, la Macintosh se ha convertido en una herramienta profesional fiable y fácil de utilizar por impresores, grafistas, músicos, fotógrafos y productores audiovisuales y por los organismos que no querían (o no podían) invertir en la creación de un servicio informático fuerte y pesado.
En la actualidad, a configuración y cualidades físicas iguales, los precios de las distintas plataformas son parecidos.

Windows 

Después de haber vendido MS-DOS a todos los fabricantes o poseedores de clones, la fortuna de Microsoft se acrecentó al haberles sabido proponer Windows, que se presenta como una revisión a nivel ergonómico de todo el parque de entornos MS-DOS a fin de que su utilización dé un salto cualitativo.
Por otra parte, las nuevas funcionalidades ofrecidas por este interfaz gráfico han permitido ampliar todavía más la audiencia y el éxito comercial de ese entorno y penetrar en los hogares, reducto hasta ahora más sensible al enfoque de Apple.
Las nuevas funcionalidades de Windows están más o menos copiadas de las del sistema operativo de la Macintosh de finales del decenio de 1980, pero sin llegar a una ergonomía tan profunda.
Además, la salida de Windows dio origen a un litigio jurídico entre Apple y Microsoft.

En Windows se recogían las ideas de la ventana, la punta de flecha, los iconos y los menús en cascada, pero no se podían desplazar los ficheros manualmente con el ratón para colocarlos en tantas carpetas como fuera necesario o para destruirlos lanzándolos a la papelera.
Para ello se debía recurrir a un subprograma que gestionara ficheros y organizara de manera bastante rígida y poco natural, por medio de la activación de las diversas funciones del menú en cascada, la jerarquía del directorio y la denominación o la destrucción de los ficheros.

Sin embargo, con Windows 3.1 el progreso era muy importante, ya que permitía a todos utilizar el MS-DOS sin conocer bien los códigos de órdenes, así como aplicar un programa fácilmente y salvaguardar y archivar el fichero sin tener que alinear demasiados signos cabalísticos.
Pero los límites del MS-DOS eran todavía muy perceptibles.
Por ejemplo, el tamaño del nombre de los ficheros estaba limitado a ocho caracteres.
Algunas ventanas y sus iconos podían desplazarse, pero no podía eliminarse un fichero, sacarlo de una carpeta para meterlo en otra, etc .

La versión de Windows 3.11 Workgroups presenta funcionalidades interesantes, no sólo para la gestión de las redes locales, sino también para fijar los parámetros del espacio de trabajo.
La versión Windows NT es un sistema operativo multitarea muy potente que es muy difícil de dominar pero que presenta muchas ventajas interesantes.
Por el momento, su carácter complejo no ha favorecido una amplia difusión.

La nueva versión de Windows, « Windows 95» , que se ha presentado en versión de prueba a los profesionales, anuncia por añadidura un gran progreso en términos de ergonomía.
Windows 95 nos promete el "plug and play" , nombres de ficheros con varias decenas de caracteres y otras muchas funcionalidades muy interesantes.
Pese a todo, para ello necesitarán poseer como mínimo un microprocesador Intel 486,15 megabytes libres para copiar el programa en el disco duro y 8 megabytes de RAM.

OS/2 Warp

Como ya hemos indicado anteriormente, la concepción del PS (Personal System) corresponde a un intento de IBM por contrarrestar a los fabricantes de clones que se habían apoderado de las PC y que habían invadido el mercado.
Además, el usuario no conseguía el dominio del sistema operativo del MS-DOS.
Inspirándose en los conceptos desarrollados por Apple y en colaboración con Microsoft (antes de que esta sociedad publicara Windows 3.1), IBM creó el OS/2 (Operation System), un sistema operativo multitarea muy fácil de hacer funcionar y muy potente basado en una configuración de 32 bits.
Sin embargo, esta plataforma de gran calidad no ha tenido el éxito comercial esperado, principalmente a causa de su precio.

La última versión de OS/2, llamada OS/2 Warp, se desarrolla sobre el PS y sobre las PC compatibles con IBM.
Por tanto, el sistema operativo OS/2 Warp se presenta como una altere nativa muy interesante a Windows.
Contiene una serie de programas integrados bien diseñados y muy útiles.
Se facilita mucho la instalación de las extensiones, como el lector de CD-ROM.
Es un sistema operativo multitarea y puede, por ejemplo, hacer desfilar varias secuencias de vídeo al mismo tiempo, cada una en su pequeña ventana.
Contiene las extensiones lógicas necesarias para tratar el sonido y el vídeo si se dispone de los interfaces de entrada y/o de salida necesarios.
Además, acepta la aplicación de los programas concebidos para MS-DOS y Windows.

Sistemas que funcionan con UNIX 

Unix es un sistema operativo y un entorno de desarrollo muy potente que permite efectuar simultáneamente varias operaciones.
Se dice que es un multitarea "verdadero" y "anticipador", es decir, que puede efectuar verdaderamente varias operaciones al mismo tiempo.
Este sistema puede funcionar indistintamente en puestos de trabajo y en todas las plataformas de microcomputadoras.
Es muy popular entre los estudiantes y los investigadores científicos, pero existen muchas versiones específicas y su aprendizaje necesita determinados conocimientos de informática.

La familia Unix se ha impuesto por su universalidad para la creación de Internet.

Gracias en parte a ella, la información puede circular libremente en Internet y pasar de una plataforma a otra sin fronteras.
Por otro lado, ha surgido recientemente Linux, una nueva versión gratuita de Unix muy interesante gracias a una colaboración internacional en Internet.

Principales elementos de la microcomputadora 

Simplificando mucho, diremos que la microcomputadora es una máquina de calcular muy potente y muy perfeccionada que sirve también para crear documentos de todas clases, archivarlos en el disco duro (o en cualquier otro soporte informático), recuperarlos, editarlos, difundirlos y constituir, si así se desea, un banco de datos que pueda consultarse en una red local o telemática.

Para avanzar en la comprensión de este sistema, que a primera vista resulta complejo, vamos a intentar detallar los diferentes elementos que lo componen.

El microprocesador 

Una microcomputadora se caracteriza por su microprocesador, que es el elemento que efectúa los cálculos.
Es una pequeña placa electrónica sobre la que se graban centenares de miles de componentes electrónicos microscópicos.
El número de estos componentes (equivalentes a transistores) que se puede grabar sobre esta placa aumenta continuamente, y en la actualidad ya se ha conseguido grabar varios millones de ellos.
De esta forma, esos microprocesadores son cada vez más potentes.
La frecuencia con que efectúan los cálculos es cada vez más rápida.
Esta frecuencia se mide en megahercios.

Estos microprocesadores pueden procesar las instrucciones de acuerdo con la tecnología a partir de la cual han sido creados: la tecnología CISC (Complex Instruction Set Computer) o la tecnología RISC (Reduced Instruction Set Computer).
La segunda ejecuta las operaciones más rápidamente que la primera, ya que se basa en un número de instrucciones reducido.

Las memorias 

Los datos de las operaciones que deben ejecutarse, así como las correspondientes a los resultados de los cálculos, son almacenados en la memoria viva, generalmente denominada RAM (Random Access Memory).
La memoria viva es otro tipo de placa en la que las informaciones expresadas en bytes pueden grabarse más o menos rápidamente.
En la actualidad, la capacidad de memoria viva permite almacenar de 1 a 64 millones de bytes (de 1 a 64 megabits).
El tiempo en que esta memoria da acceso a la información es muy rápido.
Del orden de 70 nanosegundos.

Generalmente, se puede aumentar la capacidad de memoria viva en la placa base de la computadora para trabajar con aplicaciones más potentes en documentos gráficos o de vídeo de gran calidad.

También existe otro tipo de memoria que está soldada en la placa base de la microcomputadora: la ROM ( Read Only Memory ) o memoria muerta, en la que se cargan las informaciones necesarias para el funcionamiento del sistema que no están incluidas en el sistema operativo.

El disco duro es otra memoria de gran capacidad que puede contener de 100 a 9000 megabytes, o incluso muchos más.
Puede ser externo o interno y sobre él se graban todos los programas necesarios: en primer lugar, el sistema operativo que se carga en la memoria viva desde la puesta en marcha del ordenador y que genera en la pantalla su interfaz gráfico de órdenes y el puntero del ratón.
Luego los programas de aplicación con los que se crearán, editarán y, si así se desea, difundirán los documentos.

Las entradas y salidas 

Los interfaces de entrada, como el teclado, el ratón, el escáner, la tarjeta de digitalización del sonido, la de vídeo, etc., que proporcionan informaciones digitales que se encaminan hacia el microprocesador por medio de circuitos complejos, se materializan en la placa base en circuitos y microplacas que controlan la entrada y salida de los flujos de datos.
Al final del circuito, los resultados aparecen en la pantalla.
EL usuario los graba en un periférico, como el disco duro interno (o externo), un disquete magnético, o magneto-óptico, o una cinta magnética de salvaguarda.
O bien los imprime sobre una hoja de papel o una transparencia.
Si se trata de sonidos o de imágenes elaborados por el sistema, se grabarán en una banda magnética de audio o vídeo, o también pueden proyectarse sobre una pantalla con un proyector de vídeo.

Cada elemento suplementario (impresora, escáner, cámara, micrófono, magnetófono o magnetoscopio, proyector, etc. ) está conectado con la unidad central mediante una conexión llamada "port" o puerto.
Si la máquina no lleva de serie este interfaz específico, suele ser posible generarlo añadiendo a la placa base una tarjeta de extensión adecuada.
EL interfaz de diálogo de entrada y salida con la red telefónica se llama modem ( mo dulador- des modulador).

Visualización de los datos 

La visualización de los datos se efectúa en la pantalla por un sistema que acelera y optimiza la operación.
Este sistema puede presentarse en forma de tarjeta de extensión dotada de un procesador que trabaja a 32 o 64 bits y una capacidad de memoria de vídeo VRAM (Vídeo Random Access Memory) más o menos importante.

Estas tarjetas se conectan a la placa base de la unidad central por medio de una toma cuya norma sea NuBUS, VESA o PCI.
Algunas microcomputadoras incluyen en su placa base todos los elementos necesarios para gestionar la visualización de manera óptima sin necesidad de añadir una tarjeta.
En la visualización intervienen diferentes parámetros: el tamaño de la pantalla, el número de colores, las dimensiones de la imagen y la memoria de vídeo disponible.

La imagen se visualiza en forma de puntos contiguos que se suceden sobre las líneas de la pantalla.
Estos puntos se llaman "pixels" (pictures elements) .

Según el tamaño de la pantalla, la imagen será de: xxx .

Cada pixel puede codificarse en: xxx .

Figura 6

Modelización de la imagen digital

Tabla 1

Tamaño de las imágenes

Dimensiones de la imagen x número de bits = memoria necesaria.

Los buses 

En el interior de la microcomputadora, los datos transitan por un canal que llamamos «bus».

Existen varios tipos: ISA, VESA, EISA, PCM-CIA, NUBUS.

Los más interesantes son aquellos que tienen los mayores rendimientos, como el PCI (Peripheral Component Interconnect) que ofrece hasta 100 megabytes por segundo.

Varios tipos de bus pueden cohabitar en el interior de una máquina según el tipo de tarjetas de extensión que reciban.

Por medio de un conectador de la norma SCSI (Small Computer System Interface) es posible enlazar con la unidad central varios elementos periféricos, como el lector de CD-ROM, el disco duro externo, el lector-grabador de disquetes magneto-ópticos, la cinta magnética de seguridad, etc., si bien este tipo de conectador sólo permite rendimientos inferiores a 2 megabytes por segundo.
Para algunas aplicaciones, como la de vídeo, este rendimiento es insuficiente y entonces se utiliza la norma SCSI-2.

Las funcionalidades multimedia 

Se dice que una microcomputadora es multimedia si puede tratar en la entrada o en la salida ficheros de audio y de vídeo.
Como ya hemos indicado, muy pronto, a mediados del decenio de 1980, la Macintosh permitió procesar el sonido de entrada y de salida.
Unas tarjetas de extensión permitían conseguir, si así se deseaba, que la calidad del tratamiento alcanzase un nivel profesional.
A principios del decenio de 1990, la extensión del sistema operativo llamado QuickTime permitió procesar en lectura el vídeo comprimido en una pequeña ventana, y en entrada mediante varias tarjetas de digitalización.
Luego, algunos modelos de la gama Macintosh o PowerMac fueron equipados de origen para procesar datos multimedia en diferentes niveles de calidad.

La norma multimedia del PS/2 se llama Ultimedia.

Se basa en la tecnología DVI (Digital Video Interactive), desarrollada por Intel, y es la única que en el momento de su lanzamiento ofrecía la posibilidad de tener vídeo y sonido en la pantalla.
Se trata de una tarjeta de extensión que permite tratar el audio y el vídeo en condiciones satisfactorias.

Tabla 2

Normas MPC (MHz = megahercios)

En cuanto a las PC compatibles con IBM, para que los creadores independientes pudieran diseñar tarjetas de extensión multimedia, se publicó la norma MPC por iniciativa del MPC Marketing Council y de muchas empresas del sector, principalmente Microsoft, con el fin de añadir funcionalidades de tratamiento del sonido y del vídeo a las computadoras compatibles con IBM.

Ahora existen muchos kits de adaptación de las PC compatibles con IBM que contienen una tarjeta de extensión, un lector de CD-ROM y soportes lógicos que permiten una instalación más o menos fácil y el aprovechamiento de las aplicaciones multimedia compatibles.
La ausencia de especificación de los puertos en la norma MPC ha favorecido el desarrollo de soluciones caseras que hacen difícil la compatibilidad.
Sin embargo, cada vez más, el puerto SCSI tiende a imponerse como una norma de hecho.
Existen varios niveles de calidad según la potencia del microprocesador empleado.

Sin embargo, modelos de varias marcas compatibles con IBM se han vendido completamente configurados con la norma MPC.
Los destinados al público en general incluyen un lector de CD-ROM y se limitan a tratar el sonido y el vídeo de los CD-ROM.
Otros más potentes están destinados a los profesionales del multimedia y permiten tratar el sonido y el vídeo de entrada y de salida en los soportes elegidos.

Figura 7

Sistema multimedia y soportes digitales 

Examinaremos más adelante las diferentes soluciones que existen para producir aplicaciones multimedia a partir de diversas plataformas.
Ahora vamos a interesarnos por diferentes soportes que pueden utilizarse en el entorno informático para procesar, archivar o difundir los ficheros.

Los soportes magnéticos 

En los soportes magnéticos, la codificación de los datos digitales se efectúa por medio de una modificación puntual del magnetismo del soporte.
Los soportes magnéticos pueden presentarse en forma de cinta o disco.
Las cintas tienen una lectura secuencial, pasan delante de un cabezal lector-grabador fijo y tardan algún tiempo en rebobinarse.
Los discos giran frente a un cabezal lector-grabador móvil y pueden acceder instantáneamente a los datos deseados.
Sin embargo, los soportes magnéticos no son muy fiables, ya que se desmagnetizan accidentalmente por la acción de los campos magnéticos o poco a poco con el paso del tiempo.
Por otra parte, conviene saber que, en principio, a causa del tiempo de rebobinado, las cintas son menos interactivas que los discos.
En forma de cintas encontramos los casetes y los cartuchos.
En forma de discos, los discos duros y los disquetes.

El disquete magnético 

Económico y práctico, es el soporte magnético más popular, el más universalmente difundido.
Esta tecnología ha contribuido mucho a la democratización de la informática.
El disquete de 5 1/4 pulgadas era en sus orígenes el soporte de inscripción de datos de las primer ras microcomputadoras y tenía poca capacidad.
El formato del disco que se ha impuesto es el del disquete de 3 1/2 pulgadas.
Protegido por una cubierta de plástico duro, el disquete magnético puede contener en sus dos caras 744 kilobytes en el formato doble densidad , o 1,44 megabytes en el formato alta densidad .

Ligero y de dimensiones lo suficientemente reducidas para guardarlo en un bolsillo o en un sobre, este disco es el formato ideal que han adaptado todos los grandes editores para la venta de sus programas.
Por supuesto, la relativa limitación de su capacidad constituye un obstáculo, pero el disquete es la norma universal por excelencia para la difusión de los programas.
Ahora todas las microcomputadoras llevan al salir de fábrica lectores-grabadores de estos discos.
Sólo el formato de los bloques varía entre la Macintosh y las compatibles con IBM.
Sin embargo, cualquier disquete de 3 1/2 pulgadas formateado para una PC se puede leer en una Macintosh, gracias a la extensión Exchange PC/Macintosh.

Figura 8

Esquema del lector-grabador de disquetes 3 1/2 

Para finales del año 1995 se ha anunciado un disquete magnético de 3 1/2 pulgadas de una capacidad de 120 megabytes, basado en una tecnología piloto de cabezal lector-grabador y un nuevo soporte magnético con mejores cualidades técnicas.

Las cintas magnéticas DAT(Digital Audio Tape) 

Este tipo de casete magnético de audio es muy utilizado como soporte de salvaguardia para garantizar periódicamente la seguridad de los datos informáticos.
Como en un magnetófono DAT, los datos informáticos se inscriben en la cinta a medida que pasan ante el cabezal magnético, en bloques de tamaño fijo de una dirección.
A petición del usuario, la microcomputadora busca la dirección de los datos requeridos, pero el rebobinado exige cierto tiempo para alcanzar el lugar de la cinta donde se encuentra la información buscada.
En consecuencia, este soporte no ofrece una buena velocidad de acceso a la información y sirve principalmente para archivar grandes cantidades de información (hasta 14 gigabytes).
Los programas de salvaguardia automática en este tipo de soportes son muy prácticos, pues permiten garantizar la gestión de las redes en caso de que le ocurriera algún accidente al disco duro.

Los cartuchos 

Los cartuchos SyQuest, como los cartuchos Bernouilli, son casetes de cinta magnética con sistemas de rebobinado especiales que permiten optimizar el tiempo de acceso y la velocidad de lectura para archivar varias decenas de megabytes (88, 120, 240 megabytes o más).
El cartucho SyQuest está muy difundido en el mundo de la PAC: por ejemplo, permite intercambiar entre los estudios de grafismo y las imprentas grandes ficheros de las maquetas de libros, las revistas y los documentos gráficos.
La fragilidad de estos formatos ha impedido utilizarlos como soportes editoriales, pese a su buena difusión en los medios profesionales.

El disco duro 

El disco duro es un órgano generalmente interno de la microcomputadora.
Es la memoria de regeneración sobre la que se almacenan las carpetas que contienen los documentos, los ficheros correspondientes a estos documentos y los programas que sirven para elaborarlos.
El programa que se quiera utilizar y los datos que tenga que procesar deben cargarse en la memoria viva.
Cuando se ha ejecutado el procesamiento, el resultado se salva en forma de fichero en el disco duro.
Entonces puede editarse en el soporte elegido: papel, disquete...
Así pues, el disco duro no es en principio un soporte de publicación; sin embargo, se puede intentar transportar (con ciertas precauciones) hacia otra microcomputadora, en un disco duro externo, aplicación que es particularmente voluminosa.

Figura 9

Esquema de un disco de gran capacidad

El disco duro externo se presenta en forma de caja que se conecta con el bus de intercambio de datos.

De esta forma puede añadirse al sistema o sustraerse del mismo según las necesidades.
Su versión interna es un módulo que se conecta al mismo bus, pero en el interior de la caja - microcomputadora.

En la actualidad, el disco duro es el soporte de grabación y de acceso a los datos informáticos que ha dado mejores resultados.

Existen discos duros con capacidades de varios gigabytes (millares de megabytes), tasas de transferencia del orden de 10 megabytes por segundo en un bus SCSI 2 y tiempos de acceso a la información de alrededor de 5 milésimas de segundo a precios proporcionalmente muy económicos.
Este disco ha hecho posible el desarrollo de aplicaciones multimedia ricas en imágenes y con visualización a toda pantalla que hasta ahora eran imposibles.
Estas prestaciones pueden todavía mejorarse con la tecnología del apilamiento de discos duros que permite incluso acelerar la velocidad y garantizar la grabación de datos copiándolos en dos discos a la vez.

Los soportes ópticos 

Entre los soportes ópticos, consideraremos principalmente la familia de los Discos Ópticos Compactos, o DOC, que tienen su origen en la definición del formato y la puesta a punto de la tecnología del Compact Disc Digital Audio por Philips y Sony efectuada al comienzo del decenio de 1980.

En principio, los discos de esta familia no son grabables, es decir, que el usuario no puede utilizarlos para grabar en ellos los datos.
Se utilizan únicamente para la lectura, de ahí su nombre de CD-ROM: Read Only Memory.

Hoy, el lector de CD-ROM evoluciona hacia una compatibilidad con la mayoría de los formatos DOC: también lee el CD-ROM XA, el CD-Audio y el CD-Foto.
Si bien la tecnología de copia de estos discos en grandes cantidades no es posible a partir de una microcomputadora, el lector-grabador de los discos ópticos compactos de PCD 200 de Kodak prefigura la evolución en curso.
Este PC graba por unidades los diferentes formatos siguientes: CD-ROM, CD-I, CD-Audio, de acuerdo con la norma ISO 9660, en disco grabable una sola vez e imborrable, y Writable CD (tipo WORM: Write Once Read Many), gracias a programas de formateo adecuados.

Figura 10

Genealogía de los discos ópticos compactos 

Hoy día, podemos encontrar en el mercado muchos lectores-grabadores de este tipo, que permiten editar en DOC, de una en una, aplicaciones acabadas, para atender necesidades internas y también para ponerlas a prueba ante una muestra de usuarios.
En un disco DOC también se pueden archivar grandes ficheros de aplicaciones que ocupan demasiado sitio en los discos duros después de su producción y utilización.
Algunos laboratorios fotográficos ofrecen nuevos servicios a su clientela: la grabación de sus fotos en CD-Foto.

El CD-ROM 

Como ya hemos indicado anteriormente, el CD-ROM (Compact Disc Read Only Memory) está definido en principio sólo para leer.
Igual que el CD-Audio, es un soporte editorial que puede editar alrededor de 600 megabytes de datos multimedia en un soporte muy económico.
La ventaja del CD-ROM en relación con otros DOC es su transportabilidad.

Cualquier contenido editado en CD-ROM puede ser reconocido muy fácilmente por cualquier otro tipo de DOC, ya que todos derivan de su formato.

El lector está dirigido por la microcomputadora a la que está conectado.
Para conseguir una buena utilización se requiere una configuración mínima.
Las necesidades serán distintas según los contenidos, pero nosotros recomendamos o bien una Macintosh con 4 megabytes de memoria viva, que visualice 256 colores como mínimo, o bien una PC con la norma MPC, es decir, con un procesador 80386 y una cadencia de 16 megahercios (o mejor, con un 80486), 4 megabytes de memoria viva, una pantalla con carta VGA de 256 colores, una tarjeta de recuperación sonora compatible con el CD-ROM deseado y Windows 3.1.

Una nueva generación de discos ópticos compactos está recibiendo las especificaciones que le permitan grabar, según la tecnología empleada, de 7 gigabytes (sobre una superficie en formato multimedia CD de Sony-Philips compatible con los CD-ROM antiguos) a 10 gigabytes (sobre dos superficies en formato Matsushita-Toshiba no compatibles con los CD-ROMS antiguos).
Si ahora se pueden grabar setenta y dos minutos de vídeo comprimido en el formato MPEG en un CD-ROM, después será posible grabar más de cuatro horas y media con estas nuevas normas.
Sin embargo, una nueva tecnología de compresión del vídeo del Houston Advanced Research Center (Harc-C) permite comprimir cinco veces más el vídeo.

Figura 11

Esquema del disco óptico compacto 

Los soportes magneto- ópticos 

La tecnología de los soportes magneto-ópticos se basa en el principio de la modificación de la orientación magnética de un punto de la superficie de un disco - fabricado con una aleación de óxidos metálicos -, producida por el calor de un rayo láser concentrado sobre este punto.
Una vez enfriado el soporte, el campo magnético no puede modificarlo.
Esta circunstancia explica que los soportes magneto-ópticos duren mucho y sean muy apreciados para dedicarlos a archivo.
Cuando se trata de leer, el láser se pone en régimen de baja potencia y el rayo lee los puntos magnetizados sin calentarlos.

Comparada con la velocidad de los discos duros, la de los discos magneto-ópticos es relativamente lenta, tanto en grabación como en lectura, debido al proceso de grabación de datos.
Primero se produce una pasada para borrar los datos sobre la porción de disco afectada, luego una pasada de grabación de nuevos datos , y por fin una tercera pasada de verificación de los datos .
Por tanto, no se trata de un disco duro amovible, sino, al contrario, de un excelente soporte de almacenamiento de muy gran capacidad, más rápido que el disquete magnético.

Figura 12

Esquema del lector-grabador de discos magneto-ópticos 3 1/2 

Los discos magneto-ópticos se pueden grabar y borrar como los soportes magnéticos.
AL contrario que los DOC, actualmente no están considerados como soportes editoriales.
Sin embargo, estos discos magneto-ópticos no se consideran baratos, aunque a 0,23 dólares de los Estados Unidos el precio del megabyte grabado la relación sea más bien favorable frente al disquete magnético, que sale a 1,4 dólares de los Estados Unidos por megabyte.

De iguales dimensiones que el disquete magnético de 3 1/2 pulgadas, y apenas dos veces más grueso, el disco flexible magneto-óptico puede enviarse como una carta.
Existe en dos versiones: 128 megabytes y 230 megabytes.
También existen discos con un formato de 5 1/4 pulgadas que pueden albergar alrededor de 600 megabytes.
La presentación en bloques es incompatible con los disquetes magnéticos y los DOC.
Este tipo de soporte ofrece muchas ventajas y debería difundirse ampliamente como memoria de salvaguardia de gran capacidad.

Las redes locales 

Las redes conectan las computadoras entre sí para que puedan intercambiar datos.
Las características principales de una red son: el tipo de cable e interfaz que necesita, su rendir miento (es decir, la cantidad de informaciones que puede transmitir en un segundo), el número de máquinas que puede albergar, el tipo de entorno o los diferentes tipos de entorno que puede gestionar, su costo, la multiplicidad y riqueza de sus funciones, y su fiabilidad.

Las causas del mal funcionamiento de una microcomputadora y, con mayor razón, de una red son múltiples: variación brutal de la alimentación eléctrica, un virus, un conflicto de programas, etc.
Estos accidentes pueden adquirir dimensiones catastróficas si no se salvan con frecuencia los datos procesados y archivados.
Si ocurre un accidente en el disco duro del servidor y no se ha procedido a ninguna salvaguardia, todos los datos de una organización pueden desaparecer irremediablemente y llevar al organismo a una catástrofe fatal.
Si se ha efectuado recientemente una salvaguardia, sólo se perderá el trabajo realizado posteriormente y en algunos casos quizá pueda recuperarse en el disco duro de cada computadora cliente.

EL concepto de red se basa en el principio de que una computadora o servidora colocada a la cabeza de la red gestiona la comunicación entre todas las computadoras clientes de la red.
Generalmente, el servidor es de mayor potencia que los clientes.
EL servidor gestiona la base de datos, la comunicación y el acceso de los diferentes clientes entre sí en relación con las tareas que se les atribuyen.
EL servidor gestiona también la salvaguardia periódica de los ficheros para garantizar una mayor seguridad.
Esta salvaguardia se efectúa sobre el disco duro del servidor, cintas magnéticas DAT o discos magneto-ópticos de gran capacidad.

Existen muchas soluciones para crear redes locales (LAN).
Las más interesantes son las que proporcionan el mayor rendimiento al menor costo y se abren a todas las clases de plataforma.
La tecnología Ethernet que tiende a imponerse en la actualidad proporciona rendimientos de hasta 100 megabytes por segundo según las opciones elegidas y se encuentra disponible en todas las plataformas.
Las tarjetas de extensión de conexión con las redes Ethernet son muy económicas.
Por otra parte, algunas plataformas o modelos de microcomputadoras están equipados en origen con una conexión Ethernet.

Figura 13

Esquema general de una red

La red física está dirigida por un programa que puede trabajar con MS-DOS, Windows, OS/2, MacOS o Unix según la plataforma utilizada como servidor.
Este programa de gestión de redes se aprovecha en principio de las funcionalidades y del interfaz gráfico del sise tema operativo con el que trabaja, pero los programas de gestión de redes confían sobre todo en sus propias funcionalidades.
En primer lugar, las funcionalidades de instalación permiten una puesta en marcha transparente y muy rápida o, por el contrario, larga y penosa.
La eficacia de las funcionalidades de diálogo entre los clientes y el servidor para acceder en seguida a las informaciones frecuentemente utilizadas permiten ganar bastante tiempo.
La sencillez de administrar la red visualizando los procesos en curso, cliente por cliente, permite un mejor control de las operaciones.
Las posibles funcionalidades de integración de la red en el entorno informático preexistente son notables, por ejemplo, en el caso de una conexión a un sistema informático centralizado o heterogéneo.

Algunos programas de gestión de la red tienen la posibilidad de establecer parámetros automáticamente para tener en cuenta la evolución del servidor de la red o para gestionar la distribución de la actualización de los datos en todas las computadoras clientes.
La salvaguardia automática es una funcionalidad interesante, toda vez que, por ejemplo, puede efectuarse de noche por lo que atañe a los datos del servidor.
También lo es en relación con las computadoras clientes, que pueden apagarse después de realizada la operación de salvaguardia.

Los principales programas de gestión de redes son: NetWare de Novell, Windows Workgroup Server y NT Server de Microsoft, que funcionan en las PC compatibles con IBM.
La versión de NetWare 4.1 incluye el soporte de OSl2 y de MacOS, pero este programa está destinado de momento a la utilización compartida de ficheros de tipo texto y se considera poco propicio para las aplicaciones multimedia.
Los programas Workgroup Server AppleShare y PowerShare son las soluciones de Apple.
Citaremos también el programa Workgroup Server 4D de ACI, que integra un sistema de gestión de base de datos, un tratamiento de textos y un programa gráfico, y que puede utilizarse con entorno Windows y MacOS.
Por tanto, el Workgroup Server 4D puede trabajar con las PC compatibles con IBM, las Macintosh o las PowerMac y permite conectar sistemas o redes heterogéneos.

Las funcionalidades de desarrollo de aplicaciones disponibles en estos programas de gestión de redes son muy notables.
No sólo permiten desarrollar aplicaciones que optimizan la gestión o la administración de las empresas, sino que, sobre todo en cuanto al tema que nos atañe, facilitan, si así se desea, la creación de aplicaciones de formación en una red, especialmente interesantes en términos pedagógicos.
Ya hemos mencionado este punto en la sección titulada "Las redes, una nueva manera de formarse".

Las aplicaciones multimedia se pueden compartir en cualquier red física cuyo rendir miento se aproxime a 10 megabytes por segundo.
Cuanto mayor sea el rendimiento, más fluidas y funcionales serán las aplicaciones multimedia.
Ya hemos visto que para la visioconferencia incluso la red telefónica ordinaria permite intercambiar imágenes de vídeo en tiempo real, a una frecuencia que está en función del rendimiento de la línea y del modem utilizados.

Metodología de la producción de soportes 

El mundo de la educación y de la formación no es un mundo cerrado que vive replegado sobre sí mismo, sino que comunica con su entorno y con la sociedad y sus miembros, dejando aparte el hecho de que su finalidad es comunicar conocimientos a los alumnos.
Los organismos de formación deben gestionar consciente, plena y coherentemente su dimensión de comunicación.
Sus acciones o sus operaciones de comunicación deben diseñarse con los medios y competencias necesarios para obtener los mejores resultados posibles.

Generalidades 

¿Qué ocurre en el punto de partida de los intercambios de información que tienen lugar en la transmisión de información y de conocimientos?
Aunque la complejidad de los procesos que intervienen en este tipo de operación no ha podido considerarse desde un punto de vista científico hasta fecha relativamente reciente, las prácticas se remontan a la noche de los tiempos.

Los animales comunican, las plantas y las células también.
La vida es comunicación.

Figura 14

Esquema del recorrido de la información 

Una fuente de información produce un mensaje que se codifica para ser emitido por una "vía".
El destinatario recibe el mensaje, lo codifica y lo integra.
Este escenario de tipo mecanicista se aplica a la mayoría de las situaciones de comunicación.
La transferencia de las informaciones se efectúa de la fuente al destinatario con una disminución de la entropía informativa (la fuente establece orden en el espíritu del destinatario).
El codificador graba en el flujo energético de los medios de comunicación las modulaciones del mensaje que el descodificador traduce para transmitirlas al destinatario.
Se produce un gasto de energía entre el emisor y el receptor a lo largo de la vía de transmisión, con un aumento de la entropía energética (el consumo energético establece desorden en la vía de transmisión).

Factores de orden energético pueden influir en la calidad de la transmisión, como el debilitamiento, la interrupción o los parásitos del flujo energético que transporta la información y que pueden hacerse inherentes a la vía.
Entonces hablamos de ruido .
Así pues, una vía se caracteriza por el ruido que induce, pero también por su banda pasante .
Si la amplitud de las modulaciones del flujo energético que la atraviesan supera el umbral de su banda pasante, la señal queda «descrestada» en sus extremidades y cuando se descodifica no encontramos todas las informaciones.

Factores de orden informativo también pueden perturbar la transmisión del mensaje, especialmente en el momento de la codificación que debe ser objeto de una convención previa entre la fuente y el destinatario, so pena de encontrarse con problemas en el momento de la descodificación.

Esta convención es un código , es decir, una lista de signos .

Todo signo tiene dos caras: la primera es el significante (la modulación que lo graba en el flujo energético), la segunda es el significado (la definición convencional del signo).
Pero a un significante no corresponde necesariamente un solo significado, y a la inversa.
Un signo puede tener varios sentidos, por homonimia (una misma palabra puede caracterizar cosas diferentes) o por polisemia (una imagen puede interpretarse de diferentes maneras en función del contexto o del observador).

Los diferentes tipos de documentos 

A primera vista, los documentos se diferencian por su naturaleza, su origen, su objetivo, su forma y su contenido.
Generalmente se clasifican en función de estos criterios.

También se caracterizan por los soportes tecnológicos que los albergan, los medios de comunicación que los transportan y las aplicaciones que se hacen de ellos.
En el ámbito de la educación y de la formación, los documentos son utilizados con fines de información, formación, promoción o relaciones públicas.

Los clasificaremos en tres categorías: soportes tradicionales, soportes analógicos y soportes digitales.
Por soportes tradicionales entendemos aquellos que se imprimen sobre papel o transparencias v que se utilizan tanto con fines administrativos como informativos para un público muy amplio o con cualquier otro fin.
Los soportes analógicos son los que utilizan las tecnologías así llamadas, "analógicas", que transmiten la información en forma de señal electromagnética modulada.
Es el caso de las técnicas audiovisuales y muy especialmente de los casetes de audio y de vídeo.
Son soportes digitales todos los soportes periféricos de computadora que se han convertido en medios de edición y de comunicación y cuyo desarrollo actual conmociona los métodos de trabajo, de formación y de información.

Los objetivos 

Figura 15

Identificación de un documento 

Algunas generalidades deberían permitirnos enfocar mejor los problemas que se plantean al creador y al productor de documentos.
En primer lugar, como en todo proceso de producción o formación, se trata de identificar correctamente al emisor de la petición, para percibir mejor la naturaleza de la necesidad que este emisor expresa.
La transcripción o grabación, por escrito o en un magnetófono, de una conversación en la que se haga un pedido será útil para elaborar el proyecto.
EL esfuerzo deberá dirigirse hacia la percepción de todos los elementos útiles, incluidos los sobrentendidos en el discurso del emisor, para conseguir todos los objetivos y los resultados esperados de la operación proyectada.

Después de registrar el pedido, el creador debe poder identificar los medios en juego y el enfoque propuesto para tratar los contenidos.
Debe poder identificar al público al que va destinado el documento y tener conocimiento de las coordenadas del proyecto: lugar, fecha y hora de la entrega del documento final y de su difusión, e identificación del medio de difusión y del difusor.
El tiempo de realización del proyecto debe concretarse, así como los principales vencimientos de los pagos y la financiación disponible.

Figura 16

Clasificación de los soportes 

La recapitulación detallada de todos estos condicionantes, para intentar aclarar los puntos oscuros en presencia del solicitante, es importante para comprobar que realmente hay un acuerdo recíproco preciso sobre la petición efectuada.
El problema que el creador intenta evitar constantemente es el de encontrarse al final con un documento que no corresponda a lo esperado por el solicitante o a las necesidades que éste ha formulado.
Dicho resultado sería un desastre porque se habría producido una inversión inútil.
Alguna vez deberá irse incluso más allá de la petición formulada para ver si en ella se sobrentiende una visión diferente y, si es el caso, ponerla de manifiesto.
De esta manera, ayudaremos al solicitante a afinar la forma de abordar el problema y apreciar los objetivos en función de los datos que tintes no había tenido en cuenta.

Tabla 3

Principales etapas de la producción de un documento

La concepción 

En una opción ideal, el pedido podría desembocar en la forma concreta de un documento escrito, firmado por las dos partes y llamado a menudo "pliego de condiciones".
La concepción del documento o documentos proyectados ya puede empezar.

EL autor del documento deberá, llegado el caso, verificar la validez de las informaciones que haya recibido e ir en busca de informaciones o documentos complementarios, toda vez que deberá esforzarse en contestar a las preguntas de ritual:
¿dónde?, ¿cuándo?, ¿cómo?, ¿por qué?, ¿para quién?,¿y con quién?, ¿con qué?, ¿para obtener qué?
De este modo, poco a poco, se podrán prever los medios que deban emplearse y aparecerán los primeros elementos de concepción del mensaje y la forma de tratarlos.
Los riesgos de cualquier clase se pondrán de manifiesto hasta donde permitan las circunstancias.

Uno de los elementos clave para el éxito de la operación será la identificación tan clara como sea posible del destinatario medio, desde el principio de la concepción.
Convendrá conocer su perfil y tipología, su categoría socioprofesional, sus prácticas culturales, sus diversiones, su hábitat y los medios de comunicación que utiliza habitualmente, para concebir un documento que corresponda a su entorno cultural acostumbrado.

Convendrá no alejarse demasiado del lenguaje y las preocupaciones del destinatario tipo para seducirlo sin molestarlo.

El productor debe recapitular los requisitos, sin olvidar ninguno (¡siempre se olvida alguno!), los cuales deben coordinarse para llegar a producir el documento adecuado en el momento deseado y con los medios de que dispone.
Estos requisitos son, en primer lugar, inherentes a los medios de comunicación que deben utilizarse, cada uno de los cuales tiene las características propias de la tecnología que lo informa; en segundo lugar, son característicos del tipo de documento que se produce.

Figura 17

Factores que deben coordinarse para establecer el programa de trabajo 

Ya en la fase de concepción convendrá poner a prueba las ideas y la maqueta ante un sector del público-objetivo para comprobar su coherencia.
Los documentos ya existentes utilizados para la producción deberán estar exentos de derechos de autor o será preciso solicitar autorización para utilizarlos a sus autores o a las personas que posean los derechos correspondientes.

Este es un punto muy importante que debe solventarse desde el momento de la concepción del documento, si no quieren correrse graves contrariedades o penosos problemas jurídicos.
Durante la concepción es mejor procurar no recurrir a documentos cuyos derechos no poseamos o que nuestros medios no nos permitan adquirir o producir.
Es mejor respetar esta regla.
Por otra parte, en la elaboración de los contenidos convendrá procurar respetar la información que contengan estos documentos.

En la opción ideal, según el tipo de documento o de medio de comunicación que se utilice, la concepción debería desembocar en la formalización de los «documentos provisionales» que son útiles para comunicar el contenido del proyecto a los diferentes interesados, en especial al solicitante, así como a los diversos colaboradores que deban participar en la producción.

La planificación de las operaciones es una actividad que debe desembocar, tan pronto como sea posible, en la elaboración del programa de trabajo, en el que deben figurar, siguiendo un orden cronológico y de prioridades, todas las tareas que los distintos participantes tienen que efectuar.
Los datos de entrega y difusión del documento deben figurar en el programa de trabajo con la máxima precisión.
Generalmente, se presentan incidentes y retrasos imprevistos, por lo que convendrá prever plazos de seguridad para poder recuperar esos retrasos sin sobrepasar la fecha prevista para el final de las operaciones.
Por eso, de nada sirve subestimar el tiempo necesario para el cumplimiento de las diferentes tareas a fin de intentar ganar tiempo.
Las tareas deberán definirse con precisión y distribuirse equitativamente.

La producción 

Durante la producción es imprescindible que todos los medios necesarios estén a disposición de los diferentes participantes, en el momento deseado.
Deberán enumerarle cuanto antes todos los medios técnicos necesarios durante el proceso de producción para poder disponer de ellos sin demora llegado el momento.
Podrán adquirirse o alquilarse, o se podrá disponer de ellos gratuitamente, y deberán ponerse a prueba antes de su utilización efectiva para no tener sorpresas en el último momento.
Esta recomendación se refiere tanto a la disponibilidad de los documentos de base como a los equipos físicos o lógicos que se utilicen para la digitalización y el procesamiento de los diferentes elementos, la elaboración de los contenidos, el desarrollo de las aplicaciones y la finalización del documento.

Se movilizarán todas las posibilidades de la estructura de producción y, llegado el caso, de fuera de ella, para obtener prestaciones determinadas y puntuales de especialistas muy destacados.
La financiación estará prevista desde el principio con una estimación presupuestaria que será aprobada por los diferentes responsables, y se reservarán y gestionarán los fondos con rigor.
También se preparará la logística cuidadosamente.
Los locales, los vehículos, los posibles desplazamientos, el hospedaje, las comidas y otras prestaciones se reservarán con mucha antelación y se confirmarán antes de la salida para evitar alguna sorpresa desagradable en el último momento.

La realización se llevará a cabo bajo la responsabilidad de un coordinador general, llamado «jefe de proyecto», «realizador», «jefe de taller» o «editor», según el tipo de documento que se produzca: multimedia, película, emisión de televisión, libro.
En todos los casos se trata de velar por que la elaboración de los contenidos se haga de acuerdo con los documentos provisionales (resúmenes, pliego de condiciones, sinopsis, guión, planificación de las escenas, story-board o maqueta) que se hayan aprobado previamente.
Cada participante debe proporcionar la prestación más adecuada por medio de una búsqueda de los resultados óptimos en la expresión, el enriquecimiento y ponderación de las ideas, y la creatividad, de acuerdo con el conjunto del documento que debe producirse.
EL realizador será el responsable de la coherencia y de la armonía general del conjunto.
Orientará siempre el trabajo de cada participante en el sentido que desee ver lo plasmado para dar toda la coherencia necesaria a la obra.
Con su idea de cómo deba ser el producto, lo imaginará a su manera, imprimiéndole fuerza y estilo, y dedicará todos sus esfuerzos a estimular a todos los participantes para que trabajen de común acuerdo y el resultado corresponda a su visión creadora.

Figura 18

Difusión de documentos 

Así pues, este trabajo de realización es una labor de gestión de la elaboración y el tratamiento del contenido.
También es una labor de gestión de los riesgos, ya que cada decisión que se tome puede poner en entredicho la conformidad del documento final con el pedido y los objetivos que se persiguen.
Además, es un trae bajo de gestión de la comunicación mantenida con el conjunto de colaboradores y responsables.
EL realizador debe encontrar las palabras necesarias para expresar lo que espera de cada uno de ellos con una precisión y un poder de evocación que proporcionen todos los elementos precisos, así como para despertar la motivación y el deseo de emulación y estimular la creatividad.

Los elementos producidos se deberán montar, editar y reunir en una maqueta que primero se ajustará y luego se presentará al solicitante y a una muestra del público-objetivo.

Entonces se harán las rectificaciones necesarias en la maqueta para finalizar el documento, que quedará a punto de copia, revelado, impresión, difusión o puesta en servicio, según los casos.

La difusión 

Aunque los documentos se creen y produzcan con mucho cuidado y por fases, es preciso comprobar con atención que no se ha pasado por alto ningún defecto redhibitorio.
Antes de su difusión, el impacto del documento se pondrá a prueba y se valorará por primera vez ante una muestra de público-objetivo con la ayuda de un protocolo detallado y riguroso.
Si después de esta evaluación se comprueba que el documento en cuestión no cumple correctamente su función, será preciso modificarlo y reflexionar convenientemente antes de proceder a su difusión para no llevar a cabo una operación inútil, ineficaz o aberrante que ponga en peligro la imagen y la reputación del organismo para el que se trabaja.

La difusión se preparará y ejecutará con mucho cuidado.
La evaluación del impacto efectivo sobre los destinatarios se realizará con gran precisión.
Se prestará mucha atención a que todos los documentos lleguen a sus destinatarios en el momento deseado y en buen estado.
EL mecanismo de evaluación deberá estar completamente a punto para funcionar.
Los resultados deberán recogerse, procesarse y analizarse rápidamente para poder intervenir de nuevo y modificar el documento, o su modo de difusión, o su evaluación, si fuera el caso.

En materia de comunicación nunca se está seguro de nada hasta que el destinatario se adhiere al mensaje sin reservas, pero incluso entonces uno tiene derecho a plantearse algunas dudas sobre la vanidad de las apariencias los motivos de la adhesión o la validez de la gestión.
Nada puede darse definitivamente por bueno, todo puede ponerse de nuevo en tela de juicio.

Tercera parte 

Producción y difusión de los soportes 

Ya hemos visto antes que la microcomputadora asociada a las redes está en el centro de la crisis y de los cambios tecnoeconómicos actuales.
Es una herramienta de base que permite optimizar la producción, la gestión y la difusión de la información en general, en especial en el ámbito de la formación.
Acabamos de examinar en el capítulo anterior las precauciones que se imponen para hacer coincidir las necesidades y los objetivos que motivaron la producción de los documentos con el impacto efectivo de estos documentos sobre sus destinatarios.
Ahora vamos a ver cómo las soluciones pueden aprovecharse para optimizar el ciclo de edición de los medios de comunicación destinados a la formación.

Como ya hemos visto antes, la microcomputadora debe comunicar con los elementos periféricos a los que está conectada para efectuar algunas tareas determinadas.
Estas conexiones se efectúan a través de tomas especiales "en serie" o "paralelas" que habitualmente se instalan en la parte posterior de la microcomputadora.
Los diferentes periféricos se conectan a estas tomas.
Con las tomas de tipo serie (habitualmente de la norma SCSI) es posible conectar varios periféricos en cascada para constituir configuraciones que correspondan a necesidades distintas.

Figura 19

Esquema de una cadena SCSI

Se trata de una serie de módulos que pueden adaptarse a las diferentes necesidades.
Para una configuración dedicada al tratamiento de textos bastará una impresora láser o de chorro de tinta (estas últimas son más baratas) en blanco y negro o color.
Si conviene, la impresora puede compartirse con otros terminales de la red.
Si se trata de compaginar documentos diversos, será preciso constituir una unidad de PAC con escáner, tableta gráfica y un periférico de almacenamiento.

Una configuración dedicada a la presentación asistida por computadora (PreAC) se conectará con un tablero de proyección de cristales líquidos o un proyector de vídeo adaptado a la proyección digital.

Por supuesto, la configuración física se completará con programas adecuados que permitan atender el nivel de prestaciones correspondiente a los resultados esperados.
Los soportes lógicos necesarios deberán presentarse, siempre que se pueda, como un conjunto coherente que ofrezca las máximas facilidades de funcionamiento posibles.

Así pues cualquier parte del texto, las ilustraciones, las fotografías, el sonido o el vídeo, podrá cortarse y desplazarse (pegarse) hacia otra parte del mismo documento o hacia otro documento, en otro programa.
El procesamiento de documentos por microcomputadora se fundamenta en este gran principio.

Los impresos 

Si, por ejemplo, queremos describir un cuadrado negro, podremos elegir entre dos métodos: o describir punto por punto la imagen de este cuadrado en medio de la pantalla, o describirlo de manera analítica por medio de una serie de cuatro vectores situados en un plano que definan su forma y añadiendo la información "colorear de negro la parte interior de la figura cerrada y dejar el exterior en blanco".

En el primer método, que se denomina (mapa binario), cada pixel de la pantalla se describe por medio de informaciones codificadas en 2, 8,16 o 24 bits, lo que representa gran cantidad de informaciones.
En el segundo método, denominado , tendremos muy poca información en nuestro fichero.

Por tanto, si queremos describir la letra "A" podemos hacerlo por el sistema bitmap o el vectorial.
Si se trata de un diseño de grandes dimensiones en que sólo hay esta letra, el método más económico y rápido será el vectorial.
Pero si se trata de un texto de 500,000 caracteres, necesitaremos un fichero muy importante.

En efecto, el texto es el primer lenguaje que el hombre ha enseñado a la computadora.
Cuando uno pulsa la letra "A" de un teclado, la computadora la traduce en un código digital binario de 8 bits, llamado código ASCII ( American Standard Code for Information Interchange).
Es la manera más sencilla y económica de representar una letra: hacerlo por un solo número binario en vez de describir su forma.
En este caso, nuestro texto de 500 000 caracteres sólo representará un fichero de 500 kilobytes.

Los documentos impresos son conjuntos complejos de textos, grafismos o fotografías dispuestos en un orden preciso sobre el espacio de la página.

Existe un lenguaje de descripción de páginas que se ha convertido en norma en el mundo de la edición: el lenguaje PostScript.
Este lenguaje permite definir documentos destinados a la impresión e imprimirlos con impresoras de oficina o en una imprenta con una calidad máxima.
Todo fichero de textos, gráficos, fotografías o mixto puede convertirse en formato PostScript.

En general, el soporte utilizado para la impresión es el papel, pero también es teóricamente posible realizarla sobre cualquier superficie plana: cartón, tejido, metal, plástico y, por supuesto, transparencias.
Un documento puede tener una o varias páginas, hasta varios centenares.
Las dimensiones pueden ir desde el tamaño de un sello hasta una valla gigante, pasando por todos los formatos normalizados: A5, A4, A3, A2, A1, A10.

Los periféricos 

Todo ello puede concebirse en una microcomputadora y, llegado el caso, imprimirse en una impresora periférica láser o de chorro de tinta, en blanco y negro o color.
Las primeras tiradas permitirán apreciar la calidad del documento y ponerla a prueba ante el usuario potencial.
Si la cantidad que debe producirse se limita a algunas decenas o centenas de documentos de formato A4, o en su caso A3, la producción podrá hacerse de manera autónoma.

EL fichero correspondiente al documento así concebido puede también confiarse a un impresor para su producción en serie.
Las impresoras de oficina no pueden conseguir las cantidades, dimensiones, encuadernación ni calidades de reproducción de los colores logradas en las imprentas que disponen de material moderno informatizado muy perfeccionado.

En consecuencia, para crear un documento sobre un soporte impreso es necesario disponer de un texto, tal vez formado por títulos, subtítulos, párrafos y documentos gráficos para su ilustración.
En un primer caso, estos elementos se habrán creado previamente en el exterior, en una computadora, y estarán disponibles en un disco flexible magnético o magneto-óptico o en un cartucho SyQuest, en forma de uno o varios ficheros digitales que, llegado el caso, deberán convertirse al formato en que deba efectuarse el trabajo de concepción y compaginación.

En un segundo caso, el conjunto de los elementos textuales y gráficos se crea íntegramente en la microcomputadora.
EL texto podrá generarse directamente con el teclado y un soporte lógico de tratamiento de textos.
Las ilustraciones se dibujarán con la ayuda de un soporte lógico de grafismo, dibujo (bitmap o vectorial) o pintura, con el ratón o con más funcionalidades creativas, sobre una tableta gráfica mediante un lápiz magnético.
A continuación podrá disponerse de ellos en forma de ficheros digitales en el formato que se elija.

Figura 21

Esquema de una estación de PAC 

En un tercer caso, si los elementos ya se han creado sobre un soporte determinado, será preciso digitalizarlos por medio de un escáner conectado con la toma SCSI de la microcomputadora.

EL escáner plano sirve para digitalizar los textos, los grafismos o las fotografías ya producidos en un soporte de papel.
Después se salva cada documento digitalizado en forma de fichero bitmap en el disco duro.
Los ficheros gráficos contienen todos los datos que describen el aspecto gráfico del documento, punto por punto.
Este fichero se podrá abrir con un soporte lógico de dibujo, retoque de fotografías, tratamiento de textos (si contiene un utilitario de ilustración gráfica) o compaginación.
Si el texto digitalizado no es manuscrito, podrá reconocerse en forma de caracteres ASCII por medio de un programa de reconocimiento de caracteres, lo que evitará tener que volverlo a introducir por medio del teclado para transformarlo en código ASCII.

El escáner de diapositivas sirve para digitalizar las fotografías directamente sobre la película fotográfica (negativa o positiva) sin necesidad de hacer una tirada en papel.
Esta operación permite tener una mejor calidad de imagen.
A continuación se podrá abrir el fichero en un programa de tratamiento de fotografías y realizar una infinidad de operaciones para modificarlas: aumentar o disminuir el tamaño, eliminar el predominio de un color, pasar de negativo a positivo y viceversa, seleccionar una parte de la imagen y sustituirla por otra, introducir texto o grafismos, efectuar sobreimpresiones y muchas otras operaciones.

Figura 22

Esquema de un escáner

La cámara fotonumérica podrá servir para procesar internamente las instantáneas cuando esto sea posible, es decir, si se posee la competencia suficiente.
De este modo podremos disponer inmediatamente de ficheros digitalizados de las fotografías para procesarlas, retocarlas e insertarlas en los documentos que tengan que producirse, sin intervención del laboratorio o de otros servicios externos.
Existen cámaras fotonuméricas bastante económicas que permiten niveles de calidad suficientes para determinados tipos de publicaciones.
Otras soluciones más caras alcanzan niveles de calidad muy altos.

Una solución interesante consiste en transferir las fotografías en película, directamente de la película a un CD-Foto.
El CD-Foto es un formato de edición de fotografías en un tipo de CD-ROM particular, creado por Kodak en colaboración con Philips a principios del decenio de 1990 para que fuera compatible con los productos de la gama de los DOC.
Su objetivo es proporcionar a los fotógrafos profesionales o aficionados una herramienta que les permita procesar y editar sus trabajos en una gama de soportes digitales compatibles con las prácticas que llevan a cabo los edito res, los autores y los fotógrafos en los diferentes ámbitos de la edición.

En el CD-Foto, cada fotografía puede darse en toda una gama de formatos para obtener una resolución que garantice la mejor calidad de reproducción posible en función de la utilización final.

EL CD-Foto se produce a partir de negativos, diapositivas o positivados sobre papel.
Las fotos se digitalizan en estaciones de transferencia especializadas de gran calidad definidas por Kodak, las cuales forman parte del equipo de que disponen los laboratorios fotográficos.
AL final del proceso se entrega al cliente un CD-Foto (o varios) llamado "master" .
Este disco puede contener hasta cien imágenes que están disponibles en cinco formatos diferentes: base 16, base 4, base, 4 base y 16 base, que permitirán los cinco tipos de aplicaciones correspondientes.
En una impresora especial se pueden hacer tiradas en papel de una extraordinaria calidad a partir del CD-Foto.

Las fotografías así digitalizadas están disponibles en ese soporte práctico, que puede utilizarse fácilmente en cualquier documento creado con un programa de tratamiento de fotografías o de compaginación.
Por último, hay otro sistema de adquisición de imágenes, la cámara de vídeo, pero es poco apto para la edición en soporte impreso, a no ser que se disponga de una cámara especial cuya resolución sea muy elevada.
La resolución que permiten las cámaras de vídeo (incluso las profesionales) no alcanza un nivel suficiente para una buena calidad de impresión.

Los programas de tratamiento de textos 

Las principales funcionalidades de los programas de tratamiento de textos consisten en permitir la concepción del contenido de manera planificada, con sus diferentes partes y los títulos de los capítulos y las secciones.
Se debe facilitar la escritura del texto permitiendo las correcciones y el traslado rápido y cómodo de una frase a otro párrafo o de un párrafo a otro capítulo con una sencilla orden de "cortar y pegar".
Habitualmente basta con seleccionar con el ratón la parte afectada, elegir en el menú la función , situar con el ratón el punto de inserción en el lugar deseado y elegir la función "pegar".
Una funcionalidad todavía más sencilla es la de , que consiste en tomar la porción de texto seleccionada marcándola con el ratón y, manteniéndolo pulsado, desplazar el texto hasta el lugar deseado.

Las funcionalidades referentes al aspecto de las letras, como el cambio de tamaño o de tipo, la inclusión de negritas , cursivas o subrayado o la colocación de las letras en exponente o en subíndice son generalmente muy fáciles de obtener, siempre seleccionando la parte de texto afectada y eligiendo la función deseada en el menú.

En cualquier momento se puede insertar una a principio de línea, un recuadro con un número de líneas y de columnas determinado o una ilustración creada con un soporte lógico de grafismo y después o creada directamente con un programa de ilustración integrado en el soporte lógico de tratamiento de textos (como ocurre con h mayoría de las ilustraciones que figuran en este texto).

La búsqueda de todas las veces que aparece una palabra en el texto permite sucesivamente, una vez tras otra, o en todo el texto de una sola vez, por otra palabra definida en la ventana de diálogo que se abre en la pantalla.

Se puede acudir a varios programas de ayuda: un diccionario de sinónimos, un comprobador ortográfico o un corrector gramatical (más o menos eficaces).

Los documentos se crean en todos los formatos de página corrientes o en el tamaño deseado.

Los márgenes se pueden ajustar a voluntad, en todos los sentidos, y la numeración de las páginas se efectúa automáticamente a petición del interesado.
Las notas a pie de página se colocan y gestionan automáticamente.

Las ilustraciones se incorporan o (o se crean) y se colocan en el texto por medio de un programa gráfico que se incluye en el soporte lógico de tratamiento de textos.
Así pues, con algunas limitaciones de calidad de los grafismos importados o creados, se puede ilustrar un texto.
Sin embargo, un trabajo que deba responder a los criterios profesionales de edición no puede evitar pasar por un soporte lógico de compaginación para la realización de la maqueta, y por un soporte lógico de tratamiento de fotografías y otro de tratamiento de grafismo para las ilustraciones.

Los ficheros creados con los soportes lógicos de tratamiento de textos se graban en un formato determinado.
En principio, no pueden leerse en otras plataformas.
Sin embargo, existen programas que convierten los ficheros de un formato en otro.
Algunos de estos programas se integran en los soportes lógicos de tratamiento de textos, pero la conversión no siempre es buena, sobre todo por lo que se refiere a las ilustraciones.
Un programa de conversión como MacLinkPlus es eficaz en casi todos los casos en que hay que incluir figuras en medio de un texto.

Tabla 4

Principales tratamientos de textos

Los programas de grafismo 2D 

Los programas de grafismo, como ya hemos visto, se dividen en dos grandes categorías: bitmap o vectoriales, según el modo de definición de la imagen.
También se clasifican en programas de dibujo en dos dimensiones (2D) o en tres dimensiones (3D).
Cuando se representa un objeto en una hoja de papel o en una pantalla de computadora, este objeto se dibuja en perspectiva, de manera más o menos formal, sobre una superficie plana que tiene dos dimensiones y simula la tercera dimensión.
Los programas que permiten realizar a mano este dibujo normal se denominan programas de grafismo 2D.

Además, quedan incluidos en esta categoría los programas de tratamiento de fotografías que disponen generalmente de algunas funcionalidades de dibujo.

Los programas de dibujo 2D generan una hoja de dibujo y una gama de herramientas más o menos abundante y sofisticada que permite dibujar a mano con un lápiz más o menos grueso, o bien con un pincel fino o espeso, acuarelas, aguadas, apuntes al carbón, al pastel, con rotulador, etc .
Según el número de colores que el puesto de recogida de datos permita, se podrá trabajar con 256 colores o con millares o millones de colores.

También se podrán separar los colores de una imagen por capas transparentes (rojo-verde-azul), como calcos en que los colores pueden descubrirse O mezclarse (a elección) al superponerse.
Igual que pasa con el texto, se podrá seleccionar cualquier parte del dibujo por medio de una herramienta de selección, más o menos afinada, y luego copiarla o cortarla y pegarla en otra parte del mismo dibujo o en otro dibujo completamente distinto.

También hay facilidades para el dibujo de tipo técnico por medio de una panoplia más o menos abundante de herramientas de dibujo de formas geométricas básicas precisas (rectas, curvas, cuadriláteros, polígonos, elipses, etc.) que se podrán desplazar, superponer, reunir, deformar, copiar y colorear para representar el objeto deseado.
A estas ilustraciones se podrán añadir textos, leyendas o títulos.

Los programas de tratamiento de fotografías permiten digitalizar y procesar las fotografías para modificar los parámetros dimensionales (tamaño, resolución, etc.), fotométricos (contraste, luminosidad, etc.) y colorimétricos (colorido, saturación, etc.) y aplicarles los filtros que modifican su textura y su aspecto.
También permiten separar las diferentes capas rojo-verde-azul (RVA) o azul-magenta-amarillo-negro (AMAN) y efectuar selecciones en una de estas capas o en el conjunto para eliminar o modificar un elemento de la imagen.

Es raro que un mismo programa permita realizar todos estos tipos de dibujos, pinturas y tratamientos de imagen.
Habitualmente, se utilizan programas especializados, ya sea para la ilustración tipo pintura o Tipo dibujo, ya sea para el tratamiento de fotografías.
Los dibujos se salvan preferentemente en el formato correspondiente a su utilización final: PostScript, EPS, PICT, GIF, TIFF u otros.
No todos los programas permiten hacer la conversión a todos los formatos.
Sin embargo, existen programas especializados en la conversión de ficheros gráficos, como DeBabelizer o Graph Converter.

Los principales programas de conversión gráfica, aparte de las funcionalidades contenidas en los propios programas gráficos, son DeBabelizer y GraphicConverter.

Los programas de grafismo 3D(síntesis de imágenes) 

Si el objeto que debe representarse está dibujado con un programa de grafismo 3D, será modelizado en tres dimensiones a partir de volúmenes geométricos simples llamados «primitivos» (rectas, planos, cubos, esferas, conos, pirámides, etc .), que podrán redimensionarse, deformarse y agruparse y luego situarse en el espacio en relación al entorno previsto con el fin de constituir lo que se llama una escena.

Por ejemplo, se podrá disponer de iluminaciones de diferente naturaleza (luz directa en haces focalizados o amplios, luz difusa, luz coloreada, etc .), dar atributos de materia (vidrio, metal, madera, plástico, etc. ), aplicar una imagen (fotografía o dibujo) sobre una superficie y definir la línea focal de una toma fotográfica.
A continuación se podrá pedir al programa que calcule una perspectiva de esta escena en cualquiera de sus ángulos posibles colocando la cámara en una posición cualquiera.
De esta forma el programa calculará la multitud de reflexiones sucesivas de la luz sobre todas las superficies, en función de su naturaleza y de las diferentes luces que iluminan la escena para darle el máximo aspecto de realidad posible.

Generalmente, la imagen del objeto modelizado es vectorial (como si se representara con alambres) y la imagen final calculada por la computadora es bitmap.

También veremos la importancia de este concepto de la imagen 3D para la realización de películas de animación y para la realidad virtual.
Algunos programas de grafismo 3D van equipados con funcionalidades que les permiten calcular una serie de imágenes correspondientes al desplazamiento de la cámara o de uno o varios objetos siguiendo una trayectoria definida.
EL visionado de esta sucesión de imágenes les otorga movimiento y constituye una película de animación.

Los programas de efectos especiales 

Existen programas llamados «de efectos especiales» que permiten aplicar a una imagen efectos determinados de textura, materias, efectos de mosaico, imagen suavemente borrosa, solarización o distorsiones y metamorfosis.
Estos efectos pueden aplicarse sobre una imagen, pero también sobre una secuencia de imágenes para crear movimiento.

Los programas de compaginación 

Los programas de compaginación ofrecen las funcionalidades profesionales necesarias para crear documentos que puedan imprimirse.
Estos programas permiten definir los formatos y la maqueta del documento en todos sus detalles, con el máximo de flexibilidad y precisión: títulos, márgenes, filetes, columnas, recuadros y fondos de páginas.
Se importan textos, grafismos, letras y fotografías en sus formatos habituales, en bloques específicos que pueden crearse a voluntad y luego se agrandan, arreglan y desplazan dentro de la página o en otra página.

La «rigidez» inherente a los tratamientos de texto, en que los cuadros y las ilustraciones deben colocarse obligatoriamente siguiendo las líneas, da paso aquí a la libertad total en la disposición y equilibrio de los bloques de texto y los bloques de imagen entre sí.

EL programa de compaginación debe poder proporcionar al impresor, en forma de fichero digital, todos los elementos necesarios para producir el documento impreso: los contenidos escritos y gráficos, pero también todas las dimensiones referentes a la disposición de los elementos entre sí.
La presentación de un documento textual impreso reviste una gran importancia.

Debe prestarse gran cuidado a la compaginación de los elementos más significativos.
Los documentos se compaginan para imprimirse, pero su conversión a los efectos de publicación en los servidores de World Wide Web puede resultar un objetivo muy importante, como veremos más adelante.
Ahora, algunos programas de compaginación comportan ya esta funcionalidad.

Tabla 7

Principales programas de efectos especiales

Los programas integrados 

Los programas integrados son series de programas que se comunican entre sí y se complementan.

Generalmente, comprenden un tratamiento de textos, un programa de grafismo una hoja de cálculo, una base de datos y un programa de comunicación.
Son herramientas destinadas al gran mercado de los usuarios individuales.
Son productos baratos con funcionalidades y prestaciones interesantes, pero no corresponden al nivel que se espera de los programas profesionales.

Tabla 8

Principales programas de presentación asistida por computadora

Los programas de reconocimiento de caracteres 

Cuando un documento se ha digitalizado por medio de un escáner, ya hemos visto que se salva en forma de fichero gráfico de tipo bitmap.
Si se trata de un texto impreso, las letras serán posiblemente legibles en la pantalla, pero no serán reconocidas por la computadora como caracteres ASCII y, en consecuencia, no podrán utilizarse en un tratamiento de textos.
Por eso, es necesario traducir este texto «imagen» por medio de un programa de reconocimiento de caracteres.
Ese programa examina la imagen de cada letra y deduce de ella el código ASCII correspondiente.
De este modo, un texto puede recuperarse con un éxito aproximado del 99 por ciento.
El corrector ortográfico de un tratamiento de textos puede, en general, rectificar la mayoría de los errores.
Por tanto, no es necesario entrar los textos impresos por medio del teclado, si se dispone de un escáner y un programa de reconocimiento de caracteres.
Esta operación representa una economía de tiempo proporcional al número de páginas.

Si el texto está escrito a mano, el problema es diferente, más difícil pero no imposible.

Existen programas basados en algunos conceptos de inteligencia artificial que pueden aprender a convertir la forma de las letras manuscritas producidas por una persona determinada en su equivalente en caracteres ASCII.
Por tanto, antes de cualquier reconocimiento es necesario enseñar al programa a reconocer la escritura de la persona que ha escrito el documento y a este efecto ya existe un proceso de aprendizaje previo.

La presentación 

Los mecanismos de PreAC permiten editar y presentar a un auditorio un discurso ilustrado de documentos diversos, cuya claridad e interés ofrece a los participantes una tasa de retención superior a la de una exposición clásica.
Para ello, el presentador deberá haber efectuado una labor de preparación.
A partir del texto de su intervención, elaborado a poder ser con un programa de tratamiento de textos, tendrá que establecer el plan, las principales líneas, las ideas directrices y los puntos fuertes de su discurso para crear con el programa de PreAC de que dispone las pantallas que presentará a los participantes en apoyo de su argumentación.

Debe preparar y producir su presentación antes de difundirla.

Figura 23

Esquema de una estación de edición de PreAC

Producción de la presentación 

Según el tipo de documento que elija como ilustración, deberá disponer de los diferentes periféricos de digitalización adecuados.
Necesitará un escáner para integrar los textos, los grafismos o las fotografías y, llegado el caso, una cámara de fotografía numérica digitalizada para efectuar tomas directamente integrables en la aplicación.
Si se decide integrar el vídeo y el sonido, se necesitará una microcomputadora capaz de gestionar este tipo de datos y una cámara de vídeo, un magnetoscopio y un micrófono.

La mayoría de los programas de presentación funciona en base al principio de un encadenamiento de pantallas cuya duración puede definirse (y modificarse) automáticamente o dejarse a la apreciación del presentador mediante el avance manual.
Así pues, en este último caso, el presentador podrá, llegado el momento en su exposición, pedir la visualización de la pantalla cuando lo juzgue necesario.
Algunos programas de presentación ofrecen una representación de la aplicación que se está creando con el encadenamiento de las pantallas en una línea temporal.
Asimismo, algunos tienen botones que permiten enlazar los contenidos entre sí y pasar de una pantalla a otra.
Todos ofrecen efectos de transición entre las pantallas en número variable, fundidos encadenados, barridos, sustituciones, etc .

La mayoría de estos programas integran herramientas de dibujo y pintura y funcionalidades de animación gráfica.
Todos los que indicamos en el cuadro adjunto permiten integrar el sonido, el vídeo y animaciones gráficas tratados exteriormente e importados en la aplicación en diferentes formatos.
Algunos ofrecen la posibilidad de crear una aplicación en una plataforma y, si conviene, leerla en otra.

Estos programas ofrecen modelos y funcionalidades de cuadros, fondos, recuadros, subtítulos, histogramas, efectos de sombras, degradados o tramados a punto de ser utilizados para facilitar la creación de las pantallas a los usuarios que no Tienen un gran dominio de la creación gráfica.
Algunos de ellos ofrecen también funcionalidades de tratamiento de imágenes, de video y de sonido, como Movieworks.

Tabla 9

Principales programas de presentación asistida por computadora

La retroproyección 

La mayoría de estos programas permiten imprimir en una impresora de oficina adecuada las transparencias correspondientes a las diferentes pantallas editadas, en caso de que no se disponga de un tablero de cristal líquido y de que la presentación deba desarrollarse en varios sitios, algunos de los cuales no estén equipados de proyector multimedia sino únicamente de un retroproyector.

Los tableros de cristal líquido son casi siempre suficientemente compactos y ligeros para transportarlos y conectarlos a una microcomputadora de oficina o portátil.
Sin embargo, debe tenerse en cuenta que los tableros de cristal líquido sólo transmiten una media del 5 por ciento de la luz del retroproyector que pasa a través suyo.
Por eso, será necesario disponer de un retroproyector potente, de 3.000 lumens por lo menos, para tener una imagen suficientemente luminosa y precisa en la pantalla de proyección.
Por supuesto, esto está también en función del tamaño de la pantalla, de la sala e incluso del encuadre del tablero de cristal líquido.

Generalmente, el tamaño de la imagen es de 640 x 480 pixels, pero el encuadre puede tener, por ejemplo, 8,4 o 10,4 pulgadas de diagonal.

Ciertos tableros de cristal líquido llevan consigo un altavoz y un micrófono, e incluso toleran el control de la interactividad a distancia por medio de un ratón de rayos infrarrojos parecido a un mando a distancia.
Algunos cuentan también con una toma de vídeo para proyectar un videocasete leído por un magnetoscopio.
Todos funcionan indistintamente en las diferentes plataformas con los cables o interfaces adecuados.

Este tipo de proyección relativamente económica es muy adecuada para las asambleas no muy numerosas, pero no permite alcanzar un nivel de calidad de imagen muy elevado a causa de las pérdidas de luz debidas a la retroproyección.

Figura 24

El sistema de la retroproyección

Tabla 10

Principales tableros de proyección de cristal líquido

La proyección de video multimedia 

La proyección de vídeo multimedia permite obtener una calidad de imagen muy buena en pantallas de hasta 4 metros de base, en grandes salas y ante una asistencia numerosa.
La proyección de vídeo es una tecnología que aprovecha, a la vez, el perfeccionamiento de la proyección de vídeo clásica y la solidez del cristal líquido.

La proyección en vídeo de imágenes informáticas se hacía al principio en proyectores de tres tubos que habían alcanzado un nivel de calidad muy bueno pero que eran muy pesados, incómodos y de ajuste muy delicado.
Además, se necesitaba un interfaz costoso para convertir la señal y lograr un nivel de calidad suficiente.

Hoy, los proyectores de vídeo de cristal líquido lo integran todo en una caja (pesada pero transportable) y ofrecen una calidad equivalente, una utilización más económica y una mejor fiabilidad.

Los tableros o los proyectores de cristal líquido no sólo proyectan las aplicaciones de presentación asistida por computadora.
Por una parte, ya hemos visto que están equipados con una toma de vídeo, lo que les permite proyectarlo con una cámara o un magnetoscopio.
Por otra parte, conectados a la unidad central, proyectan todo lo que se encuentra en la pantalla de la computadora, en aplicaciones de PreAC pero también en cualquier otra aplicación.
Es decir, cualquier demostración que tenga lugar en una computadora puede también proyectarse en tiempo real.

Tabla 11

Principales proyectores de cristal líquido

Sin embargo, algunos programas muy útiles en el ámbito de la formación permiten grabar toda la actividad que puede desplegarse en la pantalla como consecuencia de un trabajo determinado en un programa de aplicación.
EL resultado de esta recogida de datos de la pantalla es un fichero que puede ejecutarse sin el programa de aplicación original y se presenta como una película en la que se reproduce íntegramente la pantalla de la computadora y se ve desplazarse el puntero del ratón, abrir un fichero o una carpeta, mover una ventana de diálogo, etc. Sin embargo, hay que tener en cuenta que, con este Tipo de soporte gráfico, la imagen de vídeo no puede desplegarse a la frecuencia suficiente para pasar a la velocidad normal de 30 (NTSC) o 25 (PAL, SECAM) imágenes por segundo.
Por el contrario, la imagen gráfica de la pantalla de la computadora se despliega perfectamente sin movimientos bruscos si se dispone de una microcomputadora de potencia media.

Algunos programas, como CameraMan, permiten incluso añadir una o varias bandas de sonido sincronizadas con las imágenes para los comentarios o las ilustraciones sonoras.
Por supuesto, estos ficheros se pueden proyectar tal cual dentro de una perspectiva pedagógica, pero algunos de esos programas ofrecen también la posibilidad de grabarlos en vídeo y poderlos distribuir en forma de casetes.

Igual que algunos programas de PreAC.

Tabla 12

Principales programas de captura de la actividad de pantalla

Los condicionantes de la proyección 

La difusión debe constituir el interés permanente del creador de aplicaciones de presentación.
Todas las ilustraciones y todos los textos deben adaptarse al visionado en condiciones óptimas para todo el público en todas las sedes de difusión previstas.
Ningún detalle debe ser inferior a la dimensión mínima Visible desde el punto de la sala más alejado de la pantalla.

Cuando se realice la proyección, la pantalla debe estar cerca y en posición perpendicular al eje de proyección, de manera que la imagen sea completamente rectangular y no sufra deformaciones.
El proyector debe colocarse de forma que no moleste la visión de la pantalla.
Si es necesario, la sala deberá quedar a oscuras para que la pantalla sólo reciba la luz del proyector y la imagen sea más hermosa y contrastada, con colores que no sean apagados.

Los casetes 

Los diferentes formatos de casetes de audio y vídeo se han convertido en soportes económicos privilegiados para la difusión de documentos sonoros y audiovisuales.
Son de utilización muy flexible, fáciles de producir y especialmente adaptados a la producción de soportes pedagógicos, sobre todo desde que las tecnologías digitales permiten nuevas funcionalidades de producción para poner estas herramientas a disposición de todos enriquecer los contenidos, disminuir los costos y mejorar aún más la calidad.

El casete de audio (igual que el videocasete) es un sustituto eficaz y práctico de la bobina de cinta magnética, la cual puede devanarse accidentalmente y ensuciarse, y que se debe cargar de forma correcta en el aparato siguiendo un procedimiento bastante complejo.

El casete protege la cinta, la cual está al abrigo de los accidentes y del polvo en su estuche cerrado.

Además, el casete automatiza y hace más seguro el complejo proceso de carga en el aparato lector-grabador.
También permite su etiquetado, embalaje y almacenamiento en forma compacta.

El sonido 

El sonido es el vector natural de la comunicación oral.
Por esta razón, desempeña una función privilegiada en la relación pedagógica y afectiva que se establece entre el formador y el alumno.
El tono de la voz, su ritmo y su música transmiten determinados afectos que actúan poderosamente sobre el trasvase de conocimientos.
Las técnicas de tratamiento del sonido empezaron a dominarse bastante pronto, a finales del siglo pasado, por lo que se refiere a la radiodifusión y a la grabación de cilindros de cera.
Luego, pasando por el disco de 78 revoluciones, el disco microsurco y la cinta magnetofónica, el casete magnético de audio se convirtió en norma universal.
Más tarde han aparecido otros soportes de audio en el mercado, como el CD-Audio que ha sido el origen de toda la familia de los Discos ópticos Compactos.

La difusión de programas radiofónicos progresa continuamente en el mundo y a veces da lugar a aplicaciones pedagógicas importantes, en especial por lo que se refiere a la enseñanza de idiomas.
A menudo se difunden en algunos ámbitos programas radiofónicos pedagógicos específicos que pueden llegar a alcanzar objetivos ambiciosos con una gran audiencia y con muy pocos medios (los receptores de radio son muy populares, incluso en los países más pobres).

Las técnicas de grabación y tratamiento del sonido analógico no variaron durante mucho tiempo, utilizando los legendarios magnetófonos portátiles Nagra , y más tarde los Uher , que permiten una grabación de muy alta calidad en condiciones muy difíciles.
El montaje en bobinas de cinta magnética puede realizarse por medio de la localización manual de los sonidos en la cinta, el corte con tijeras y el pegado con cinta adhesiva.

Desde su aparición a comienzos del decenio de 1960, el casete de audio constituyó un avance considerable para la difusión de las cintas grabadas y para un uso más popular de la grabación de audio.
La obligación de copiar la cinta para proceder al montaje limitó su uso a operaciones de gama baja.
Sin embargo, ahora existen magnetófonos de casete de calidad profesional, bastante accesibles, que se adaptan bien al entorno profesional para producir documentos de audio de excelente calidad.

La tecnología de los micrófonos, los altavoces, los mezcladores, los amplificadores y otros equipamientos analógicos de estudio de alta gama progresó también mucho en términos de calidad y de miniaturización.
Este avance dio paso, en el decenio de 1970, a una industria floreciente (principalmente japonesa) y un mercado mundial del material de audio doméstico (y profesional).
Los receptores de radio y los sistemas estéreo de lectura de discos de microsurco con amplificadores, altavoces y magnetófonos se integraron en forma de módulos conectables y configurables a voluntad, y se ofrecieron a la codicia de los consumidores.

Convertidos en gigantes de la industria a escala internacional, los actores principales de este mercado se encontraron más tarde con el mercado de la televisión, el vídeo y las aplicaciones domésticas surgidas de la tecnología microinformática.

Bastante a menudo, el casete de audio sirve de cuaderno de notas a los estudiantes, que graban en él sus cursos.
Sin embargo, la producción de casetes pedagógicos de audio depende de un proceso técnico que recurre, como ya hemos dicho, a la capacidad de profesionales experimentados y material especializado.

Generalmente, los documentos originales se graban en material de excelente calidad, llegado el caso en un aparato de cinta DAT (Digital Audio Tape) de tecnología digital.
El montaje podrá realizarse también sobre material digital para ser copiado, al terminar el proceso de producción, en un casete de audio analógico para su difusión.
La microcomputadora está especialmente indicada para el montaje y el tratamiento del sonido.
Preserva la calidad del original, y las funcionalidades de tratamiento, mezcla y montaje dan excelentes resultados y permiten una gran sofisticación de los documentos.

La microcomputadora y el tratamiento del sonido 

Como ya hemos visto, la microcomputadora ha entrado con fuerza en el mundo de la producción de documentos sonoros.
Hoy está a punto de sustituir al magnetófono como soporte de grabación del sonido.
La microcomputadora posee la ventaja sobre el magnetófono de poder tratar tanto el sonido como montarlo, mezclarlo, archivarlo y editarlo en cualquier soporte sin alterar la calidad (pudiendo incluso mejorarla).
De momento, no se utilizan computadoras portátiles para hacer tomas de sonido en el exterior, pero es muy corriente grabarlo en estudio, en el disco duro de una microcomputadora.

Figura 26

Esquema de una estación de edición sonora

Como quiera que la Macintosh integra de origen la gestión del sonido, durante mucho tiempo fue la única plataforma que hada el tratamiento sonoro.

Sobre esta plataforma aparecieron muchas tarjetas de nivel profesional para la digitalización del sonido y la conexión de los diferentes elementos de la cadena de creación del sonido en entrada y salida.
Pero aunque la Macintosh (y sobre todo las PowerMac) sigue siendo un soporte privilegiado en este ámbito, el decenio de 1990 se ha caracterizado por el rápido desarrollo de tarjetas de sonido para las PC con norma MPC.
Hoy, la potencia y configuración de algunas Macintosh (de la gama AV) y de las PowerMac permiten digitalizar y tratar el sonido sin tarjeta de extensión, simplemente con un disquete profesional de excelentes resultados: el Deck II de la empresa OSC.

Estas tarjetas y sistemas añaden funcionalidades a los diferentes modelos de Macintosh y PowerMac.
Algunas tarjetas sólo sirven para digitalizar, otras son sintetizadores que trabajan con la norma MIDI y algunas son muestreadoras.
Ciertos sistemas son módulos externos que se conectan a una Macintosh y que permiten tratamientos de gran calidad.

Al principio, las PC compatibles con IBM no disponían de una norma de funcionalidades de audio, y diferentes proveedores crearon tarjetas de extensión acústica para añadirles funcionalidad es de digitalización o tratamiento del sonido.
La norma MPC II establecida por Microsoft define un muestreo del sonido en 16 bits a 44,1 kHz.

Estas tarjetas permiten digitalizar el sonido, controlar un lector de CD-ROM y, a menudo, integrar un sintetizador de sonidos más o menos perfeccionado.

Tabla 13

Tarjetas y sistemas de digitalización y tratamiento del sonido para Macintosh y PowerMac

Existe un número considerable de tarjetas y no siempre es fácil encontrar la que conviene al sistema de que disponemos y al uso que perseguimos.

Muchas veces son difíciles de instalar y configurar.
Es de esperar que la nueva versión del sistema de explotación Windows 95 facilite realmente la integración de los periféricos por medio de la introducción del concepto «plug and play» .

Los soportes lógicos de tratamiento y montaje del sonido permiten digitalizarlo y salvarlo en forma de fichero sonoro, visualizarlo en una ventana, en distintas formas, para representar sus características, y modificar sus propiedades físicas y acústicas.
Las funcionalidades de montaje permiten copiar, cortar y pegar cualquier parte del fichero seleccionado, exactamente igual que un texto o un grafismo, para integrarlo en otra parte del mismo fichero o en otro fichero completamente distinto.
La posibilidad de trabajar en varias pistas permite mezclar diferentes sonidos, por ejemplo músicas, comentarios o ruidos, y ajustarlos en relación con otros.

Todas estas herramientas materiales o lógicas permiten crear y producir cintas de sonido de gran calidad y excelentes resultados, que pueden grabarse en casetes de audio o vídeo al final del proceso de edición, así como en cualquier soporte digital físico adecuado, como el CD-Audio y el CD-ROM, o incluso en línea con las redes, como veremos más adelante.

El vídeo 

La grabación simultánea de la imagen y el sonido en un banda magnética es una tecnología de principios del decenio de 1950 surgida del matrimonio de la televisión (que hasta entonces no podía realizarse más que en directo) y la grabación sonora.
Las primeras cintas magnéticas de vídeo en bobinas medían casi 50 cm de diámetro y 2 pulgadas de grosor.
Los magnetoscopios eran enormes armarios metálicos.
Las cámaras surgidas de la televisión pesaban mucho y el conjunto del sistema era extremadamente difícil de ajustar y mantener en buen estado de funcionamiento.
Hasta principios del decenio de 1970, el montaje se hacía manualmente por medio de una copia efectuar da «al vuelo».

Tabla 14

Selección de algunas tarjetas de sonido para PC compatibles con IBM (norma MPC II)

El primer magnetoscopio portátil de color, llamado «profesional» pese a su calidad de imagen limitada, el U'Matic , apareció a mediados del decenio de 1970 y fue considerado una verdadera revolución.
Permitía una relativa automatización del montaje, especialmente gracias al casete de vídeo de 3/4 de pulgada.
Por supuesto, los progresos tecnológicos que estuvieron en el origen del desarrollo de la informática encontraron aplicaciones en nuevos mercados como el del vídeo destinado al público en general.
La definición de estas normas hacia finales del decenio de 1970 dio lugar a un altercado histórico entre los promotores del Betamax (de Sony) y del VHS (de JVC-Matsushita).
La norma V 2000 del consorcio europeo Philips-Thomson llegó demasiado tarde.
Sabemos que ganó el VHS, gracias a su política de comercialización.
Sus promotores decidieron compartir en todo lo posible la licencia de explotación con la mayoría de fabricantes de televisores y aparatos electrónicos o electrodomésticos.
Hoy, el parque de magnetoscopios se calcula por decenas de millones y no cesa de aumentar.

Tabla 15

Principales programas de tratamiento y montaje del sonido

Sony se vio obligada a reconocer su fracaso en este segmento del mercado.
Sin embargo, al modificar el Betamax (rebautizado Betacam ) para situarlo en la alta gama de la norma profesional que utilizan todos los canales de televisión, Sony se ha impuesto en otro mercado, el del «broadcast», en el que el Betacam es hoy una autoridad.
La respuesta del grupo Matsushita para difundir su norma profesional broadcast M2 ha sido un relativo fracaso comercial.

En el decenio de 1980, estos mismos gigantes de la electrónica rivalizaron de manera idéntica para definir las nuevas normas de las videocámaras destinadas al público en general, que reúnen la cámara, el micrófono y el magnetoscopio en un solo aparato.
Sony lanzó el V8 mm y Matsushita replicó con el S-VHS contra el cual Sony propuso el HI-8 .
En resumen, nos encontramos hoy en el mercado destinado al público en general con una gama de aparatos de grabación de imagen y sonido en los formatos VHS, V8 mm, S-VHS y HI-8 que ofrecen resultados desiguales según los modelos, pero que suelen ser muy satisfactorios en los mejores casos.
Para las necesidades profesionales, especialmente en materia de formación, se admite que el S-VHS y el HI-8 son normas aceptables.
Existe una gama de material en estas dos normas que responde a criterios profesionales.
En las producciones destinadas a la televisión, hoy es muy corriente que cuando las condiciones de rodaje son difíciles y el peso y la incomodidad deben reducirse (o por razones de tipo económico), los reportajes se realicen en formatos ligeros y se finalice el montaje en Betacam SP .

En el ámbito de la formación, si se necesita un vídeo con la configuración de autoscopia , podemos recomendar por razones económicas la utilización del formato VHS.
Si se trata de recoger imágenes y sonidos que deban montarse, son preferibles los formatos S-VHS o HI-8 porque permiten una o dos generaciones (copia y copia de la nueva copia para el montaje) sin excesivas pérdidas de calidad.
Si su difusión precisa una gran calidad de imagen, después de una grabación original en S-VHS o HI-8 el montaje puede realizarse en una norma de calidad superior.

El visionado del original, la selección de las secuencias útiles y la concepción del montaje necesitan muchas lecturas de la cinta, razón por la cual es recomendable efectuar una copia de trabajo en VHS, con una visualización del tiempo codificado en la parte inferior de la imagen.
Esta copia puede leerse y releerse sin temor al menoscabo de la calidad del original.
La visualización del tiempo codificado permite leerlo en la pantalla y anotar con precisión todos los puntos de entrada y salida de cada secuencia seleccionada.
De este modo, el proceso de montaje se efectúa sobre la copia de trabajo.
Cuando se ha terminado y verificado la maqueta, se anotan las entradas y salidas de los planos definitivos y puede llevarse a cabo el montaje final para obtener el master, a partir del cual se realizan todas las copias necesarias para su difusión.

Generalmente, el montaje se efectúa en un aparato formado por dos magnetoscopios dirigidos desde una mesa de mando.
Esta mesa permite programar en un teclado el tiempo codificado de los puntos de entrada y salida de cada secuencia e iniciar así la operación de copia plano a plano, uno tras otro.
Algunas de estas mesas permiten dirigir dos máquinas lectoras para mezclar las imágenes y obtener efectos de sobreimpresión o fundidos encadenados.
Este proceso puede informatizarse, como ya indicamos en un esquema reproducido anteriormente, porque existen programas que manejan con precisión los magnetoscopios, en los que es posible programar muchos puntos de entrada y salida para efectuar el montaje automático y los efectos de transición del vídeo.
El montaje del sonido de la grabación del casete de vídeo original se hace también de la misma manera, en las pistas de sonido.
Se introducen músicas y comentarios poco a poco en la pista de sonido libre, pero también puede conectarse a este aparato una mesa de mezcla de sonidos para facilitar esta tarea.

El formato HI-8 goza de una excelente calidad de imagen y sonido, sobre todo en las cámaras de vídeo profesionales, pero la cinta magnética de su casete es frágil porque es muy fina y poco ancha (8 mm).
El S-VHS presenta una calidad completamente análoga en máquinas equivalentes, en una cinta más robusta y ancha (1/2 pulgada), en casetes compactos o normales, pero a veces la fiabilidad del material depende de las marcas.

Además, hay una compatibilidad progresiva con el formato VHS (cualquier casete VHS puede ser leído por una máquina S-VHS, pero no a la inversa), lo cual permite integrar, llegado el caso, elementos de VHS en documentos S-VHS.

- la calidad de la óptica y del tratamiento de la señal;
- Las características, el número y la resolución de las células del dispositivo de acoplamiento de carga (CCD) que define la imagen;
- las características técnicas del micrófono; 
- la posibilidad de parar los automatismos para poder hacer un ajuste manual de todos los parámetros deseables; 
- la presencia de conectadores BNC o DIN; 
- la solidez, ergonomía, peso y fiabilidad del material.


Figura 27

Esquema de una configuración de montaje de vídeo y cuadro de normas 

Los magnetoscopios profesionales son sólidos y están provistos de conectadores BNC y de un interfaz RS 232 o RS 422 que los hace manejables desde una mesa de mandos o una computadora.
Suelen estar dotados de un mecanismo llamado «corrector de la base de tiempo» ( TBC ) , que corrige los posibles pequeños defectos de la imagen ( drops ) debidos a imperfecciones accidentales de la cinta o de la señal.

Estos últimos años, el casete VHS se ha convertido en un soporte de edición de películas muy popular que ha invadido las estanterías especializadas de los hipermercados y de las grandes superficies dedicadas a la venta de productos culturales.
La edición de programas didácticos de vídeo también se ha desarrollado sobre este soporte, no sólo en el ámbito del aprendizaje de idiomas, sino también para el aprendizaje de la programación y de programas informáticos específicos.
En este sector existe una gran gama de productos.
También se publican programas documentales con fines educativos sobre las ciencias físicas, las ciencias humanas, la medicina la maternidad, los animales, los vegetales y otros muchos temas.
Algunas universidades o asociaciones de carácter científico publican también en casetes de vídeo cursos o contenidos didácticos relativos a tecnologías muy avanzadas.

Al mismo tiempo, cada vez más, se graban en vídeo cursos o comunicaciones y prestaciones pedagógicas diversas para atender necesidades de referencia y archivo.
También se utiliza mucho la autocopia en los casos de aprendizaje.
Los servicios prestados en este ámbito por el vídeo son incomparables.
Antes, ningún medio de comunicación podía grabar la imagen y el sonido de una prestación con una determinada frecuencia temporal (a 25 o 30 imágenes por segundo en vídeo normal, pero también a una imagen por minuto, o por hora, etc.).
De este modo, el alumno puede observar la manera en que efectúa su prestación y modificarla hasta la perfección.
El instructor puede utilizarla para ajustar el desglose de las operaciones o la descripción de los objetos y de los mecanismos de que se trate.

El problema de la compresión de los datos 

La digitalización del vídeo en las microcomputadoras sólo ha sido posible de manera eficaz desde principios del decenio de 1990.
Fue preciso resolver muchos problemas para conseguirlo.
La cantidad enorme de datos que representa la visualización del vídeo a toda pantalla, a 25 o 30 imágenes por segundo y en millones de colores, fue uno de los más importantes habida cuenta de la potencia de procesamiento de los microprocesadores disponibles en aquel momento.
Otro problema era la gestión del sonido y su sincronización con la imagen.
Se debía encontrar una solución física para hacer entrar, procesar y hacer salir las señales de audio y vídeo, pero también era preciso adaptar los sistemas operativos a este tipo de proceso de datos que presenta condicionantes difíciles de resolver.

El microprocesador de la unidad central está limitado por su potencia de cálculo.
El único medio de conseguir procesar la cantidad de datos necesarios para una visualización simultánea aceptable del vídeo y el sonido consiste en reducir en todo lo posible la cantidad de datos que codifican los diferentes parámetros.
Se puede reducir el tamaño y el número de las imágenes que deben visualizarse cada segundo y el número de colores, pero esto no basta, ya que los mecanismos de digitalización del vídeo se basan en el principio de la compresión de datos.
Se trata de eliminar todos los datos redundantes del fichero de imágenes para guardar sólo los datos pertinentes.
Un minuto de vídeo a toda pantalla en millones de colores representa un fichero digital de aproximadamente 1 700 megabytes de datos.
Comprimir este minuto en un factor de 1/20 es llegar a obtener un fichero de 85 megabytes, cantidad que lo hace mucho más manejable.

La primera solución consiste en sustituir la codificación de varios pixels idénticos (o parecidos) contiguos por un solo dato.
La norma de compresión de imágenes fotográficas JPEG ( Joint Photographic Expert Group ) funciona de esta manera.
Con ella se obtienen muy buenos resultados, en términos de calidad, para las imágenes fijas, aunque haya pérdida de información pertinente.
La M-JPEG ( Motion-JPEG ) es una versión de esta norma adaptada a la compresión de imágenes de vídeo, pero los ficheros obtenidos son todavía de tamaño notable.
Sin embargo, este tipo de fichero puede ser procesado por configuraciones de microcomputadoras bastante potentes.

Un fichero bit-map describe cada segmento de vídeo, la calidad de la imagen es excelente y puede obtenerse a toda pantalla.
Sin embargo, al final del proceso de tratamiento se puede comprimir nuevamente el fichero obtenido mediante otros algoritmos de compresión, para reducir el tamaño sin alterar demasiado la recuperación.
En la actualidad, los más utilizados son Cinepack, Indeo y TrueMotion.

La norma MPEG 

Existe otro método de compresión del vídeo, un poco menos capaz que la norma M-JPEG pero más adaptado a una gran difusión:
consiste en eliminar en las imágenes que se suceden todos los elementos que son parecidos, para codificar solamente la diferencia entre ellas.
Es una técnica muy interesante porque puede reducir en un factor de 1/100 la cantidad de datos necesarios para codificar el vídeo.
Esta técnica se utiliza en la norma MPEG 1 (Motion Picture Expert Group) que se creó para difundir aplicaciones de vídeo digitales en plataformas destinadas al público en general.
- a 30 imágenes por segundo (704 x 480) con la norma de televisión norteamericana, y 
- a 25 imágenes por segundo (704 x 576) con la norma de televisión europea 
con una resolución bastante buena en las microcomputadoras dotadas de tarjetas de descompresión de la norma MPEG 1.
La MPEG 2, una versión todavía más perfeccionada de esa norma, permite mejorar aún más la calidad de imagen.
Todavía existen pocas tarjetas de descompresión MPEG 2 , pero empiezan a aparecer programas que no tienen necesidad de ellas.
Sea como fuere, los mejores resultados para el visionado de secuencias de vídeo se obtienen en las microcomputadoras más potentes.

Tabla 16

Las diferentes plataformas tienen extensiones de los sistemas operativos necesarios para gestionar el vídeo digital.
Todos los sistemas compatibles con estas normas y dotados de esas extensiones pueden leer los ficheros de vídeo correspondientes.

Señalemos que QuickTime, la extensión del sistema operativo MacOS, es transportable a otras plataformas.
Efectivamente, QuickTime permite editar una aplicación de vídeo en una plataforma y transferirla para utilizarla en otra.

Igual que para el texto, el grafismo y el sonido, existen también para el vídeo diversos programas que permiten convertir a un nuevo formato los ficheros editados en otro.
Se puede, por ejemplo, convertir, con algunas condiciones, un fichero QuickTime en MPEG 1 o MPEG 2 y viceversa utilizando el programa Sparkle disponible en régimen de freeware en Internet.

Los sistemas de producción de aplicaciones del video digital 

La digitalización del vídeo y el sonido puede efectuarse a partir de microcomputadoras muy potentes que integran funcionalidades de digitalización física y lógica.
Se recomiendan los microprocesadores más potentes del mercado: el Pentium a 130 megahercios o el P6 para las PC compatibles con IBM; el PowerPC 601 a 110 megahercios o el PowerPC 604 y 620 para las PowerMac.
Se elegirán preferentemente las tarjetas de digitalización que funcionan con los buses más rápidos, como el bus PCI, que existe ya en la mayoría de las plataformas y que garantiza tasas de transferencia del orden de 100 megabytes por segundo.
Sin embargo, ciertas soluciones comprobadas funcionan muy bien con los buses tradicionales de algunas plataformas (ISA o NuBUS).
Como nunca tendremos bastante memoria viva - los 20 megabytes de RAM son un mínimo -, es mejor disponer de 64 megabytes para trabajar con comodidad.
Además, la RAM es mucho más rápida que los discos duros y la digitalización será mucho más fluida si se puede hacer en memoria viva.

Como ya hemos indicado, la cantidad de datos que codifican la imagen y el sonido digitalizados es muy importante.
Estos datos deben registrarse, transferirse y recuperarse a velocidades muy importantes a fin de que estén disponibles para su visualización a la frecuencia necesaria.
La grabación de estos datos en los discos duros debe hacerse continuamente, sin las interrupciones causadas por las rutinas automáticas de mantenimiento efectuadas habitualmente sobre todos los discos.
Por consiguiente, se necesitarán no sólo discos duros de gran capacidad (a partir de 2 gigabytes, y lo más frecuente será 9 gigabytes), sino de acceso muy rápido, con tasas de transferencia superiores a 5 megabytes por segundo, que permitan la grabación continua de los datos.
Esos discos corresponden a lo que algunos fabricantes llaman la norma AV.

Figura 28

Esquema de una estación de vídeo digital 

Para aplicaciones como el vídeo, las tasas de transferencia permitidas por los buses y los interfaces pueden causar atascos que limiten el flujo de datos.
Por ejemplo, el interfaz SCSI sólo permite 1,5 megabytes por segundo, en tanto que el vídeo a toda pantalla necesita un mínimo de 3,5 megabytes por segundo.
Con una tarjeta de extensión se puede generar un bus de la norma SCSI-2 (Fast & Wide) que permite tasas entre 10 y 20 megabytes por segundo.

Algunas plataformas disponen de un bus SCSI-2 de origen.

La adopción de buses PCI por parte de la mayoría de los fabricantes de microcomputadoras resolverá este problema y permitirá tasas del orden de 100 megabytes por segundo.

Los discos duros 

Las configuraciones de discos duros «apiladas» (RAID: Redundant Arrays of Inexpensive Disks) permiten tasas de transferencia muy elevadas.
El programa de gestión de estas configuraciones distribuye la grabación de los datos en varios discos sucesiva o simultáneamente para acelerar y asegurar el proceso de acuerdo con ocho modalidades que ofrecen diferentes niveles de seguridad y distintas tasas de transferencia.

Si las prestaciones de la plataforma de edición (o de utilización final) no son óptimas, será necesario reducir el tamaño de las imágenes y su frecuencia (corriendo el riesgo de que aparezcan movimientos bruscos) o aumentar la tasa de compresión cuando se produzca la compilación final del fichero.

Figura 17

Principales tarjetas de digitalización de vídeo

Las tarjetas de digitalización 

Las tarjetas de digitalización se caracterizan por sus prestaciones en términos de potencia y funcionalidades, y por la calidad de la conexión.

Algunas informatizan el vídeo y el sonido y están provistas de entradas y salidas.
Otras únicamente informatizan el vídeo o sólo disponen de entradas.
El tamaño de la ventana de vídeo puede ser, según los casos, de 160 x 120, de 320 x 240 o de 640 x 480 pixels en NTSC (norma norteamericana de codificación de la televisión).
La digitalización de la imagen puede efectuarse en millones de colores, en miles o en 256, a 30 cuadros por segundo o a 60 campos por segundo en NTSC (25 cuadros o 50 campos en PAL).
La digitalización del sonido puede efectuarse en 8 o 16 bits.
Puede haber grandes diferencias entre tarjetas.

Por tanto, las señales de vídeo o audio generadas por un magnetoscopio, una videocámara, un receptor de televisión, un magnetófono o un amplificador de sonido se reciben en entrada y se procesan por medio de la tarjeta de digitalización.
Un programa asociado a esta tarjeta permite definir los parámetros de digitalización y recoger las imágenes y el sonido para salvarlos en forma de fichero comprimido y en el formato que corresponda.

Los programas de montaje de vídeo 

Estos programas de recogida de imágenes están incluidos generalmente en programas de tratamiento de vídeo que tienen muchas otras funcionalidades para el montaje, el ajuste de los parámetros fotométricos de la imagen, la generación de efectos de transición entre las secuencias, la aplicación de filtros en toda una secuencia o parte de ella, etc.
El realizador (o el montador) de la película debe ajustar la longitud de las secuencias de vídeo definiendo los puntos de entrada y de salida de cada plano, imagen por imagen, basándose, a poder ser, en el tiempo codificado con la norma SMPTE que da un código numérico temporal para cada imagen.

Cada secuencia utilizada en el montaje será transferida a «la mesa de montaje».
Como para el sonido, el vídeo se representa en la pantalla por una ventana en forma de sucesión de «pequeñas imágenes» cuyos números proporcionan la longitud de la secuencia considerada.
Algunas pistas de vídeo pueden superponerse, y para pasar de una secuencia a otra existen determinados efectos especiales.
Se puede aplicar a todo un segmento dado un filtro que modifique la apariencia de la imagen.
El sonido figura debajo de la imagen, en una o varias pistas cuyos volumen, duración, mezclas y desfases por exceso o defecto pueden ajustarse para encajar exactamente con las imágenes correspondientes.

Antes de salvar definitivamente un nuevo fichero digital, el trabajo de montaje efectuado podrá visualizarse en una ventana y se podrá proceder a ajustes suplementarios, uno tras otro, hasta obtener satisfacción.
Luego podrá compilarse en forma de película digital el fichero final de la secuencia montada.
Para ello se elegirán y ajustarán el tamaño de la ventana, los algoritmos de compresión y el número de imágenes con el fin de obtener la adecuación óptima entre la potencia y las prestaciones de la plataforma final de ejecución, el tamaño del fichero y la máxima calidad posible.

Algunos de estos programas permiten que la visualización de la imagen en el tiempo codificado quede sincronizada con el bobinado del casete del magnetoscopio durante la lectura o la grabación.

Para que la computadora pueda dirigir el magnetoscopio se necesita, por una parte, que disponga de un puerto del tipo RS 232 o RS 422 y, por otra, que tenga un sistema de control mecánico.
Este sistema puede consistir en una tarjeta de extensión y un programa de dirección, o, simplemente, un programa.
Dotada de este tipo de mecanismo, la microcomputadora tiende a convertirse en un sistema de montaje.
Sin embargo, existen sise temas coherentes que reúnen en un kit todos los elementos necesarios para constituir un sistema de montaje de vídeo digital.
Con todo, conviene distinguir los sistemas de montaje no lineales (llamados también de montaje virtual) y los sistemas de montaje en línea (regidos por una computadora).

Tabla 18

Principales programas de montaje en vídeo

Los sistemas de montaje de vídeo en línea 

Los sistemas de montaje en línea se derivan de los sistemas de pilotaje del magnetoscopio.
Consisten en un conjunto de tarjetas de extensión, cables y programas específicos que permiten regir uno o varios magnetoscopios lectores y un magnetoscopio grabador (véase la figura 29) para efectuar un montaje de secuencias de vídeo clásico sin digitalización.
Se trata del montaje de vídeo tradicional, pero regido por una computadora.
El condicionante principal de este método es que el montaje se efectúa por copia y que cada copia deteriora la calidad de la señal.

Figura 29

Esquema de una configuración de montaje de video en línea 

Tabla 19

Principales sistemas de montaje de vídeo en línea

Los sistemas de montaje en línea van dirigidos a distintos públicos.
Por una parte, tenemos sistemas muy económicos que permiten hacer montajes de vídeo y sonido «de aficionado» con muy pocos medios: un magnetoscopio doméstico, la cámara de vídeo y la computadora familiar.
En general, son sistemas poco fiables pero muy útiles.
Por otra parte, tenemos toda una gama de sistemas profesionales que rivalizan con las empresas de montaje de vídeo clásicas en el terreno de las funcionalidades, pero que son relativamente más económicos.

También existen algunas configuraciones que se benefician de funcionalidades de alta gama que no figuran en los sistemas de vídeo analógicos tradicionales.

Los sistemas de montaje de video no lineales 

Los sistemas de montaje de vídeo no lineales son conjuntos de programas, cables y tarjetas de extensión que permiten constituir, a partir de una microcomputadora y de unos periféricos específicos, una estación de montaje completa que puede digitalizar y montar secuencias de vídeo digital a partir de secuencias grabadas en videocasetes.
La diferencia con los sistemas de montaje en línea reside en esa digitalización: el vídeo es procesado por la computadora.
Este tratamiento digital presenta la ventaja de no alterar la calidad de la imagen ni el sonido, sea cual sea su complejidad, al revés del tratamiento analógico clásico que requieren los sistemas de montaje en línea.

Las secuencias de vídeo se digitalizan sucesivamente, una tras otra, ya sea automáticamente y en serie, después de tomar referencias de los tiempos codificados desde el principio hasta el fin de cada uno de los planos, ya sea manualmente.
Los planos se montarán, empalmarán, trucarán, sonorizarán, titularán y visionarán antes de compilarse.

Una vez editada de este modo la secuencia, podrá grabarse con precisión casi total en un videocasete.
Así podrán unirse varias secuencias, una tras otra, para formar una película.

Estos kits permiten funcionalidades y prestaciones que la reunión de elementos de diversas procedencias no permiten.
Tienen la ventaja de ser coherentes y potentes, hasta el punto de que algunos pueden trabajar en tiempo real para el visionado del montaje y los efectos.
Sus programas de montaje están perfectamente adaptados a la configuración física, lo que optimiza los tiempos de tratamiento, que llegan a ser muy largos en los sistemas mixtos.

La principal ventaja es que estos sistemas no lineales permiten importar ficheros de textos, grafismos, fotografías, sonidos y vídeos elaborados anteriormente o paralelamente, en la mayoría de los formatos correspondientes a su plataforma.
Estos mecanismos son bastante económicos, eficaces y funcionales para la producción de documentos de vídeo de muy buena calidad destinados a la formación, así como para la mayoría de las demás necesidades de producción de programas audiovisuales o televisivos.
Su modularidad les permite integrarse perfectamente en la cadena de edición digital de documentos gráficos, fotográficos y sonoros, por una parte, y en las tecnologías tradicionales de la edición de videocasetes, por otra.
La utilización de estos sistemas permite reducir considerablemente los costos de producción de los documentos de vídeo y poner sus funcionalidades de uso al alcance de todos.

Los soportes ópticos 

Antes hemos presentado la gran familia de los discos ópticos compactos, que se han convertido desde hace poco en soportes de edición muy característicos cuyo éxito comercial está a la altura de sus resultados.
Todo conjunto de ficheros digitales puede ser publicado en un disco óptico compacto.

Para ello basta disponer de una microcomputadora bastante potente, de gran capacidad de almacenamiento en las diferentes normas de los soportes periféricos conectados entre sí por medio de una cadena SCSI rápida: el disco duro de gran capacidad, el lector-grabador de cartuchos SyQuest, el lector-grabador de discos flexibles magneto-ópticos, el lector-grabador de casetes DAT y el lector-grabador de discos ópticos compactos con los diferentes programas de formateado correspondientes a los distintos formatos de discos: CD-Audio, CD-ROM, CD-Foto, CD-Vídeo y CD-I.

Figura 30

Sistema de edición de discos ópticos compactos 

Evidentemente, será necesario disponer de diferentes ficheros digitales que se habrán elaborado en el formato adecuado para editarlos con la ayuda de los programas de edición elegidos.
La presentación y la ergonomía del interfaz gráfico se diseñarán con mucho cuidado con el fin de salir al paso de las preguntas y necesidades del usuario y facilitarle la referenciación, la asimilación y la integración de los contenidos.

Así pues, el disco óptico compacto se editará en un solo ejemplar para ponerse a prueba y evaluarse en las plataformas para las que se ha creado la aplicación.
Después de las correcciones o los reajustes necesarios, el fichero se transmitirá en la forma solicitada al laboratorio, que hará el número de copias requeridas.
A partir del fichero que se le suministre, el prensador producirá una matriz de cristal en condiciones muy rigurosas de limpieza.
Esta matriz de cristal sirve para hacer el número deseado de copias de explotación.
A título indicativo, actualmente el formateado de 600 megabytes de datos de un CD-ROM vale menos de 2 000 dólares de los Estados Unidos.
Prensados en series de 1000, cada disco cuesta menos de 2 dólares de los Estados Unidos.
A ello hay que añadir el posible embalaje: la impresión de las etiquetas o del librito que acompaña al producto, la introducción en el estuche, etc.

La lectura se efectúa introduciendo simplemente el disco en el lector.
Los primeros lectores de CD-ROM eran lentos, giraban a 250 revoluciones por minuto, el tiempo de acceso a los datos era del orden de 360 milésimas de segundo y su rendimiento alcanzaba 150 kilobytes por segundo solamente.
Ahora existen lectores que giran a dos, tres, cuatro e incluso seis veces la velocidad inicial con un rendimiento de 900 kilobytes por segundo.
A partir de dos veces la velocidad inicial, el rendimiento es suficiente para asegurar una lectura fluida de los ficheros de vídeo.
El lector de CD-ROM se encuentra cada día más integrado a la microcomputadora.

Características de la producción de los diferentes formatos de discos ópticos compactos 

Cada tipo de disco óptico compacto tiene una serie de características propias de su historia, de los medios de comunicación que edita y de su utilización.

Intentaremos distinguirlos.

El CD-Audio 

El primer miembro de la familia, el CD-Audio, definido por Philips a finales del decenio de 1970 en un documento llamado "el libro rojo", ha tenido desde su lanzamiento un éxito comercial extraordinario como soporte de la edición musical.
La producción de centenares de millones de discos de esta clase creó una industria próspera que permitió popularizar e incluso trivializar esa tecnología de la edición gracias al abaratamiento de los costos de producción.
Lo mismo ocurrió con la fabricación de los lectores, de los que en la actualidad se han vendido ya decenas de millones de ejemplares y cuyos precios son muy baratos.

Cualquier fichero digital de sonido elaborado en una microcomputadora o en una estación digital especializada puede publicarse en un CD-Audio a partir de una microcomputadora conectada a un grabador de DOC dotado del programa de formateado adecuado.

El CD-ROM 

El libro amarillo publicado por Philips define las especificaciones de la organización material de los datos en el CD-ROM, pero el formateado de los datos, todo lo que se refiere a la estructura del directorio y de los ficheros se deja a la libre elección del creador del disco.
Existen tres normas de CD-ROM: en primer lugar, la ISO 9660 , adoptada en 1987, que proporciona una estructura de fichero para que los datos sean accesibles a partir de cualquiera de las plataformas.
Existen otras dos versiones de ISO 9660 , denominadas HFS ( Hierarchical File System ) para la plataforma Mac y UFS (Unix File System) para la plataforma Unix.

Dos versiones diferentes de la misma aplicación pueden cohabitar en el mismo disco.
Esta circunstancia reduce a la mitad la capacidad del disco por lo que se refiere al programa, pero tiene la ventaja de poderse leer en cualquiera de las plataformas indistintamente.
La parte que se refiere a los ficheros de vídeo, fotografía, grafismo, texto o sonido puede ser compartida por las diferentes versiones si éstas se encuentran en un formato común para las dos plataformas.

De hecho, el CD-ROM se ha convertido en una norma para la publicación multimedia.
Sirve de soporte a toda clase de aplicaciones, desde los juegos hasta las revistas periódicas especializadas, pasando por las enciclopedias, los programas pedagógicos, las visitas a los museos, etc.
Actualmente existen varios millares de títulos vendidos en el mundo entero y todos los años su número se multiplica por dos.
La actualización de los contenidos es muy fácil y todos los años puede salir una nueva versión del mismo título.

El CD-Foto 

El CD-Foto es un formato de edición de datos diseñado por Kodak, en colaboración con Philips, a principios del decenio de 1990.
Su objetivo es proporcionar a los fotógrafos profesionales o aficionados una herramienta que les permita tratar y editar sus fotografías en una gama de soportes digitales compatibles con las prácticas que existen para los fotógrafos en los diferentes ámbitos de la edición.

El CD-Foto se produce a partir de negativos, diapositivas o positivados en papel.
Las fotografías son digitalizadas en estaciones de transferencia especializadas definidas por Kodak, las cuales forman parte del equipo de los laboratorios fotográficos que deseen competir en el sector de la edición.
Al final del proceso, el cliente recibe un CD-Foto (o varios)llamado «Master» .

Puede contener hasta cien imágenes, disponibles en ese disco en cinco formatos diferentes: base 16, base 4, base, 4 base y 16 base, que permiten los cinco tipos de aplicaciones correspondientes.
Es posible hacer positivados en papel de extraordinaria calidad en una impresora especial a partir del CD-Foto.

El principio básico consiste en definir, en primer lugar, formatos de ficheros para la digitalización de las fotografías que garantice una gran calidad de reproducción, en función de la utilización final.

Figura 31

sistema de edición de CD- Foto

La utilización de este CD-Foto se hace de acuerdo con dos modelos que corresponden a una utilización de aficionado o de profesional.
En el primer caso, basta insertar el disco en el lector del CD-Foto (o del CD-I) conectado al televisor para visionar las fotografías por medio de un mando a distancia con una calidad y una comodidad de visión impresionantes.
Funcionalidades creativas de encuadre, teleobjetivo y pase automático o programación permiten crear aplicaciones interactivas.

En el segundo caso, el tratamiento, la edición y la utilización de las fotografías tienen lugar en una microcomputadora, con un lector de CD-ROM compatible con el CD-Foto (como lo son la mayoría de los nuevos modelos).
Esta circunstancia permite obtener en excelentes condiciones fotografías digitalizadas, ejecutables en distintos tamaños, de ficheros correspondientes a las diferentes aplicaciones posibles.

Varios tipos de CD-Foto son posibles en función de la finalidad de las aplicaciones.
Hemos hablado del CD-Foto Master , pero existe también el CD-Foto Master Pro , que puede contener 25 imágenes en formato de fichero 64 base (de 4 096 x 6144 pixels), con indicación del derecho de autor y un sistema de protección de las imágenes contra la piratería.
Existe también el CD-Foto Catalog , que permite almacenar hasta 10 000 imágenes en formato base 16 (de 128 x 192 pixels).
En todos los casos pueden añadirse sonidos, textos y gráficos.
Cada imagen se identifica por un número y unas palabras clave que permiten efectuar la búsqueda de las imágenes por temas desde la computadora.

Mencionemos también otro formato: el CD-Foto Portfolio .
Nos parece especialmente interesante desde la perspectiva que nos concierne.

Permite crear aplicaciones multimedia interactivas a partir de fotografías ya digitalizadas en disco CD-Foto o a partir de cualquier imagen en formatos informáticos TIFF o PICT de 512 x 768 pixels.

Puede contener hasta 700 imágenes de estas dimensiones (o una combinación de 400 imágenes y veinte minutos de sonido, por ejemplo).

Tabla 21

diferentes formatos del CD- foto

Gracias al programa Kodak Arrange it es posible crear la estructura arborescente que definirá los posibles recorridos de la aplicación e incluir las fotografías, los sonidos, los textos y los grafismos que puedan generarse con los programas de creación o tratamiento de imágenes y de sonidos corrientes.
Una vez que se haya puesto a prueba y valorado la maqueta de aplicación, se compilará en forma de fichero único que sirva para prensar el CD-Foto-Portafolio final que se podrá utilizar en cualquier lector CDFoto.
Sin embargo, esta operación final sólo será posible desde una estación integrada de un laboratorio especializado que tenga licencia de Kodak.
Con todo, una utilización directa de esta aplicación multimedia será posible en CD-ROM, por ejemplo en series cortas editadas en el lector-grabador Kodak PCD 200 o en una máquina equivalente, como ya hemos visto en el esquema anterior.

El CD-I 

CD-I es la abreviación de Compact Disc Interactive.
Es una norma que proviene del CDROM por sus especificaciones.
La diferencia esencial reside en que su utilización tiene lugar en un lector específico conectado directamente a un televisor.

Para operar el disco no se necesita recurrir a una microcomputadora.
Este hecho simplifica mucho su utilización, ya que cualquier persona puede introducir el disco en el lector, como un CD-Audio, tomar el mando a distancia y navegar inmediatamente por la aplicación.

Figura 32

sistema de CD-I

En 1987, Philips y Sony crearon conjuntamente este formato para servir de soporte a aplicaciones multimedia interactivas destinadas al público en general.
Al principio, los condicionantes debidos a las limitaciones propias de la tecnología de la compresión sólo permitían la visualización del vídeo en una octava parte de la pantalla.
En estos últimos años se ha enriquecido considerablemente el catálogo de títulos disponibles.
Ha aumentado mucho el número de lectores, en especial en el Japón, donde se ha alcanzado alrededor de un millón de ejemplares gracias a los karaokes.

El lector de CD-I lee el CD-Audio, pero también el CD-Foto.
Esta compatibilidad hace del lector de CD-I una máquina llena de recursos que debería encontrar su lugar en todos los hogares y posiblemente también en las oficinas, o en las salas de formación, si este soporte llegara a ser efectivamente accesible para las aplicaciones profesionales.

Los títulos ahora disponibles en Europa se clasifican en seis categorías: 25 títulos de Educación para avivar el ingenio, otros tantos de Juegos , una docena de títulos de Ocio, y otros tantos de Cultura , de Música y de Cine .
El catálogo se amplía día a día y la oferta debería hacerse cada vez más seductora para el público en general.
Paralelamente a ello, las aplicaciones profesionales podrán también desarrollarse en mayor número sobre este soporte cuando las modalidades de diseño y producción de aplicaciones en CD-I sean más accesibles.

De momento, el CD-ROM resulta todavía un soporte más competitivo para este tipo de mercado, puesto que puede dominarse totalmente a nivel interno y tiene un costo bastante razonable si uno sabe imponerse límites aceptables habida cuenta de sus necesidades profesionales.
Este no es el caso del CD-I, que recurre a sistemas específicos que todavía no se han popularizado y cuya utilización es aún bastante cara.
El hecho de tener que pasar por un proveedor de servicios especializados encarece mucho la operación.

El CD-Vídeo 

Recientemente, un módulo que se inserta en la parte trasera del lector de CD-I ha venido a completar la configuración para poder visualizar en toda la pantalla el vídeo comprimido en un formato MPEG 1.

Este módulo se integra en los nuevos modelos de lectores de CD-I.
Con este mecanismo se pueden grabar hasta setenta minutos de vídeo a toda pantalla en un CD-I.
Con las nuevas generaciones de normas de compresión y los formatos de discos compactos de la nueva generación que hemos mencionado anteriormente será posible aumentar la duración del vídeo en un DOC. 

Los sistemas de grabación de los DOC 

Los discos son «grabados» por un rayo láser que modifica puntualmente en tiempo real la estructura de la capa de grabación para codificar la información.
La duración de estos discos varía entre diez y cien años según la calidad.
Pueden leerse en cualquier lector correspondiente a la plataforma y formato para los que han sido editados (CD-Audio, CD-ROM, CD-Foto, CD-I y CD-Vídeo).

Todos los programas de grabación de los discos ópticos compactos disfrutan de funcionalidades especiales que les permiten grabar CD-ROM para Macintosh con la norma HFS, y para las PC con la norma ISO 9660, o CD-ROM mixtos que pueden leer indistintamente ambas normas.
También pueden grabar los CDAudio, CD-I y CD-Vídeo, o incluso servir para grabar los datos a modo de salvaguardia.
Estos programas pueden ser compatibles con diferentes tipos de lectores-grabadores o, por el contrario, con un solo lector.

El lector-grabador es un periférico SCSI que se caracteriza por su velocidad de rotación (dos, cuatro 0 seis veces la velocidad normal de rotación del CD-ROM), lo que incrementa en igual proporción la cantidad de datos transferida por segundo.
Este aumento acelera también la velocidad de grabación del disco.
Los lectores con una velocidad de rotación de seis veces la velocidad normal graban un CD-ROM en diez minutos, más o menos.
Para pequeñas series es posible grabar simultáneamente el mismo fichero en varios grabadores conectados a la cadena SCSI.

Antes de grabar un disco óptico compacto, es necesario disponer de la aplicación que se desea.

Los programas de creación de aplicaciones multimedia 

En la parte referente a la metodología de la producción hemos visto que la creación de la aplicación desemboca generalmente en la producción de un guión que define con precisión la configuración general de la aplicación, su contenido y las funcionalidades ofrecidas al usuario, así como, llegado el caso, al evaluador.
Por consiguiente, en esta fase los documentos correspondientes a los contenidos que deben comunicarse están disponibles en formas diferentes.
La primera tarea deberá ser digitalizarlos y salvarlos en forma de fichero digital con el formato adecuado para su integración y explotación final.

Tabla 22

Principales programas de grabación de discos ópticos compactos 

La fase siguiente consistirá en integrar estos documentos en forma de aplicación única, en función del guión, con el fin de ofrecer al usuario todas las funcionalidades de recorrido de estos documentos que sean necesarias para una buena transmisión del mensaje.
La elección del programa de creación de esta aplicación multimedia (algunas veces denominada sistema o programa autor) es estratégica y muy importante.
Esta decisión deberá tomarse previamente a la búsqueda o creación de los contenidos y deberá desprenderse del análisis de varios factores relativos al tipo de aplicación: las funcionalidades que deben ofrecerse al usuario, el soporte de la publicación y las prestaciones medias de la plataforma o de las plataformas elegidas.

Tabla 23

principales programas de creación de aplicaciones multimedia

¿Está adaptada la plataforma de edición de que disponemos al tipo de aplicación que queremos crear y a la plataforma de difusión que hemos elegido? 

Para empezar, es necesario que las funcionalidades de edición y las prestaciones del sise tema de edición estén a la altura de los resultados esperados, pero es importante no equivocarse y preservar la inversión aprobada para la creación de esta aplicación a fin de poder utilizarla en todos los soportes y todas las plataformas deseables en el futuro.
Los programas de creación de aplicaciones multimedia están actualmente muy perfeccionados, permiten editar una aplicación en una plataforma y convertirla para ejecutarla en otras.

Los programas de creación de aplicaciones multimedia son transportables a otras plataformas.
Por tanto, es determinante realizar una buena elección.
Una aplicación creada en una plataforma con un sistema autor de prestaciones limitadas que se utilice en una plataforma que permita funcionalidades y presentaciones más sofisticadas dará un resultado decepcionante.
Por consiguiente, es muy importante no equivocarse en esta elección.

La elección de un programa es determinante porque define las funcionalidades de creación que el sistema autor ofrece al creador, por ejemplo, las funcionalidades de creación,tratamiento o montaje de documentos.
Desde luego, los documentos se han creado previamente, pero su integración presupone un mínimo de funcionalidades de creación para conjuntarlos.
Algunos programas están mejor provistos de instrumentos de edición que otros.

Por otra parte, la misma concepción del sistema de autor está basada sobre una idea, una metáfora que orienta su utilización y dicta su lógica de funcionamiento.
Esta manera de funcionar se adaptará más o menos a la mentalidad y a los métodos de trabajo del autor que la utilice, pero también será más o menos conveniente según los tipos de aplicación y plataforma escogidos.

La metáfora más tradicional en el mundo de la informática es la del programa, la del guión, la lista de instrucciones dadas al procesador para que las ejecute.
Es la más difícil de utilizar por el autor, que en primer lugar ha de dominar el lenguaje: es la más rudimentaria pero también la más fiable.

Todas las otras metáforas vuelven a utilizar la misma solución, pero permiten que personas que no son informáticos editen con relativa facilidad aplicaciones multimedia manipulando objetos sobre la pantalla con el ratón.

La manipulación de objetos es en sí una metáfora y puede considerarse que los elementos que deben integrarse son objetos.
Las combinaciones de iconos y esquemas u organigramas proporcionan una lógica muy práctica para representar la configuración general de la aplicación, localizar el elemento deseado y modificar los parámetros que se deseen.

La metáfora de las pantallas y la partición es indudablemente la que gracias al programa Director ha conquistado a los creadores de los más famosos productos actualmente en el mercado, es decir, los CD-ROM en cualquier plataforma y las consolas de juegos.
Al principio, este programa aprovechaba algunas funcionalidades de la plataforma Macintosh para la que se había creado y además era muy fiable.
Muy pronto fue posible convertir sus aplicaciones para ejecutarlas en una PC.

Ahora, Director se utiliza directamente en las PC con entorno Windows.
Esta metáfora consiste en definir las pantallas organizando los diferentes elementos en su interior, y en prever, como en una partitura musical, la sucesión en el tiempo de esas pantallas de acuerdo con las modalidades y la interactividad definidas por el autor y de las cuales el usuario dispondrá a voluntad.

Las tarjetas (como un juego de cartas o un paquete de fichas) son una metáfora derivada del célebre programa HyperCard, que fue pionero en la creación de aplicaciones del tipo hipermedia, pero que no hemos mencionado en nuestro cuadro porque no es fundamentalmente transportable a otra plataforma (aunque se puedan compilar las pilas HyperCard para ejecutarlas en una PC a través de ToolBook gracias a un programa denominado ConvertIt).
Algunos programas nuevos vuelven a utilizar esta metáfora.
Las tarjetas se crean en el formato deseado y en ellas se pueden pegar unos botones, los cuales permiten pasar de una tarjeta a otra definida previamente.
Se puede pegar cualquier documento sobre una tarjeta, y cualquier elemento (documento o fracción de documento) puede convertirse a su vez en un botón que remita a otro documento contenido en otra tarjeta.

Algunos editores de estos programas de creación de aplicaciones multimedia graban la difusión en el mercado de las aplicaciones salidas de su producto con derechos más o menos importantes que deben pagarse de acuerdo con ciertas modalidades particulares definidas en la licencia de utilización.
Afortunadamente, no todos los editores eligen esta política, sino que algunos eximen de derechos la difusión de las aplicaciones derivadas de sus productos.
También este tema debe examinarse con cuidado antes de elegir el sistema autor a fin de evitar cualquier sorpresa desagradable en el último momento.

Entre las funcionalidades existentes en un sistema autor, la presencia de herramientas de conversión de las aplicaciones al formato de Internet es una característica notable.
Entre todos los soportes para la difusión de las aplicaciones multimedia, Internet es actualmente uno de los que ofrece las perspectivas más interesantes, pero abordaremos esta cuestión en el próximo capítulo.

Los terminales interactivos y la simulación 

Un terminal interactivo es un sistema construido alrededor de una microcomputadora multimedia en el que sólo se ven la pantalla y los altavoces.
Esta pantalla es en realidad el interfaz de diálogo sensible al tacto, se diría que es táctil.

Un mensaje visualizado en la pantalla invita al usuario a tocar el icono deseado e inmediatamente aparece la secuencia de información correspondiente.
Estos aparatos se instalan generalmente en lugares públicos, a disposición gratuita de los usuarios y están destinados a dar informaciones.

Es una manera muy atractiva de presentar los mensajes.
El contacto con la pantalla ahorra cualquier interfaz de diálogo móvil a base de teclado, ratón, palanca de mando o bola, que acaban siempre por descomponerse en con tacto con los usuarios torpes o malintencionados.

Figura 33

esquema de terminal interactivo

La pantalla táctil no corre el riesgo de estropearse, puesto que nada se mueve y, además, su contacto tiene algo de maravilloso porque basta señalar con el dedo el objeto codiciado, como si de un mago se tratara, para obtener la información correspondiente.
Los bancos, por ejemplo, utilizan mucho estos sistemas para dar informaciones relativas a la gestión de las cuentas de sus clientes e incluso como cajeros automáticos para proporcionar billetes de banco, cuando se les acopla un robot especializado.
En los países ricos es con mucho la aplicación más extendida y popular.

A menudo, también se utilizan los terminales interactivos para aplicaciones de promoción en los grandes almacenes o centros comerciales, para orientar a los pasajeros en las estaciones y los aeropuertos, y para proporcionar informaciones en los museos las exposiciones o los salones profesionales.
Los terminales interactivos se usan también en el ámbito de la empresa para controlar los procesos de producción o proporcionar informaciones didácticas.

La pantalla táctil 

Se trata generalmente de una hoja que se fija en la pantalla y que permite localizar las coordenadas del punto en que el dedo se ha situado a fin de indicárselas al programa de gestión del sistema.
Algunas veces esta hoja está integrada en la pantalla, lo que hace que el mecanismo sea más fiable.
También puede sustituirse la pantalla de tubo por una pantalla de cristal líquido, sustitución que hace que el sistema sea más ligero y sencillo.
Los fabricantes de pantallas táctiles utilizan diversos medios de detección: rayos infrarrojos, campos magnéticos u ondas acústicas.
Cada tecnología se caracteriza por una sensibilidad y un tiempo de respuesta diferentes.

Es necesario que estas pantallas sean resistentes a choques, agentes químicos u orgánicos depositados por los dedos de los usuarios y líquidos que puedan derramarse por encima, como bebidas calientes o frías y detergentes u otros productos de limpieza.

Toda aplicación multimedia interactiva desarrollada para ejecutarse con el ratón en una microcomputadora puede, en principio, transportarse para su ejecución en un terminal interactivo.
Para ello es necesario tener en cuenta los condicionantes específicos de la aplicación y el entorno del terminal: no sólo el entorno físico (espacio, localización, luces, ruidos) o el ámbito psicológico (tensiones, distracciones, nervios) en que se encuentra el usuario, sino también, simplemente, el grosor de su dedo.

La simulación y la realidad virtual 

La modelización de sistemas complejos o mundos virtuales, así como su forma de gestión o navegación, permite al usuario simular su exploración y ejercitarse en su aprendizaje.

Figura 34

principios de un sistema de realidad virtual

La palabra "simulación" es la denominación genérica que caracteriza la representación interactiva de objetos o de escenas en 3D obtenida por cálculo en una pantalla de computadora.
Esta operación también se denomina «imágenes generadas por computadora».
Actualmente están en el mercado muchos juegos y aplicaciones didácticas que permiten simular la conducta de máquinas, vehículos o ingenios más o menos fantasiosos en estaciones especializadas que, de hecho, son como máquinas de juegos de parques temáticos o centros recreativos.
Muchos de estos juegos o aplicaciones didácticas se venden también en forma de CD-ROM, casetes o discos flexibles para consolas de juegos personales o microcomputadoras.
Este mercado ha conocido un desarrollo muy importante en los últimos años y ha dado origen a toda una industria.
Lo que se llama realidad virtual es mucho más complejo.

En primer lugar, consiste en la representación de objetos o escenas en 3D en forma de dos imágenes calculadas en tiempo real (instantáneamente) desde dos ángulos ligeramente distantes para obtener la tercera dimensión en visión estereoscópica.
Estas imágenes se contemplan a través de un casco que lleva el usuario, de forma que cuando el casco se mueve las imágenes se modifican proporcionalmente de manera inmediata gracias a un sistema de control.
Además, un interfaz de diálogo manual, palanca o guante digital permite que el operador intervenga en este espacio, se desplace y se apodere de los objetos para examinarlos, o bien los desplace o deforme.
También puede añadirse a la escena una dimensión sonora y procesarla de la misma manera que las imágenes.

Estos sistemas existen para aplicaciones específicas, didácticas o lúdicas, aunque se trata de sistemas especiales muy potentes, de máquinas dedicadas a estas aplicaciones, utilizadas por empresas, parques temáticos o centros recreativos que emplean varios procesadores que actúan en paralelo.
La inmersión del operador es proporcional a la recuperación y el realismo de las imágenes y sonidos.
La experiencia es impresionante y permite una impregnación muy fuerte del alumno o el usuario.
Con este sistema se pueden representar conceptos muy abstractos y hacer explícita la complejidad desde una perspectiva didáctica, en un entorno muy concreto.

Los programas que permiten modelizar espacios y escenas complejos en 3D con iluminaciones, sombras, reflexiones, refracciones, presentaciones y funcionalidades de animación se encuentran en el mercado y son relativamente fáciles de utilizar.
En cambio, los sistemas de realidad virtual no son tan corrientes.
Téngase en cuenta que el cálculo de una sola de estas imágenes puede necesitar varias horas según el sistema y el microprocesador de que se disponga.
Calcular una animación de objetos que se desplazan en una trayectoria, como una sucesión de imágenes, necesita mucho más tiempo.
Así pues, el cálculo en tiempo real con un acabado realista de la imagen requiere una gran potencia de cálculo que todavía no es posible en una microcomputadora normal y ni tan siquiera en una estación de trabajo sencilla.
Por supuesto, existen kits de tarjetas y programas que permiten el cálculo en tiempo real de las imágenes (e incluso de los sonidos), que correspondan, en función de los movimientos de la cabeza del usuario, a la modificación de la visión estereoscópica de un espacio previamente modelizado.
Sin embargo, el acabado de estas imágenes no es muy realista y la impregnación del usuario tampoco es tan intensa como en las máquinas especializadas.
El número de colores de la imagen es reducido, los contornos de los objetos borrosos, los colores no tienen contraste y el movimiento de las imágenes es más o menos brusco.
Sin embargo, estos sistemas tienen el mérito de existir y de hacer posible algunas experiencias o utilizaciones determinadas: industriales, didácticas o lúdicas.

En la industria, una de las tendencias actuales más características es la utilización de la realidad virtual por parte de las empresas para evaluar y poner a prueba virtualmente los productos, los sistemas, las máquinas o los vehículos concebidos en las estaciones de diseño asistido por computadora (DAC) de las oficinas de proyectos.
Se trata de comprobar su viabilidad, funcionalidades de uso o conducta y prestaciones, y mejorarlas antes de empezar la fabricación de los primeros prototipos.
Con ello se consigue acortar el ciclo de diseño de los productos, mejorar la adecuación a las necesidades del mercado y disminuir el número de fracasos comerciales.

Las redes 

La producción y difusión de ficheros digitales, documentos o aplicaciones multimedia efectuada a través de las redes tiene un gran futuro.
En la actualidad están surgiendo funcionalidades de comunicación de las que no conocemos todavía todas sus virtudes ni todos sus límites.
Sus ventajas son muy interesantes y los servicios que prestan revisten hoy en día una importancia estratégica para las empresas y las instituciones públicas o privadas, nacionales o internacionales.

Estas nuevas actividades son, por orden de complejidad: el correo electrónico, el intercambio de documentos electrónicos a distancia, el suministro y búsqueda de informaciones, la visioconferencia, la formación a distancia, el trabajo en colaboración, la actualización automática de documentos de trabajo y la integración del proceso de diseño, fabricación y comercialización de los productos y del seguimiento de la gestión y los resultados.
El modelo que aparece en el horizonte es precisamente el de la empresa virtual.
Un modelo (¿utópico?) de estructura interactiva que sepa hacer frente inmediatamente a todas las incertidumbres de la coyuntura y ofrezca una respuesta óptima.

El correo electrónico introduce poco a poco, en las empresas y las instituciones, prácticas de comunicación nuevas que prescinden hábilmente del espacio, el tiempo y el número o la disponibilidad de los destinatarios.

Escrito sobre la computadora de su autor con la ayuda de un programa específico que se parece a un tratamiento de textos simplificado, el mensaje se dirige en forma de fichero ASCII, de manera casi instantánea y transparente, hacia el buzón electrónico de su destinatario.
El mismo mensaje puede enviarse simultáneamente a una lista de destinatarios diferentes, de la misma manera sencilla.
El destinatario leerá el mensaje cuando pueda o quiera, y lo contestará según el orden de sus prioridades.
La transmisión del mensaje se produce en los dos sentidos, inmediata, inmaterial e independientemente de la localización de los interlocutores o de la distancia que los separa.
Si es necesario, este diálogo por escrito puede ser continuo.
También pueden crearse periódicos o mensajerías electrónicos, gracias a programas de comunicación multientorno como First Class.

En la red adecuada y con los programas necesarios, los interlocutores pueden prolongar este diálogo verbalmente, e incluso visualizar recíprocamente su imagen en una ventana de su pantalla.
Si es necesario, otros interlocutores pueden unirse a ellos.
Durante la reunión tendrán lugar intercambios de documentos digitales (o reales) entre los participantes, que se harán cargo de ellos y reaccionarán como corresponda en tiempo real.
En el caso de programas de trabajo en colaboración, los documentos digitales pueden incluso compartirse entre los interlocutores en su pantalla individual, trabajando juntos, simultáneamente, sobre el mismo tema, pudiendo aportar cada uno su propia contribución, sus observaciones sobre la prestación de sus colegas y sus propuestas de rectificación.

La formación en la empresa se aprovecha de este soporte mediático para deslocalizar y acelerar las reuniones periódicas de reconversión o revisión cuando los empleados tengan necesidad de ello.
Se acabaron los desplazamientos de los conferenciantes o de los alumnos; incluso los documentos viajan de manera digital.
Los documentos de trabajo pueden compartirse a fin de que cada uno pueda efectuar a su vez los ejercicios, individualmente o a la vista de todos los participantes, según los objetivos pedagógicos.
Todos, alumnos, colegas o formadores, pueden, si conviene, intervenir o corregir en directo.
El interés pedagógico, en lo que se refiere a la formación con presencia física, es que cada participante puede tener ante sí el mismo documento o la misma presentación en el mismo instante, que está solo ante su pantalla y que el formador puede observarlo en sus actitudes y en sus respuestas.

Dando un impulso todavía más profundo a la integración del trabajo de colaboración a distancia en tiempo real, las herramientas de coordinación actualizan continuamente los documentos en función del trabajo efectuado por cada uno.
Así pues, los formularios y las programaciones están siempre al día y ofrecen una visión panorámica instantánea del estado de la estructura.
Esta reactualización automática de los documentos en tiempo real en función de las tareas efectuadas en todos los puestos de trabajo corresponde a una racionalización de las tareas de oficina.
Este sector, típicamente terciario, hasta ahora había seguido siendo artesanal, escapando al fenómeno de la industrialización.
La posibilidad de compartir el plan de trabajo permite que cada miembro del equipo ponga al día permanentemente el calendario, contenido o naturaleza de las tareas que debe efectuar.
La utilización de estas diferentes soluciones Tiende a reducir los riesgos de un desfase frente a la evolución rápida y aleatoria de los distintos ámbitos en que participa la empresa: la administración, la situación del mercado, la concepción de las operaciones, la comercialización, la comunicación, la formación, el desarrollo de los productos, los suministros, la producción o la difusión.

Las soluciones técnicas 

Según hemos visto anteriormente, una red local es una serie más o menos importante de microcomputadoras denominadas «clientes» que están conectadas entre sí por cables específicos a fin de comunicarse de acuerdo con ciertas modalidades.
Esta red está gestionada por una microcomputadora denominada «servidor», con la ayuda de un programa de gestión de redes.

Muchas soluciones de redes locales permiten actualmente conectar microcomputadoras entre sí para intercambiar informaciones con tasas de transferencia de 4 a 16 megabytes por segundo.
Estas redes están concebidas para trasmitir paquetes de datos de forma intermitente a distancias que no sobrepasen algunos kilómetros y pueden funcionar en el interior de un edificio para resolver necesidades ofimáticas.
No sirven para la transmisión de un flujo continuo de datos, por ejemplo de audio o de vídeo, con arreglo a los criterios profesionales clásicos que requieren soluciones técnicas que calificaríamos de «pesadas».
En cambio, existen soluciones «ligeras» para transmitir datos de vídeo o de audio por redes locales sencillas en condiciones aceptables.

Ethernet es la solución más extendida para crear redes locales.
Es un protocolo que autoriza la transmisión de datos por paquetes en redes de cable coaxial, hilo de cobre ordinario o fibra óptica con una tasa de transferencia que puede alcanzar 10 megabytes por segundo.
Una versión más potente de este protocolo, llamada Fast-Ethernet, garantiza un rendimiento de 100 megabytes por segundo y puede coexistir en una red de la norma Ethernet y transmitir datos de sonido y vídeo en excelentes condiciones.

También citaremos las normas FDDI (Fiber Distributed Data Interface) y ATM (Asynchronous Transfer Mode), que son soluciones más caras pero que permiten conectar entre sí, en redes de banda ancha, redes que funcionan con otros protocolos, ofreciendo garantías suplementarias para la transferencia de datos multimedia.

Varias redes locales pueden conectarse para crear una red ampliada (WAN: Wide Area Network) en líneas de telecomunicación especializadas de alto rendimiento.
Protocolos e interfaces de diálogo comunes permiten que redes locales diferentes se comuniquen entre sí.
Una solución para conectar redes locales heterogéneas entre sí es el protocolo TCP/IP (Transmission Control Protocol/Internet Protocol).
Hoy día es uno de los más económicos y más fáciles de instalar y se impone ampliamente tanto entre los usuarios individuales como en las empresas.
No obstante, la tasa de transferencia de Internet es variable y está en función del rendimiento de la línea especializada o del tráfico que la red soporte simultáneamente en el circuito utilizado durante la conexión.

La conexión telefónica directa entre dos microcomputadoras alejadas entre sí (o entre una microcomputadora alejada y una red local) a través de los modems es una solución práctica y fácil de establecer para las conexiones puntuales entre socios, colaboradores o redes propietarias privadas y públicas, como Internet.
En estos casos se utilizan los programas de comunicación adecuados para transmitir o recuperar correo electrónico, fax o cualquier documento en forma de fichero digital.

Programas de control a distancia permiten también compartir un disco duro entre diversas microcomputadoras alejadas, conectadas por líneas telefónicas.

El correo electrónico 

Las funcionalidades de base del correo electrónico están hoy integradas, en forma de extensiones, en los sistemas operativos de las diferentes plataformas.

Los mensajes o los documentos multimedia pueden editarse seleccionando la dirección del corresponsal en el directorio y enviarse de manera transparente a cualquier plataforma de las diferentes redes, utilizando la orden «enviar».
Los mensajes se recibirán en el buzón, que se abre pulsando sobre el icono correspondiente, y luego quedarán clasificados.
No se habrá gastado ni una sola hoja de papel.
También pueden encontrarse en el mercado programas especializados para llevar a cabo estas mismas tareas en las microcomputadoras que no disponen de programa en origen.

El Internet se ha convertido en una norma universal para el correo electrónico internacional, nacional o incluso interno.
Asimismo, el correo electrónico es la aplicación más utilizada habitualmente en esa red.
En Internet no se cobra al usuario cada mensaje como en el caso de los sistemas X400 o las mensajerías privadas.
En esa red el costo no está en función de la distancia como en el caso de las conexiones telefónicas directas.
Es la solución más económica y además es transportable a otros entornos.

Algunas extensiones del correo electrónico de Internet permiten enviar y recibir informaciones multimedia gracias a la norma MIME (Multimedia Internet Mail Extensions).
Estas informaciones se insertan y simulan en un mensaje electrónico, y si el sistema permite la visualización de los datos se podrá leer el mensaje multimedia.

También existe una funcionalidad de correo electrónico específica de Internet: la de los grupos de información (frecuentemente denominados "newsgroups").
Estos grupos son foros públicos temáticos específicos en que el usuario puede leer informaciones relativas a los temas discutidos anteriormente, disponibles en el fichero de FAQ (Frequently Asked Questions).
Luego se puede asistir a las discusiones que estén en curso o participar en ellas.
Existen varios miles de grupos sobre los temas más variados.
Están clasificados por categorías, de forma que se puedan recorrer para descubrirlos o crear nuevos grupos sobre un tema inédito que tenga un interés determinado.

En estos grupos existen muchas listas de envío (frecuentemente denominadas " mailing list ") que permiten enviar simultáneamente un mismo mensaje a cada uno de los corresponsales incluidos en las listas para plantearles alguna cuestión sobre el tema de que se ocupa el grupo o proponerles una información o una respuesta específica a una cuestión planteada anteriormente.
Así pues, en estos foros se pueden encontrar informaciones y contenidos muy sutiles sobre los más diversos temas, lo que constituye una mina inagotable de recursos para la formación.

La visioconferencia 

Hemos elegido como otros autores la denominación «visioconferencia» con el fin de designar la digitalización y la transmisión de señales de audio y vídeo en una microcomputadora para realizar conferencias a distancia.

En oposición a esta denominación, la palabra «videoconferencia» ha quedado para caracterizar las conferencias efectuadas por los medios tradicionales analógicos de la televisión herciana o por cable sin microcomputadora, aunque cada día se habla más frecuentemente de videoconferencia por microcomputadora.

Existen muchas soluciones que permiten conectar a distancia varias microcomputadoras para que sus usuarios puedan ver y entender a sus interlocutores, y unos y otros trabajen sobre un mismo documento e intercambien ficheros.
La primera categoría de estas soluciones consiste en conectar las microcomputadoras directamente entre sí a través de la red telefónica clásica o de una red digital como la RDSI (Red Digital de Servicios Integrados).
Para ello existen en el mercado kits de conexión para todos los entornos, y hay algunos para varios entornos.

Generalmente, estas soluciones consisten en una tarjeta de extensión que permite entrar las señales de vídeo y sonido y conectar con la red telefónica normal o la RDSI.
Las señales se digitalizan y comprimen para poderlas transmitir a través de la red.
A su llegada se descomprimen y visualizan en el sistema del destinatario.
El modelo Visit Video prevé el mando a distancia de la cámara por medio de un programa.
Todas estas soluciones permiten compartir lo que se ha llamado la «pizarra blanca» sobre la cual se visualizan los documentos o las aplicaciones propuestas para una sesión de trabajo colectivo.
El respeto de la norma H 320 y de las normas conexas garantiza una interoperatividad mínima de las diferentes soluciones en un mismo entorno.
Algunos de estos kits existen en las dos versiones MacOS y Windows, y permiten transportar la comunicación de un entorno a otro.

Tabla 24

principales kits de visioconferencia

La segunda categoría de soluciones se basa en Internet.
En efecto, como hemos indicado anteriormente, varios programas como el CU-SeeMe, distribuidos gratuitamente en la red, permiten intercambiar imagen y sonido entre dos interlocutores que posean sendas microcomputadoras dotadas de capacidades de digitalización de vídeo y sonido, conectadas simultáneamente con modems rápidos.
La frecuencia de las imágenes en blanco y negro es variable, del orden de cuatro imágenes por segundo, y el sonido es bastante claro, lo que resulta suficiente para su aprovechamiento, sobre todo teniendo en cuenta que su adquisición y su utilización son muy económicos.

El kit VideoVu que vende actualmente Future Communications Systems permite enviar y recibir una señal de audio y vídeo a 15 imágenes por segundo a través de un modem y con una cámara de vídeo, por medio de paquetes de datos en el formato de una versión de protocolo TCP/IP denominada Unicast.

Otras tecnologías con más prestaciones, como las que utiliza el protocolo TCP/IP Multicast, están en estos momentos en curso de experimentación y ofrecen incluso mejores resultados: pronto tendremos sonido y vídeo de buena calidad.
Internet está destinado a convertirse en un soporte privilegiado para la visioconferencia.

La informática de grupos 

Los programas de trabajo en colaboración (Groupware) se llaman a veces informática de grupos y paquetes de programas.
Son conjuntos de herramientas integradas que permiten el trabajo en grupo a distancia.
- ofimática (tratamiento de textos, grafismos, tableta gráfica y PreAC); 
- comunicación (mensajería, guía telefónica); 
- gestión de recursos (agenda, planificación); 
- coordinación (formularios, workflow); 
- gestión de la información (base de datos, foros). 


Estos programas integrados permiten crear aplicaciones colectivas diseñadas para las necesidades profesionales de cada empresa u organización.
Las herramientas individuales que son los programas de tratamiento de textos y de grafismos y las tabletas gráficas se convierten en herramientas de trabajo en equipo que distribuyen, comparten y actualizan la información en función de la actividad.
Esta conversión permite optimizar la gestión de los proyectos y el trabajo de los equipos.

Tabla 25

principales programas de informática de grupo

La riqueza y facilidad existentes para el desarrollo de estas aplicaciones de trabajo en colaboración son el resultado de las funcionalidades de las diferentes soluciones que se encuentran actualmente en el mercado.

Algunos programas como Notes y 4D se han popularizado por la relativa simplicidad de desarrollo de las aplicaciones y la buena integración de todas sus herramientas.

Un método simple y económico consiste en utilizar las soluciones listas para funcionar que se ofrecen habitualmente y adaptarlas poco a poco a las necesidades específicas de la estructura.
Si no, será necesario lanzarse a un desarrollo informático bastante complejo para los profanos o recurrir a los conocimientos de un especialista.

Estas soluciones funcionan en plataformas diferentes y redes locales heterogéneas, pero su interoperatividad no es todavía efectiva, es decir, no pueden aún comunicarse plenamente entre sí.
Algunas, que se adaptan a las normas de interoperatividad OLE o AOCE, pueden intercambiar documentos, pero, de momento, la colaboración no va más lejos.
Dicho de otra manera, una estructura que utiliza Notes no puede colaborar plenamente con otra que utilice Exchange o Workgroup, por ejemplo.

Sin embargo, la lógica del derecho de propiedad que preside el desarrollo de estos sistemas de optimización o automatización de los métodos de trabajo y gestión de proyectos se enfrenta a la necesidad de conexión y comunicación con el mundo exterior.
La apertura sobre Internet es un objetivo cada día más prioritario para las empresas y las organizaciones.

Aunque es verdad que a menudo la información tratada por los programas de trabajo en colaboración es altamente confidencial y estratégica y debe ser objeto de gran protección, no lo es menos que ha de ser objeto de comunicaciones parciales con los socios de la estructura.

Por ejemplo, los dos módulos externos de Notes, Tile e InterNotes permiten convertir una base de datos Notes en páginas del servidor World Wide Web en el Internet.
Cualquier usuario de Internet puede entonces consultar esta base de datos de Notes si está disponible de forma no cifrada en un servidor World Wide Web.
El usuario podrá consultar la base de datos, pero no dispondrá de todas las funcionalidades del trabajo en colaboración de Notes ni podrá borrar o actualizar los documentos de la base de datos.

Sin embargo, su interés reside en que estas nuevas funcionalidades de Notes aumentan el número de interacciones posibles con la estructura.

El Internet 

Desde hace dos o tres años, el Internet se ha convertido en un fenómeno internacional de primera magnitud.
El crecimiento del número de sus servidores, funcionalidades, aplicaciones y usuarios se efectúa a una velocidad y en unas proporciones impresionantes.
El Internet empezó en 1962, en una época en que la microcomputadora estaba todavía en el limbo cuando Paul Baran (Rand Corporation) publicó la descripción de las redes de comunicación de paquetes de datos en «On Distributed Communication Networks», y en 1969 el Departamento de Defensa de los Estados Unidos de América puso en práctica este concepto en el marco de la red experimental ARPANET.

El principio consiste en fraccionar en pequeños paquetes de igual tamaño los datos que deben transmitirse, y encaminarlos hasta su destino final por cualquier ruta disponible en la red.
AL principio del paquete se escribe su origen y destino y a qué otro paquete debe vincularse para recomponer los datos originales a su llegada.
A lo largo de la red, los paquetes son dirigidos por computadoras que calculan qué segmento de la red disponible está menos cargado para llegar más rápidamente a su destino.
Con este sistema, la comunicación puede continuar incluso si se destruye una parte de la red.
La conmutación del mensaje se gestiona por medio de la inteligencia de los terminales, que se van turnando a lo largo de la difusión.
Lo contrario de lo que ocurre con el teléfono o la televisión, en que la inteligencia de la conmutación y la difusión están centralizadas.

Figura 36

esquema de una red Internet

El protocolo de comunicación TCP/IP (Transmission Control Protocol/Internet Protocol) que regula el Internet funciona con arreglo a este modelo y permite que redes de microcomputadoras comuniquen entre sí, sea cual sea su sistema operativo, el tipo de cableado o el protocolo de su red local.
Además, como señalamos al citar a Gilder al principio de esta obra, la potencia de la red aumenta en proporción equivalente al cuadrado del número de sus servidores.
Cada nuevo servidor representa un recurso para los demás y la potencia y caridad de la red aumentan en una relación exponencial.
De hecho, el Internet parece un inmenso procesador planetario de información.
Los usuarios presentes en cada momento en la red comparten toda la potencia de comunicación disponible.
Al contrario del teléfono, en que la red tiene una capacidad máxima que se satura en las horas punta («debido a un exceso de llamadas, le rogamos vuelva a llamar dentro de unos minutos»), en Internet el espacio asignado a cada usuario en un momento dado es proporcional al número de usuarios presentes en cada momento.

¿Cómo se conecta con el Internet? 

El Internet no es una red uniforme, ya que está compuesta de los elementos heterogéneos que engloba; de hecho es una red que interconecta otras redes entre sí.
Cada computadora servidora de una red conectada a Internet es lo que llamamos «un servidor».
El servidor proporciona el acceso al Internet a cualquier microcomputadora que esté enlazada con ella y que disponga de los programas necesarios para comunicarse.
El servidor está conectado a una línea telefónica especializada que a su vez está conectada con el Internet y cuyo rendimiento es proporcional al número de sus clientes.
Una sociedad de telecomunicaciones proporciona el enlace con esta línea y factura la instalación y la utilización en función de su flujo.

Cuando yo me conecto con el Internet me convierto en cliente de un servidor.
Si estoy en una empresa o una organización que paga la factura del enlace y del abono, no tengo que pagar nada más para consultar durante una hora, ocho horas o veinticuatro horas, puesto que la línea se paga generalmente a un tanto alzado.
En cambio, si soy un particular que quiere conectar su microcomputadora con el Internet, tengo que dirigirme a un servidor privado comercial que me ofrezca acceso contra el pago de un abono a tanto alzado o según la duración.
Por consiguiente, en este caso debo pagar un abono, conectarme con la red del servidor que yo he elegido por medio de la línea telefónica, a través de un modem, y pagar además mi factura telefónica a fin de mes.

Cuanto más alejado esté mi servidor de mi lugar de conexión, más elevada será mi factura telefónica.
Esta partida del presupuesto tiende, lamentablemente, a ser la más importante si la política de tarificación de las sociedades de telecomunicaciones no es competitiva en el país en que vivo.

Hoy, el Internet ya no es el fenómeno anárquico, público y proteico del principio, pero desde el punto de vista comercial todavía no se ha recuperado completamente y está en una fase de transición.
Internet Society (asociación sin fines lucrativos), de la que dependen IETF (Internet Engineering Task Force) e IAB (Internet Architecture Board), dos organizaciones de pioneros y de especialistas internacionales voluntarios, todavía velan por la evolución de la red y de sus normas.
El Departamento de Defensa de los Estados Unidos de América financió la red desde sus orígenes.
A principios del decenio de 1980, la NSF (National Science Foundation) tomó el relevo con el fin de desarrollar la infraestructura física principal de las líneas especializadas (denominada familiarmente «backbone») que enlaza los servidores.
Su operador técnico, ANS (Advanced Network '&' Services), un organismo de investigación con fines no lucrativos creado en 1990 por IBM MCI y Merit Network, mantenía esta infraestructura.
ANS la ha vendido recientemente a America OnLine, una de las principales empresas del servicio en línea comercial.
Ahora, ANS, America OnLine y otras dos poderosas sociedades de servicios de comunicación, MCI y Sprint, garantizan conjuntamente el mantenimiento de la infraestructura.

Figura 37

Estructura esquemática de Internet

Caracterizada por su protocolo de comunicación TCP/IP que lo regula, el Internet se presenta como una sucesión de capas lógicas cada vez más sofisticadas que añaden, una tras otra, funcionalidades cada vez más ricas y fáciles de utilizar.
La funcionalidad de base es el correo electrónico.
Toda microcomputadora conectada con Internet tiene una dirección que le proporciona su servidor y se presenta en forma de una serie de caracteres cuya primera parte es una forma abreviada del nombre de la persona y la última una abreviatura del nombre del servidor y del país en que se sitúa el servidor destinatario.
Estas dos partes están separados por el signo «@» que es una abreviatura de la palabra inglesa « at ».
Por ejemplo: xxx .

Para enviar un mensaje se debe tener la dirección del destinatario o de los destinatarios.
Como ya hemos visto, los ficheros de sonidos, gráficos o vídeos pueden incluirse con un mensaje de texto gracias a la extensión MIME.
También es posible participar en grupos de información temática (denominados «newsgroups») y tener acceso a listas de preguntas frecuentemente formuladas en cada grupo, así como a sus respuestas.
Actualmente hay más de treinta mil «newsgroups» y otras tantas listas de participantes (Mailing Lists).
Muchos de estos grupos son establecimientos de enseñanza general o técnica, ciencias de la educación, ciencias humanas o ciencias exactas.

Telnet es una aplicación del Internet que permite conectar directamente a distancia con una computadora de acceso público para realizar alguna búsqueda en su base de datos.

Esta aplicación se utiliza para buscar referencias o ficheros, pero las órdenes no son fáciles de dominar y exigen un aprendizaje especial.

FTP (File Transfer Protocol) es otra aplicación de Internet que permite transferir en el propio disco duro ficheros que han sido localizados en microcomputadoras alejadas que autorizan la operación.
Existen numerosos servidores que ponen a disposición de los usuarios gran cantidad de bases de datos y servicios accesibles por medio del protocolo FTP.
La conexión requiere todo un procedimiento que exige el aprendizaje de las órdenes necesarias.

Telnet y FTP dan por supuesto que uno sabe dónde quiere ir.
Para ello es necesario localizar dónde se encuentra la información que se busca.
Archie es un sistema que permite localizar un fichero disponible en un servidor público. 
Archie dispone actualmente de un índice alfabético de varios millones de ficheros repartidos entre más de un millar de servidores.

Para encontrar en este índice lo que uno busca es necesario definir los criterios de la búsqueda a partir de una palabra.
Entonces, Archie puede proponer nombres de ficheros y la descripción de sus funciones.
Al final de la búsqueda, Archie da la lista de todos los ficheros correspondientes a los criterios definidos y de los servidores en que se han localizado.
Una vez localizado el fichero, FTP lo recupera.
Las versiones clientes de Archie existen en diversos entornos y en la actualidad incluyen además el protocolo FTP.

Gopher , del Internet, es una herramienta evolucionada que permite acceder a los recursos de Internet de manera simplificada.

Algunos programas clientes de Gopher están disponibles en todas las plataformas y permiten acceder a los servidores de Gopher.
Cuando se ejecuta, el programa cliente solicita a su servidor el menú principal.
Todos los servidores de Gopher suelen estar enlazados entre sí y su interfaz es de serie.
El usuario efectúa su elección definiendo su demanda.
Se inicia la búsqueda y los ficheros que se identifiquen pueden recuperarse, pero el procedimiento todavía no resulta fácil de utilizar sin un aprendizaje previo.

El sistema WAIS ( Wide Area Information Servers ) permite al usuario efectuar una búsqueda de textos en bancos de datos a partir de palabras clave basadas no ya en el título de los ficheros o la definición de sus funciones, sino en el contenido de los bancos.
El programa cliente de los servidores WAIS que existe en las principales plataformas permite acceder a estos recursos por medio de un interfaz simplificado, sin que el usuario se tenga que preocupar de la localización del servidor que tiene la información solicitada.

Pese a estas funcionalidades nuevas tan interesantes, su interfaz usuario es todavía demasiado enigmático para que goce de una amplia difusión entre el público.

World Wide Web es un sistema cliente/ servidor como Gopher, Archie o WAIS que permite acceder a los recursos de Internet, pero es mucho más fácil de utilizar.
De todos los sistemas que se han desarrollado en Internet, el Web es el que ha tenido más éxito.
Lo concibió y desarrolló Tim Berners-Lee, que trabajaba como investigador en el CERN, en Ginebra, basándose en el concepto de hipertexto.
Su puesta en marcha tuvo lugar a finales de 1992 y en marzo de 1995 contaba con 32000 servidores en todo el mundo.

Actualmente se estima que el tráfico generado por Web en Internet representa el 20 por ciento del tráfico total.

El Web se explora con la ayuda de un programa de navegación (denominado también «browser», «programas de navegación» o, simplemente, «navegantes»).
Estos navegantes son interfaces gráficos sofisticados que facilitan el recorrido por los recursos de los servidores Web, en los que la información se organiza a partir del modelo del hipermedia.
Los servidores Web albergan documentos que contienen textos, grafismos, sonidos o vídeos.

Estos elementos, cuando están enlazados por vínculos virtuales (hiperenlaces) a otros elementos del mismo servidor, o de otro alejado, están subrayados o recuadrados con el fin de indicar al usuario que puede pulsar encima de ellos para acceder a la información correspondiente.

El protocolo utilizado por el Web es el HTTP (Hypertext Transfer Protocol), que recupera y visualiza los documentos tan rápidamente como lo permiten la plataforma y la conexión.
Los documentos publicados en el Web son editados utilizando un programa de autor que está basado en el lenguaje HTML (Hypertext Markup Language).
El texto está integrado en formato ASCII.

Cuando está subrayado, sirve de puntero para los ficheros multimedia y para la localización de sus servidores.
Cuando el usuario aprieta sobre la palabra subrayada, el hiperenlace indica al Web con qué servidor debe conectar y qué fichero debe recuperar.

Cada servidor Web es una dirección que comienza siempre por el prefijo xxx .
He aquí un ejemplo: xxx .

El usuario conectado a Internet puede procurarse gratuitamente todos los elementos necesarios para navegar por los servidores del Web que desee.
Necesita sobre todo un programa de navegación como Mosaic o Netscape, que es más reciente, más rápido y más perfeccionado.
Le basta indicar la dirección del servidor con el que quiere conectar en la ventana de diálogo adecuada, se establece la conexión y aparece la página de acogida.
Ya no le queda sino efectuar su búsqueda pulsando una y otra vez sobre los elementos subrayados, en negritas o recuadrados que correspondan a sus intereses.

Estos servicios son accesibles a todas las plataformas mediante los navegantes Mosaic y Netscape, pero se anuncian nuevos programas que estarán directamente integrados a los sistemas operativos.
El World Wide Web se ha convertido en una norma al alcance de todos para acceder con facilidad a las informaciones multimedia que de este modo se ponen a su disposición.
Si es fácil acceder a estas informaciones, es casi tan fácil publicarlas.

Hoy, abren servidores Web las grandes cene bales sindicales, por ejemplo AFL-CIO, la revista Workers' Education y diversas publicaciones de la FIAEO (Federación Internacional de Asociaciones de Educación Obrera), que preparan también la edición de sus archivos sobre ese soporte.
En otro tiempo, algunas universidades se dedicaban a la enseñanza a distancia, como la Télé-Université du Québec , pero hoy se crean directamente universidades, escuelas y centros de formación a distancia en el Internet y el Web.

Figura 38

Número de servidores de World Wide Web

La publicación de informaciones en un servidor de World Wide Web 

Hoy, si se quieren publicar informaciones en Web para usuarios aislados en el mundo entero o para grupos de trabajo, se presentan cuatro tipos de soluciones.

La primera consiste en subcontratar completamente la edición y la difusión de las páginas.

La segunda es editar uno mismo las páginas y confiar a un servidor su difusión.

La tercera consiste en editar uno mismo las páginas y difundirlas desde su propia red conectada a la de un servidor.

Por último, la cuarta es producir y difundir uno mismo las páginas de manera completamente autónoma.

Todo depende del presupuesto o la competencia técnica de que se disponga y de la autonomía que se necesite.

Hasta hace poco era necesario no sólo tener un buen dominio de la producción de los documentos multimedia en microcomputadora, sino también disponer de una red con sistema operativo Unix para publicar y difundir informaciones por Web.
Ahora existen kits que permiten constituir una configuración en la plataforma elegida para editar y difundir páginas en formato HTML (Hypertext Markup Language).
Ya hemos visto que los programas de creación de aplicaciones multimedia como M/Tropolis o PowerMedia que han aparecido recientemente, permiten no sólo editar aplicaciones multimedia, sino también convertirlas al formato HTML.

Las últimas versiones de las grandes normas de tratamiento de textos Word o WordPerfect, al igual que los programas de compaginación XPress y FrameMaker, permiten también convertir al formato HTML los documentos que ayudan a editar.
Hace algún tiempo era necesario codificar manualmente la compaginación de los documentos previamente creados y la interactividad de las aplicaciones, con la sintaxis específica.
Algunos programas de edición en formato HTML como W3 o BBEdit en Macintosh, permiten también efectuar este trabajo de codificación de forma automática a partir de un documento ya existente.

Algunos fabricantes de computadoras como Apple Computers, Performance Technology o Sun Microsystems ofrecen actualmente en el mercado servidores llaves en mano.
En el caso de Apple se trata de los AIS (Apple Internet Servers) basados en las microcomputadoras PowerMac.
Estos AIS están dotados de un conjunto de programas difundidos en CD-ROM y permiten que uno mismo instale automáticamente el servidor y asegure el conjunto de las funciones necesarias para su creación sin tener ninguna noción de Unix, desde la creación de las páginas del Web hasta la gestión de la red local y las transacciones con todos los entornos clientes (Windows o Unix) en el Internet y el Web.
Entre todos los programas suministrados, WebStar (o MacHTTP) tiene un interfaz gráfico que facilita su funcionamiento y asegura muy eficazmente esta función de administración del servidor y de las llamadas simultáneas de los clientes.

Por su parte, Performance Technology ofrece Instant Internet.
Es una solución completa en forma de cajetín que se conecta con una red local de tipo NetWare IPX LAN a través de Windows para servir de puente entre la red y el Internet.
No es un servidor en sentido estricto, es simplemente un medio económico de conectar una red de microcomputadoras al Internet.
Tiene todos los elementos físicos y lógicos necesarios para su instalación y funcionamiento: el puerto Ethernet, el modem y el procesador Intel 486SX.
La instalación es bastante fácil y se suministran los programas necesarios para la gestión de la red y la navegación por Internet.
Sin embargo, es un servidor Windows exclusivamente; sólo los clientes que funcionan con este sistema operativo tienen acceso a sus servicios.

En el entorno PC, los servicios se crean generalmente a partir de máquinas potentes provistas de un microprocesador Intel Pentium (o DEC Alpha), a través de Microsoft Windows NT 3.5 y con el programa EMWAC Web Server (European Microsoft Windows Academic Consortium).

Sun, que desde hace tiempo colabora en la creación y gestión de los servidores TCP/IP a través de Unix, ofrece ahora un servidor llaves en mano: la estación Netra Internet Server.
Es un cajetín que contiene una placa base de estación de trabajo Sun que funciona a través de Solaris (la versión Unix de Sun).

Insertado en una red de estaciones de trabajo, proporciona el acceso al Internet a cualquier máquina de la red.
Sin embargo, como Instant Internet, no es un servidor propiamente dicho.
La instalación del cajetín Netra Internet Server debe realizarla un especialista, pero su gestión puede garantizarla un usuario de la red que ya conozca el funcionamiento de Unix.

El futuro de las redes 

Ya hemos visto que el establecimiento de una red o un servidor basados en el protocolo TCP/IP es relativamente fácil.
Esta solución tiene la ventaja de su universalidad y economía.
Puede utilizarse en todas las redes locales, así como para comunicar en el Internet, intercambiar mensajes electrónicos ocasionales, llevar a cabo visioconferencias, buscar informaciones y contenidos de formación o trabajar en colaboración con colegas situados en lugares alejados o en el otro extremo del planeta.

La evolución de esta tecnología es muy rápida y se produce gracias a una concertación continua de estudiantes e investigadores que ya la utilizan como un medio de trabajo colectivo, circunstancia que acelera proporcionalmente su desarrollo.
Las prestaciones y funcionalidades que conocemos hoy no serán nada comparadas con las que habrá mañana.
Las aplicaciones comerciales que surgen en la actualidad hacen aumentar las ganas de utilizarla.
Todas las grandes empresas del sector se movilizan para ocupar los nichos estratégicos.
La seguridad de las transacciones comerciales es todavía un problema en este tipo de red pública.
Los «hackers», o jóvenes piratas de la tecnología digital, efectúan incursiones en las redes de las grandes empresas o de los organismos públicos para extraer informaciones estratégicas.
Algunos cometen incluso fechorías destructoras introduciendo virus informáticos en los sistemas y las redes que visitan.

Hasta hace poco el Internet presentaba el inconveniente de no ofrecer garantías suficientes de confidencialidad y exponer a los servidores y las redes locales a acciones de esos piratas, pero ahora hay soluciones basadas en el cifrado o codificación de las informaciones. 
Únicamente las legislaciones nacionales que limitan el uso de estos métodos de cifrado se oponen todavía a su utilización.
En cualquier caso, si hay un tema que no necesita confidencialidad éste es el de la disponibilidad de las informaciones y los recursos didácticos más eficaces para la defensa y la educación de los trabajadores, que, por el contrario, debe presentarse con los instrumentos que garanticen la máxima difusión posible.

Conclusión 

Hemos intentado poner de manifiesto a lo largo de este recorrido transversal un poco inhabitual cuáles son en este período de mutación y crisis las tecnologías y los métodos que se ofrecen a los sindicatos y a los organismos dedicados a la educación o formación de los trabajadores.
Los interlocutores deben establecer procedimientos de comunicación y actividades de formación eficaces, adaptados a las necesidades de hoy.
Han de contribuir a la producción y suministro de los documentos de comunicación correspondientes y los recursos didácticos adecuados con los medios adaptados a cada circunstancia.
Como ya hemos visto a lo largo de toda esta obra, esas actividades de formación o comunicación presuponen la creación de un contexto tecnológico apropiado.
A modo de conclusión, intentaremos sintetizar en la lista siguiente las principales ventajas que cabe esperar obtener de la aplicación de las nuevas tecnologías en el ámbito de la formación: 

Publicación económica y difusión mundial de la información: las tecnologías digitales en general, el Internet en particular, permiten comunicar rápidamente y de manera eficaz con todos los interlocutores del mundo del trabajo.
Cada uno de ellos puede poner a disposición de los demás todas las informaciones que considere útiles.

Optimización de la búsqueda documental: la utilización de las redes permite experimentar y desarrollar métodos de búsqueda más fiables en más bancos de datos y con contenidos más amplios que den acceso a informaciones más sutiles y coherentes.

Aprendizaje in situ: la formación puede llevarse donde el individuo la necesite.
El trabajador puede recibir en el mismo lugar de trabajo, en su casa a través de su microcomputadora, o en la sede sindical, la información o la formación que necesite para progresar en el ejercicio de sus funciones o para adaptar su cultura y sus conocimientos técnicos a las nuevas tareas que la sociedad espera de él.

Adaptación del ritmo de aprendizaje: la computadora es un profesor particular incansable que se adapta, sin variaciones en el estado de ánimo, con discreción y sin prejuicios, al ritmo, disponibilidad, localización o disposiciones intelectuales a manuales de cada uno.

Simulación de los entornos en grandes dimensiones y en tiempo real: las computadoras permiten simular todos los sistemas complejos, los fenómenos reales del mercado o los sistemas de producción necesarios para el estudio y análisis de la situación y la adopción de las decisiones más eficaces.

Incremento de la interactividad de los actores: la puesta en práctica de modalidades de búsqueda de información, trabajo o formación en colaboración en las redes aumenta el número de interacciones de los trabajadores con sus interlocutores reforzando la asimilación de las informaciones y conocimientos, así como la rapidez y calidad en la adopción de decisiones.

Confidencialidad del aprendizaje: el individuo, situado ante su microcomputadora, puede aislarse y perder de este modo el miedo o la propensión al bloqueo frente a la presencia o la mirada de sus colegas.
Así se siente más confiado y, por consiguiente, se encuentra en mejor situación para comprender y asimilar las informaciones y transformarlas en conocimientos generales y técnicos.

Regulación del comportamiento del alumno: las decisiones que el usuario debe tomar en el curso de las operaciones movilizan su atención y constituyen un llamamiento a su buen juicio y su responsabilidad.
Su atención está encauzada por el desarrollo del programa que él mismo dirige, a su propio ritmo.
Todo ello contribuye a regularizar el comportamiento de las personas inestables, difíciles o reacias.

Cambio de función del formador: como quiera que las informaciones o los conocimientos ya no son transmitidos exclusivamente por el formador, su papel consiste más bien en ser un diseñador de actividades, un metodólogo y un guía para los alumnos a fin de que puedan acceder con autonomía a los recursos y aprovecharlos eficazmente con arreglo a sus necesidades.

Fomento de la curiosidad, la creatividad y el trabajo en equipo: la aplicación de estos procedimientos de comunicación puede favorecer la expresión de las cualidades de todos los miembros del equipo, mejorando globalmente la responsabilidad de cada uno y su colaboración en el destino de la estructura en la que participa.

En la actualidad, los nuevos medios de comunicación permiten que todas las organizaciones afectadas, en todos los países, se pongan en contacto instantánea y permanentemente a escala internacional para participar en ese amplio movimiento de reflexión y renovación de la acción sindical y la formación de los trabajadores.
De este modo, en un impulso de solidaridad saludable, los que tienen más recursos podrán poner rápida y fácilmente al servicio de los más desfavorecidos sus medios, sus informaciones, sus conocimientos, sus consejos y su ayuda.
